//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35813241
// Cuda compilation tools, release 12.9, V12.9.41
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_52
.address_size 64

	// .globl	where_i64_f32

.visible .entry where_i64_f32(
	.param .u64 where_i64_f32_param_0,
	.param .u64 where_i64_f32_param_1,
	.param .u64 where_i64_f32_param_2,
	.param .u64 where_i64_f32_param_3,
	.param .u64 where_i64_f32_param_4,
	.param .u64 where_i64_f32_param_5,
	.param .u64 where_i64_f32_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<157>;


	ld.param.u64 	%rd54, [where_i64_f32_param_0];
	ld.param.u64 	%rd55, [where_i64_f32_param_1];
	ld.param.u64 	%rd59, [where_i64_f32_param_2];
	ld.param.u64 	%rd60, [where_i64_f32_param_3];
	ld.param.u64 	%rd56, [where_i64_f32_param_4];
	ld.param.u64 	%rd57, [where_i64_f32_param_5];
	ld.param.u64 	%rd58, [where_i64_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB0_13;

	mov.u64 	%rd145, 1;
	mov.u32 	%r72, 0;

$L__BB0_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB0_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd145, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB0_13;

$L__BB0_4:
	mul.lo.s64 	%rd145, %rd10, %rd145;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd69, %r72;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB0_2;

	mov.u64 	%rd146, 1;
	mov.u32 	%r73, 0;

$L__BB0_6:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB0_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd146, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB0_13;

$L__BB0_8:
	mul.lo.s64 	%rd146, %rd14, %rd146;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd78, %r73;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB0_6;

	mov.u64 	%rd147, 1;
	mov.u32 	%r74, 0;

$L__BB0_10:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB0_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd147, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB0_13;

$L__BB0_12:
	mul.lo.s64 	%rd147, %rd18, %rd147;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd87, %r74;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB0_10;

$L__BB0_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd148, %r75;
	@%p32 bra 	$L__BB0_31;
	bra.uni 	$L__BB0_14;

$L__BB0_31:
	setp.ge.u64 	%p29, %rd148, %rd54;
	@%p29 bra 	$L__BB0_34;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB0_33:
	shl.b64 	%rd138, %rd148, 3;
	add.s64 	%rd139, %rd4, %rd138;
	ld.global.u64 	%rd140, [%rd139];
	setp.eq.s64 	%p30, %rd140, 0;
	selp.b64 	%rd141, %rd2, %rd3, %p30;
	shl.b64 	%rd142, %rd148, 2;
	add.s64 	%rd143, %rd141, %rd142;
	ld.global.f32 	%f3, [%rd143];
	add.s64 	%rd144, %rd1, %rd142;
	st.global.f32 	[%rd144], %f3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd148, %r75;
	setp.lt.u64 	%p31, %rd148, %rd54;
	@%p31 bra 	$L__BB0_33;
	bra.uni 	$L__BB0_34;

$L__BB0_14:
	setp.ge.u64 	%p17, %rd148, %rd54;
	@%p17 bra 	$L__BB0_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB0_30;

$L__BB0_16:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB0_17:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r77;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB0_19;

	div.u64 	%rd149, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd149, %rd24;
	sub.s64 	%rd150, %rd22, %rd93;
	bra.uni 	$L__BB0_20;

$L__BB0_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd149, %r49;
	cvt.u64.u32 	%rd150, %r51;

$L__BB0_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd150;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd149;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd98, %r76;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p20 bra 	$L__BB0_17;

$L__BB0_21:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r80;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB0_23;

	div.u64 	%rd151, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd151, %rd33;
	sub.s64 	%rd152, %rd31, %rd104;
	bra.uni 	$L__BB0_24;

$L__BB0_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd151, %r58;
	cvt.u64.u32 	%rd152, %r60;

$L__BB0_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd152;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd151;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd109, %r79;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p22 bra 	$L__BB0_21;

$L__BB0_25:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r83;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB0_27;

	div.u64 	%rd153, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd153, %rd42;
	sub.s64 	%rd154, %rd40, %rd115;
	bra.uni 	$L__BB0_28;

$L__BB0_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd153, %r67;
	cvt.u64.u32 	%rd154, %r69;

$L__BB0_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd154;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd153;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd120, %r82;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB0_25;

	mul.wide.u32 	%rd121, %r78, 8;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u64 	%rd123, [%rd122];
	setp.eq.s64 	%p25, %rd123, 0;
	mul.wide.u32 	%rd125, %r81, 4;
	add.s64 	%rd126, %rd3, %rd125;
	mul.wide.u32 	%rd128, %r84, 4;
	add.s64 	%rd129, %rd2, %rd128;
	selp.b64 	%rd130, %rd129, %rd126, %p25;
	ld.global.f32 	%f1, [%rd130];
	shl.b64 	%rd132, %rd148, 2;
	add.s64 	%rd133, %rd1, %rd132;
	st.global.f32 	[%rd133], %f1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd148, %r75;
	setp.lt.u64 	%p26, %rd148, %rd54;
	@%p26 bra 	$L__BB0_16;
	bra.uni 	$L__BB0_34;

$L__BB0_30:
	ld.global.u64 	%rd134, [%rd4];
	setp.eq.s64 	%p27, %rd134, 0;
	selp.b64 	%rd135, %rd2, %rd3, %p27;
	ld.global.f32 	%f2, [%rd135];
	shl.b64 	%rd136, %rd148, 2;
	add.s64 	%rd137, %rd1, %rd136;
	st.global.f32 	[%rd137], %f2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd148, %r75;
	setp.lt.u64 	%p28, %rd148, %rd54;
	@%p28 bra 	$L__BB0_30;

$L__BB0_34:
	ret;

}
	// .globl	where_i64_f64
.visible .entry where_i64_f64(
	.param .u64 where_i64_f64_param_0,
	.param .u64 where_i64_f64_param_1,
	.param .u64 where_i64_f64_param_2,
	.param .u64 where_i64_f64_param_3,
	.param .u64 where_i64_f64_param_4,
	.param .u64 where_i64_f64_param_5,
	.param .u64 where_i64_f64_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b32 	%r<87>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<156>;


	ld.param.u64 	%rd54, [where_i64_f64_param_0];
	ld.param.u64 	%rd55, [where_i64_f64_param_1];
	ld.param.u64 	%rd59, [where_i64_f64_param_2];
	ld.param.u64 	%rd60, [where_i64_f64_param_3];
	ld.param.u64 	%rd56, [where_i64_f64_param_4];
	ld.param.u64 	%rd57, [where_i64_f64_param_5];
	ld.param.u64 	%rd58, [where_i64_f64_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB1_13;

	mov.u64 	%rd144, 1;
	mov.u32 	%r72, 0;

$L__BB1_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB1_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd144, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB1_13;

$L__BB1_4:
	mul.lo.s64 	%rd144, %rd10, %rd144;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd69, %r72;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB1_2;

	mov.u64 	%rd145, 1;
	mov.u32 	%r73, 0;

$L__BB1_6:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB1_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd145, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB1_13;

$L__BB1_8:
	mul.lo.s64 	%rd145, %rd14, %rd145;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd78, %r73;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB1_6;

	mov.u64 	%rd146, 1;
	mov.u32 	%r74, 0;

$L__BB1_10:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB1_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd146, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB1_13;

$L__BB1_12:
	mul.lo.s64 	%rd146, %rd18, %rd146;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd87, %r74;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB1_10;

$L__BB1_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd147, %r75;
	@%p32 bra 	$L__BB1_31;
	bra.uni 	$L__BB1_14;

$L__BB1_31:
	setp.ge.u64 	%p29, %rd147, %rd54;
	@%p29 bra 	$L__BB1_34;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB1_33:
	shl.b64 	%rd138, %rd147, 3;
	add.s64 	%rd139, %rd4, %rd138;
	ld.global.u64 	%rd140, [%rd139];
	setp.eq.s64 	%p30, %rd140, 0;
	selp.b64 	%rd141, %rd2, %rd3, %p30;
	add.s64 	%rd142, %rd141, %rd138;
	ld.global.f64 	%fd3, [%rd142];
	add.s64 	%rd143, %rd1, %rd138;
	st.global.f64 	[%rd143], %fd3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p31, %rd147, %rd54;
	@%p31 bra 	$L__BB1_33;
	bra.uni 	$L__BB1_34;

$L__BB1_14:
	setp.ge.u64 	%p17, %rd147, %rd54;
	@%p17 bra 	$L__BB1_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB1_30;

$L__BB1_16:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB1_17:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r77;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB1_19;

	div.u64 	%rd148, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd148, %rd24;
	sub.s64 	%rd149, %rd22, %rd93;
	bra.uni 	$L__BB1_20;

$L__BB1_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd148, %r49;
	cvt.u64.u32 	%rd149, %r51;

$L__BB1_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd149;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd148;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd98, %r76;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p20 bra 	$L__BB1_17;

$L__BB1_21:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r80;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB1_23;

	div.u64 	%rd150, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd150, %rd33;
	sub.s64 	%rd151, %rd31, %rd104;
	bra.uni 	$L__BB1_24;

$L__BB1_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd150, %r58;
	cvt.u64.u32 	%rd151, %r60;

$L__BB1_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd151;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd150;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd109, %r79;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p22 bra 	$L__BB1_21;

$L__BB1_25:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r83;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB1_27;

	div.u64 	%rd152, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd152, %rd42;
	sub.s64 	%rd153, %rd40, %rd115;
	bra.uni 	$L__BB1_28;

$L__BB1_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd152, %r67;
	cvt.u64.u32 	%rd153, %r69;

$L__BB1_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd153;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd152;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd120, %r82;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB1_25;

	mul.wide.u32 	%rd121, %r78, 8;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u64 	%rd123, [%rd122];
	setp.eq.s64 	%p25, %rd123, 0;
	mul.wide.u32 	%rd125, %r81, 8;
	add.s64 	%rd126, %rd3, %rd125;
	mul.wide.u32 	%rd128, %r84, 8;
	add.s64 	%rd129, %rd2, %rd128;
	selp.b64 	%rd130, %rd129, %rd126, %p25;
	ld.global.f64 	%fd1, [%rd130];
	shl.b64 	%rd132, %rd147, 3;
	add.s64 	%rd133, %rd1, %rd132;
	st.global.f64 	[%rd133], %fd1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p26, %rd147, %rd54;
	@%p26 bra 	$L__BB1_16;
	bra.uni 	$L__BB1_34;

$L__BB1_30:
	ld.global.u64 	%rd134, [%rd4];
	setp.eq.s64 	%p27, %rd134, 0;
	selp.b64 	%rd135, %rd2, %rd3, %p27;
	ld.global.f64 	%fd2, [%rd135];
	shl.b64 	%rd136, %rd147, 3;
	add.s64 	%rd137, %rd1, %rd136;
	st.global.f64 	[%rd137], %fd2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p28, %rd147, %rd54;
	@%p28 bra 	$L__BB1_30;

$L__BB1_34:
	ret;

}
	// .globl	where_i64_u8
.visible .entry where_i64_u8(
	.param .u64 where_i64_u8_param_0,
	.param .u64 where_i64_u8_param_1,
	.param .u64 where_i64_u8_param_2,
	.param .u64 where_i64_u8_param_3,
	.param .u64 where_i64_u8_param_4,
	.param .u64 where_i64_u8_param_5,
	.param .u64 where_i64_u8_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<154>;


	ld.param.u64 	%rd54, [where_i64_u8_param_0];
	ld.param.u64 	%rd55, [where_i64_u8_param_1];
	ld.param.u64 	%rd59, [where_i64_u8_param_2];
	ld.param.u64 	%rd60, [where_i64_u8_param_3];
	ld.param.u64 	%rd56, [where_i64_u8_param_4];
	ld.param.u64 	%rd57, [where_i64_u8_param_5];
	ld.param.u64 	%rd58, [where_i64_u8_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB2_13;

	mov.u64 	%rd142, 1;
	mov.u32 	%r72, 0;

$L__BB2_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB2_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd142, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB2_13;

$L__BB2_4:
	mul.lo.s64 	%rd142, %rd10, %rd142;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd69, %r72;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB2_2;

	mov.u64 	%rd143, 1;
	mov.u32 	%r73, 0;

$L__BB2_6:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB2_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd143, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB2_13;

$L__BB2_8:
	mul.lo.s64 	%rd143, %rd14, %rd143;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd78, %r73;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB2_6;

	mov.u64 	%rd144, 1;
	mov.u32 	%r74, 0;

$L__BB2_10:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB2_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd144, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB2_13;

$L__BB2_12:
	mul.lo.s64 	%rd144, %rd18, %rd144;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd87, %r74;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB2_10;

$L__BB2_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd145, %r75;
	@%p32 bra 	$L__BB2_31;
	bra.uni 	$L__BB2_14;

$L__BB2_31:
	setp.ge.u64 	%p29, %rd145, %rd54;
	@%p29 bra 	$L__BB2_34;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB2_33:
	shl.b64 	%rd136, %rd145, 3;
	add.s64 	%rd137, %rd4, %rd136;
	ld.global.u64 	%rd138, [%rd137];
	setp.eq.s64 	%p30, %rd138, 0;
	selp.b64 	%rd139, %rd2, %rd3, %p30;
	add.s64 	%rd140, %rd139, %rd145;
	ld.global.u8 	%rs3, [%rd140];
	add.s64 	%rd141, %rd1, %rd145;
	st.global.u8 	[%rd141], %rs3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd145, %r75;
	setp.lt.u64 	%p31, %rd145, %rd54;
	@%p31 bra 	$L__BB2_33;
	bra.uni 	$L__BB2_34;

$L__BB2_14:
	setp.ge.u64 	%p17, %rd145, %rd54;
	@%p17 bra 	$L__BB2_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB2_30;

$L__BB2_16:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB2_17:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r77;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB2_19;

	div.u64 	%rd146, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd146, %rd24;
	sub.s64 	%rd147, %rd22, %rd93;
	bra.uni 	$L__BB2_20;

$L__BB2_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd146, %r49;
	cvt.u64.u32 	%rd147, %r51;

$L__BB2_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd147;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd146;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd98, %r76;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p20 bra 	$L__BB2_17;

$L__BB2_21:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r80;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB2_23;

	div.u64 	%rd148, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd148, %rd33;
	sub.s64 	%rd149, %rd31, %rd104;
	bra.uni 	$L__BB2_24;

$L__BB2_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd148, %r58;
	cvt.u64.u32 	%rd149, %r60;

$L__BB2_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd149;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd148;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd109, %r79;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p22 bra 	$L__BB2_21;

$L__BB2_25:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r83;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB2_27;

	div.u64 	%rd150, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd150, %rd42;
	sub.s64 	%rd151, %rd40, %rd115;
	bra.uni 	$L__BB2_28;

$L__BB2_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd150, %r67;
	cvt.u64.u32 	%rd151, %r69;

$L__BB2_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd151;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd150;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd120, %r82;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB2_25;

	mul.wide.u32 	%rd121, %r78, 8;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u64 	%rd123, [%rd122];
	setp.eq.s64 	%p25, %rd123, 0;
	cvt.u64.u32 	%rd124, %r81;
	add.s64 	%rd126, %rd3, %rd124;
	cvt.u64.u32 	%rd127, %r84;
	add.s64 	%rd129, %rd2, %rd127;
	selp.b64 	%rd130, %rd129, %rd126, %p25;
	ld.global.u8 	%rs1, [%rd130];
	add.s64 	%rd132, %rd1, %rd145;
	st.global.u8 	[%rd132], %rs1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd145, %r75;
	setp.lt.u64 	%p26, %rd145, %rd54;
	@%p26 bra 	$L__BB2_16;
	bra.uni 	$L__BB2_34;

$L__BB2_30:
	ld.global.u64 	%rd133, [%rd4];
	setp.eq.s64 	%p27, %rd133, 0;
	selp.b64 	%rd134, %rd2, %rd3, %p27;
	ld.global.u8 	%rs2, [%rd134];
	add.s64 	%rd135, %rd1, %rd145;
	st.global.u8 	[%rd135], %rs2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd145, %r75;
	setp.lt.u64 	%p28, %rd145, %rd54;
	@%p28 bra 	$L__BB2_30;

$L__BB2_34:
	ret;

}
	// .globl	where_i64_u32
.visible .entry where_i64_u32(
	.param .u64 where_i64_u32_param_0,
	.param .u64 where_i64_u32_param_1,
	.param .u64 where_i64_u32_param_2,
	.param .u64 where_i64_u32_param_3,
	.param .u64 where_i64_u32_param_4,
	.param .u64 where_i64_u32_param_5,
	.param .u64 where_i64_u32_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<157>;


	ld.param.u64 	%rd54, [where_i64_u32_param_0];
	ld.param.u64 	%rd55, [where_i64_u32_param_1];
	ld.param.u64 	%rd59, [where_i64_u32_param_2];
	ld.param.u64 	%rd60, [where_i64_u32_param_3];
	ld.param.u64 	%rd56, [where_i64_u32_param_4];
	ld.param.u64 	%rd57, [where_i64_u32_param_5];
	ld.param.u64 	%rd58, [where_i64_u32_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB3_13;

	mov.u64 	%rd145, 1;
	mov.u32 	%r75, 0;

$L__BB3_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB3_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd145, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB3_13;

$L__BB3_4:
	mul.lo.s64 	%rd145, %rd10, %rd145;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd69, %r75;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB3_2;

	mov.u64 	%rd146, 1;
	mov.u32 	%r76, 0;

$L__BB3_6:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB3_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd146, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB3_13;

$L__BB3_8:
	mul.lo.s64 	%rd146, %rd14, %rd146;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd78, %r76;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB3_6;

	mov.u64 	%rd147, 1;
	mov.u32 	%r77, 0;

$L__BB3_10:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB3_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd147, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB3_13;

$L__BB3_12:
	mul.lo.s64 	%rd147, %rd18, %rd147;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd87, %r77;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB3_10;

$L__BB3_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd148, %r78;
	@%p32 bra 	$L__BB3_31;
	bra.uni 	$L__BB3_14;

$L__BB3_31:
	setp.ge.u64 	%p29, %rd148, %rd54;
	@%p29 bra 	$L__BB3_34;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB3_33:
	shl.b64 	%rd138, %rd148, 3;
	add.s64 	%rd139, %rd4, %rd138;
	ld.global.u64 	%rd140, [%rd139];
	setp.eq.s64 	%p30, %rd140, 0;
	selp.b64 	%rd141, %rd2, %rd3, %p30;
	shl.b64 	%rd142, %rd148, 2;
	add.s64 	%rd143, %rd141, %rd142;
	ld.global.u32 	%r74, [%rd143];
	add.s64 	%rd144, %rd1, %rd142;
	st.global.u32 	[%rd144], %r74;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p31, %rd148, %rd54;
	@%p31 bra 	$L__BB3_33;
	bra.uni 	$L__BB3_34;

$L__BB3_14:
	setp.ge.u64 	%p17, %rd148, %rd54;
	@%p17 bra 	$L__BB3_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB3_30;

$L__BB3_16:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB3_17:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r80;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB3_19;

	div.u64 	%rd149, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd149, %rd24;
	sub.s64 	%rd150, %rd22, %rd93;
	bra.uni 	$L__BB3_20;

$L__BB3_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd149, %r49;
	cvt.u64.u32 	%rd150, %r51;

$L__BB3_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd150;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd149;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd98, %r79;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p20 bra 	$L__BB3_17;

$L__BB3_21:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r83;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB3_23;

	div.u64 	%rd151, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd151, %rd33;
	sub.s64 	%rd152, %rd31, %rd104;
	bra.uni 	$L__BB3_24;

$L__BB3_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd151, %r58;
	cvt.u64.u32 	%rd152, %r60;

$L__BB3_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd152;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd151;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd109, %r82;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p22 bra 	$L__BB3_21;

$L__BB3_25:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r86;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB3_27;

	div.u64 	%rd153, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd153, %rd42;
	sub.s64 	%rd154, %rd40, %rd115;
	bra.uni 	$L__BB3_28;

$L__BB3_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd153, %r67;
	cvt.u64.u32 	%rd154, %r69;

$L__BB3_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd154;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd153;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd120, %r85;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB3_25;

	mul.wide.u32 	%rd121, %r81, 8;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u64 	%rd123, [%rd122];
	setp.eq.s64 	%p25, %rd123, 0;
	mul.wide.u32 	%rd125, %r84, 4;
	add.s64 	%rd126, %rd3, %rd125;
	mul.wide.u32 	%rd128, %r87, 4;
	add.s64 	%rd129, %rd2, %rd128;
	selp.b64 	%rd130, %rd129, %rd126, %p25;
	ld.global.u32 	%r71, [%rd130];
	shl.b64 	%rd132, %rd148, 2;
	add.s64 	%rd133, %rd1, %rd132;
	st.global.u32 	[%rd133], %r71;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p26, %rd148, %rd54;
	@%p26 bra 	$L__BB3_16;
	bra.uni 	$L__BB3_34;

$L__BB3_30:
	ld.global.u64 	%rd134, [%rd4];
	setp.eq.s64 	%p27, %rd134, 0;
	selp.b64 	%rd135, %rd2, %rd3, %p27;
	ld.global.u32 	%r72, [%rd135];
	shl.b64 	%rd136, %rd148, 2;
	add.s64 	%rd137, %rd1, %rd136;
	st.global.u32 	[%rd137], %r72;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p28, %rd148, %rd54;
	@%p28 bra 	$L__BB3_30;

$L__BB3_34:
	ret;

}
	// .globl	where_i64_i64
.visible .entry where_i64_i64(
	.param .u64 where_i64_i64_param_0,
	.param .u64 where_i64_i64_param_1,
	.param .u64 where_i64_i64_param_2,
	.param .u64 where_i64_i64_param_3,
	.param .u64 where_i64_i64_param_4,
	.param .u64 where_i64_i64_param_5,
	.param .u64 where_i64_i64_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<159>;


	ld.param.u64 	%rd54, [where_i64_i64_param_0];
	ld.param.u64 	%rd55, [where_i64_i64_param_1];
	ld.param.u64 	%rd59, [where_i64_i64_param_2];
	ld.param.u64 	%rd60, [where_i64_i64_param_3];
	ld.param.u64 	%rd56, [where_i64_i64_param_4];
	ld.param.u64 	%rd57, [where_i64_i64_param_5];
	ld.param.u64 	%rd58, [where_i64_i64_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB4_13;

	mov.u64 	%rd147, 1;
	mov.u32 	%r72, 0;

$L__BB4_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB4_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd147, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB4_13;

$L__BB4_4:
	mul.lo.s64 	%rd147, %rd10, %rd147;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd69, %r72;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB4_2;

	mov.u64 	%rd148, 1;
	mov.u32 	%r73, 0;

$L__BB4_6:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB4_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd148, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB4_13;

$L__BB4_8:
	mul.lo.s64 	%rd148, %rd14, %rd148;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd78, %r73;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB4_6;

	mov.u64 	%rd149, 1;
	mov.u32 	%r74, 0;

$L__BB4_10:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB4_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd149, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB4_13;

$L__BB4_12:
	mul.lo.s64 	%rd149, %rd18, %rd149;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd87, %r74;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB4_10;

$L__BB4_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd150, %r75;
	@%p32 bra 	$L__BB4_31;
	bra.uni 	$L__BB4_14;

$L__BB4_31:
	setp.ge.u64 	%p29, %rd150, %rd54;
	@%p29 bra 	$L__BB4_34;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB4_33:
	shl.b64 	%rd140, %rd150, 3;
	add.s64 	%rd141, %rd4, %rd140;
	ld.global.u64 	%rd142, [%rd141];
	setp.eq.s64 	%p30, %rd142, 0;
	selp.b64 	%rd143, %rd2, %rd3, %p30;
	add.s64 	%rd144, %rd143, %rd140;
	ld.global.u64 	%rd145, [%rd144];
	add.s64 	%rd146, %rd1, %rd140;
	st.global.u64 	[%rd146], %rd145;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p31, %rd150, %rd54;
	@%p31 bra 	$L__BB4_33;
	bra.uni 	$L__BB4_34;

$L__BB4_14:
	setp.ge.u64 	%p17, %rd150, %rd54;
	@%p17 bra 	$L__BB4_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB4_30;

$L__BB4_16:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB4_17:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r77;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB4_19;

	div.u64 	%rd151, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd151, %rd24;
	sub.s64 	%rd152, %rd22, %rd93;
	bra.uni 	$L__BB4_20;

$L__BB4_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd151, %r49;
	cvt.u64.u32 	%rd152, %r51;

$L__BB4_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd152;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd151;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd98, %r76;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p20 bra 	$L__BB4_17;

$L__BB4_21:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r80;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB4_23;

	div.u64 	%rd153, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd153, %rd33;
	sub.s64 	%rd154, %rd31, %rd104;
	bra.uni 	$L__BB4_24;

$L__BB4_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd153, %r58;
	cvt.u64.u32 	%rd154, %r60;

$L__BB4_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd154;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd153;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd109, %r79;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p22 bra 	$L__BB4_21;

$L__BB4_25:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r83;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB4_27;

	div.u64 	%rd155, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd155, %rd42;
	sub.s64 	%rd156, %rd40, %rd115;
	bra.uni 	$L__BB4_28;

$L__BB4_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd155, %r67;
	cvt.u64.u32 	%rd156, %r69;

$L__BB4_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd156;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd155;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd120, %r82;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB4_25;

	mul.wide.u32 	%rd121, %r78, 8;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u64 	%rd123, [%rd122];
	setp.eq.s64 	%p25, %rd123, 0;
	mul.wide.u32 	%rd125, %r81, 8;
	add.s64 	%rd126, %rd3, %rd125;
	mul.wide.u32 	%rd128, %r84, 8;
	add.s64 	%rd129, %rd2, %rd128;
	selp.b64 	%rd130, %rd129, %rd126, %p25;
	ld.global.u64 	%rd131, [%rd130];
	shl.b64 	%rd133, %rd150, 3;
	add.s64 	%rd134, %rd1, %rd133;
	st.global.u64 	[%rd134], %rd131;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p26, %rd150, %rd54;
	@%p26 bra 	$L__BB4_16;
	bra.uni 	$L__BB4_34;

$L__BB4_30:
	ld.global.u64 	%rd135, [%rd4];
	setp.eq.s64 	%p27, %rd135, 0;
	selp.b64 	%rd136, %rd2, %rd3, %p27;
	ld.global.u64 	%rd137, [%rd136];
	shl.b64 	%rd138, %rd150, 3;
	add.s64 	%rd139, %rd1, %rd138;
	st.global.u64 	[%rd139], %rd137;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p28, %rd150, %rd54;
	@%p28 bra 	$L__BB4_30;

$L__BB4_34:
	ret;

}
	// .globl	where_u32_f32
.visible .entry where_u32_f32(
	.param .u64 where_u32_f32_param_0,
	.param .u64 where_u32_f32_param_1,
	.param .u64 where_u32_f32_param_2,
	.param .u64 where_u32_f32_param_3,
	.param .u64 where_u32_f32_param_4,
	.param .u64 where_u32_f32_param_5,
	.param .u64 where_u32_f32_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<153>;


	ld.param.u64 	%rd54, [where_u32_f32_param_0];
	ld.param.u64 	%rd55, [where_u32_f32_param_1];
	ld.param.u64 	%rd59, [where_u32_f32_param_2];
	ld.param.u64 	%rd60, [where_u32_f32_param_3];
	ld.param.u64 	%rd56, [where_u32_f32_param_4];
	ld.param.u64 	%rd57, [where_u32_f32_param_5];
	ld.param.u64 	%rd58, [where_u32_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB5_13;

	mov.u64 	%rd141, 1;
	mov.u32 	%r75, 0;

$L__BB5_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB5_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd141, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB5_13;

$L__BB5_4:
	mul.lo.s64 	%rd141, %rd10, %rd141;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd69, %r75;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB5_2;

	mov.u64 	%rd142, 1;
	mov.u32 	%r76, 0;

$L__BB5_6:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB5_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd142, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB5_13;

$L__BB5_8:
	mul.lo.s64 	%rd142, %rd14, %rd142;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd78, %r76;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB5_6;

	mov.u64 	%rd143, 1;
	mov.u32 	%r77, 0;

$L__BB5_10:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB5_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd143, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB5_13;

$L__BB5_12:
	mul.lo.s64 	%rd143, %rd18, %rd143;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd87, %r77;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB5_10;

$L__BB5_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd144, %r78;
	@%p32 bra 	$L__BB5_31;
	bra.uni 	$L__BB5_14;

$L__BB5_31:
	setp.ge.u64 	%p29, %rd144, %rd54;
	@%p29 bra 	$L__BB5_34;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB5_33:
	shl.b64 	%rd136, %rd144, 2;
	add.s64 	%rd137, %rd4, %rd136;
	ld.global.u32 	%r74, [%rd137];
	setp.eq.s32 	%p30, %r74, 0;
	selp.b64 	%rd138, %rd2, %rd3, %p30;
	add.s64 	%rd139, %rd138, %rd136;
	ld.global.f32 	%f3, [%rd139];
	add.s64 	%rd140, %rd1, %rd136;
	st.global.f32 	[%rd140], %f3;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd144, %r78;
	setp.lt.u64 	%p31, %rd144, %rd54;
	@%p31 bra 	$L__BB5_33;
	bra.uni 	$L__BB5_34;

$L__BB5_14:
	setp.ge.u64 	%p17, %rd144, %rd54;
	@%p17 bra 	$L__BB5_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB5_30;

$L__BB5_16:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB5_17:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r80;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB5_19;

	div.u64 	%rd145, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd145, %rd24;
	sub.s64 	%rd146, %rd22, %rd93;
	bra.uni 	$L__BB5_20;

$L__BB5_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd145, %r49;
	cvt.u64.u32 	%rd146, %r51;

$L__BB5_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd146;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd145;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd98, %r79;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p20 bra 	$L__BB5_17;

$L__BB5_21:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r83;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB5_23;

	div.u64 	%rd147, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd147, %rd33;
	sub.s64 	%rd148, %rd31, %rd104;
	bra.uni 	$L__BB5_24;

$L__BB5_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd147, %r58;
	cvt.u64.u32 	%rd148, %r60;

$L__BB5_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd148;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd147;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd109, %r82;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p22 bra 	$L__BB5_21;

$L__BB5_25:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r86;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB5_27;

	div.u64 	%rd149, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd149, %rd42;
	sub.s64 	%rd150, %rd40, %rd115;
	bra.uni 	$L__BB5_28;

$L__BB5_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd149, %r67;
	cvt.u64.u32 	%rd150, %r69;

$L__BB5_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd150;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd149;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd120, %r85;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB5_25;

	mul.wide.u32 	%rd121, %r81, 4;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u32 	%r71, [%rd122];
	setp.eq.s32 	%p25, %r71, 0;
	mul.wide.u32 	%rd124, %r84, 4;
	add.s64 	%rd125, %rd3, %rd124;
	mul.wide.u32 	%rd127, %r87, 4;
	add.s64 	%rd128, %rd2, %rd127;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.f32 	%f1, [%rd129];
	shl.b64 	%rd131, %rd144, 2;
	add.s64 	%rd132, %rd1, %rd131;
	st.global.f32 	[%rd132], %f1;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd144, %r78;
	setp.lt.u64 	%p26, %rd144, %rd54;
	@%p26 bra 	$L__BB5_16;
	bra.uni 	$L__BB5_34;

$L__BB5_30:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p27, %r72, 0;
	selp.b64 	%rd133, %rd2, %rd3, %p27;
	ld.global.f32 	%f2, [%rd133];
	shl.b64 	%rd134, %rd144, 2;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.f32 	[%rd135], %f2;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd144, %r78;
	setp.lt.u64 	%p28, %rd144, %rd54;
	@%p28 bra 	$L__BB5_30;

$L__BB5_34:
	ret;

}
	// .globl	where_u32_f64
.visible .entry where_u32_f64(
	.param .u64 where_u32_f64_param_0,
	.param .u64 where_u32_f64_param_1,
	.param .u64 where_u32_f64_param_2,
	.param .u64 where_u32_f64_param_3,
	.param .u64 where_u32_f64_param_4,
	.param .u64 where_u32_f64_param_5,
	.param .u64 where_u32_f64_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b32 	%r<90>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<154>;


	ld.param.u64 	%rd54, [where_u32_f64_param_0];
	ld.param.u64 	%rd55, [where_u32_f64_param_1];
	ld.param.u64 	%rd59, [where_u32_f64_param_2];
	ld.param.u64 	%rd60, [where_u32_f64_param_3];
	ld.param.u64 	%rd56, [where_u32_f64_param_4];
	ld.param.u64 	%rd57, [where_u32_f64_param_5];
	ld.param.u64 	%rd58, [where_u32_f64_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB6_13;

	mov.u64 	%rd142, 1;
	mov.u32 	%r75, 0;

$L__BB6_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB6_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd142, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB6_13;

$L__BB6_4:
	mul.lo.s64 	%rd142, %rd10, %rd142;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd69, %r75;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB6_2;

	mov.u64 	%rd143, 1;
	mov.u32 	%r76, 0;

$L__BB6_6:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB6_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd143, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB6_13;

$L__BB6_8:
	mul.lo.s64 	%rd143, %rd14, %rd143;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd78, %r76;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB6_6;

	mov.u64 	%rd144, 1;
	mov.u32 	%r77, 0;

$L__BB6_10:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB6_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd144, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB6_13;

$L__BB6_12:
	mul.lo.s64 	%rd144, %rd18, %rd144;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd87, %r77;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB6_10;

$L__BB6_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd145, %r78;
	@%p32 bra 	$L__BB6_31;
	bra.uni 	$L__BB6_14;

$L__BB6_31:
	setp.ge.u64 	%p29, %rd145, %rd54;
	@%p29 bra 	$L__BB6_34;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB6_33:
	shl.b64 	%rd136, %rd145, 2;
	add.s64 	%rd137, %rd4, %rd136;
	ld.global.u32 	%r74, [%rd137];
	setp.eq.s32 	%p30, %r74, 0;
	selp.b64 	%rd138, %rd2, %rd3, %p30;
	shl.b64 	%rd139, %rd145, 3;
	add.s64 	%rd140, %rd138, %rd139;
	ld.global.f64 	%fd3, [%rd140];
	add.s64 	%rd141, %rd1, %rd139;
	st.global.f64 	[%rd141], %fd3;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd145, %r78;
	setp.lt.u64 	%p31, %rd145, %rd54;
	@%p31 bra 	$L__BB6_33;
	bra.uni 	$L__BB6_34;

$L__BB6_14:
	setp.ge.u64 	%p17, %rd145, %rd54;
	@%p17 bra 	$L__BB6_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB6_30;

$L__BB6_16:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB6_17:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r80;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB6_19;

	div.u64 	%rd146, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd146, %rd24;
	sub.s64 	%rd147, %rd22, %rd93;
	bra.uni 	$L__BB6_20;

$L__BB6_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd146, %r49;
	cvt.u64.u32 	%rd147, %r51;

$L__BB6_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd147;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd146;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd98, %r79;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p20 bra 	$L__BB6_17;

$L__BB6_21:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r83;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB6_23;

	div.u64 	%rd148, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd148, %rd33;
	sub.s64 	%rd149, %rd31, %rd104;
	bra.uni 	$L__BB6_24;

$L__BB6_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd148, %r58;
	cvt.u64.u32 	%rd149, %r60;

$L__BB6_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd149;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd148;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd109, %r82;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p22 bra 	$L__BB6_21;

$L__BB6_25:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r86;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB6_27;

	div.u64 	%rd150, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd150, %rd42;
	sub.s64 	%rd151, %rd40, %rd115;
	bra.uni 	$L__BB6_28;

$L__BB6_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd150, %r67;
	cvt.u64.u32 	%rd151, %r69;

$L__BB6_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd151;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd150;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd120, %r85;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB6_25;

	mul.wide.u32 	%rd121, %r81, 4;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u32 	%r71, [%rd122];
	setp.eq.s32 	%p25, %r71, 0;
	mul.wide.u32 	%rd124, %r84, 8;
	add.s64 	%rd125, %rd3, %rd124;
	mul.wide.u32 	%rd127, %r87, 8;
	add.s64 	%rd128, %rd2, %rd127;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.f64 	%fd1, [%rd129];
	shl.b64 	%rd131, %rd145, 3;
	add.s64 	%rd132, %rd1, %rd131;
	st.global.f64 	[%rd132], %fd1;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd145, %r78;
	setp.lt.u64 	%p26, %rd145, %rd54;
	@%p26 bra 	$L__BB6_16;
	bra.uni 	$L__BB6_34;

$L__BB6_30:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p27, %r72, 0;
	selp.b64 	%rd133, %rd2, %rd3, %p27;
	ld.global.f64 	%fd2, [%rd133];
	shl.b64 	%rd134, %rd145, 3;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.f64 	[%rd135], %fd2;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd145, %r78;
	setp.lt.u64 	%p28, %rd145, %rd54;
	@%p28 bra 	$L__BB6_30;

$L__BB6_34:
	ret;

}
	// .globl	where_u32_u8
.visible .entry where_u32_u8(
	.param .u64 where_u32_u8_param_0,
	.param .u64 where_u32_u8_param_1,
	.param .u64 where_u32_u8_param_2,
	.param .u64 where_u32_u8_param_3,
	.param .u64 where_u32_u8_param_4,
	.param .u64 where_u32_u8_param_5,
	.param .u64 where_u32_u8_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<151>;


	ld.param.u64 	%rd54, [where_u32_u8_param_0];
	ld.param.u64 	%rd55, [where_u32_u8_param_1];
	ld.param.u64 	%rd59, [where_u32_u8_param_2];
	ld.param.u64 	%rd60, [where_u32_u8_param_3];
	ld.param.u64 	%rd56, [where_u32_u8_param_4];
	ld.param.u64 	%rd57, [where_u32_u8_param_5];
	ld.param.u64 	%rd58, [where_u32_u8_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB7_13;

	mov.u64 	%rd139, 1;
	mov.u32 	%r75, 0;

$L__BB7_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB7_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd139, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB7_13;

$L__BB7_4:
	mul.lo.s64 	%rd139, %rd10, %rd139;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd69, %r75;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB7_2;

	mov.u64 	%rd140, 1;
	mov.u32 	%r76, 0;

$L__BB7_6:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB7_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd140, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB7_13;

$L__BB7_8:
	mul.lo.s64 	%rd140, %rd14, %rd140;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd78, %r76;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB7_6;

	mov.u64 	%rd141, 1;
	mov.u32 	%r77, 0;

$L__BB7_10:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB7_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd141, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB7_13;

$L__BB7_12:
	mul.lo.s64 	%rd141, %rd18, %rd141;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd87, %r77;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB7_10;

$L__BB7_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd142, %r78;
	@%p32 bra 	$L__BB7_31;
	bra.uni 	$L__BB7_14;

$L__BB7_31:
	setp.ge.u64 	%p29, %rd142, %rd54;
	@%p29 bra 	$L__BB7_34;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB7_33:
	shl.b64 	%rd134, %rd142, 2;
	add.s64 	%rd135, %rd4, %rd134;
	ld.global.u32 	%r74, [%rd135];
	setp.eq.s32 	%p30, %r74, 0;
	selp.b64 	%rd136, %rd2, %rd3, %p30;
	add.s64 	%rd137, %rd136, %rd142;
	ld.global.u8 	%rs3, [%rd137];
	add.s64 	%rd138, %rd1, %rd142;
	st.global.u8 	[%rd138], %rs3;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd142, %r78;
	setp.lt.u64 	%p31, %rd142, %rd54;
	@%p31 bra 	$L__BB7_33;
	bra.uni 	$L__BB7_34;

$L__BB7_14:
	setp.ge.u64 	%p17, %rd142, %rd54;
	@%p17 bra 	$L__BB7_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB7_30;

$L__BB7_16:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB7_17:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r80;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB7_19;

	div.u64 	%rd143, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd143, %rd24;
	sub.s64 	%rd144, %rd22, %rd93;
	bra.uni 	$L__BB7_20;

$L__BB7_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd143, %r49;
	cvt.u64.u32 	%rd144, %r51;

$L__BB7_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd144;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd143;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd98, %r79;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p20 bra 	$L__BB7_17;

$L__BB7_21:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r83;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB7_23;

	div.u64 	%rd145, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd145, %rd33;
	sub.s64 	%rd146, %rd31, %rd104;
	bra.uni 	$L__BB7_24;

$L__BB7_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd145, %r58;
	cvt.u64.u32 	%rd146, %r60;

$L__BB7_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd146;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd145;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd109, %r82;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p22 bra 	$L__BB7_21;

$L__BB7_25:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r86;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB7_27;

	div.u64 	%rd147, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd147, %rd42;
	sub.s64 	%rd148, %rd40, %rd115;
	bra.uni 	$L__BB7_28;

$L__BB7_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd147, %r67;
	cvt.u64.u32 	%rd148, %r69;

$L__BB7_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd148;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd147;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd120, %r85;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB7_25;

	mul.wide.u32 	%rd121, %r81, 4;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u32 	%r71, [%rd122];
	setp.eq.s32 	%p25, %r71, 0;
	cvt.u64.u32 	%rd123, %r84;
	add.s64 	%rd125, %rd3, %rd123;
	cvt.u64.u32 	%rd126, %r87;
	add.s64 	%rd128, %rd2, %rd126;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.u8 	%rs1, [%rd129];
	add.s64 	%rd131, %rd1, %rd142;
	st.global.u8 	[%rd131], %rs1;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd142, %r78;
	setp.lt.u64 	%p26, %rd142, %rd54;
	@%p26 bra 	$L__BB7_16;
	bra.uni 	$L__BB7_34;

$L__BB7_30:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p27, %r72, 0;
	selp.b64 	%rd132, %rd2, %rd3, %p27;
	ld.global.u8 	%rs2, [%rd132];
	add.s64 	%rd133, %rd1, %rd142;
	st.global.u8 	[%rd133], %rs2;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd142, %r78;
	setp.lt.u64 	%p28, %rd142, %rd54;
	@%p28 bra 	$L__BB7_30;

$L__BB7_34:
	ret;

}
	// .globl	where_u32_u32
.visible .entry where_u32_u32(
	.param .u64 where_u32_u32_param_0,
	.param .u64 where_u32_u32_param_1,
	.param .u64 where_u32_u32_param_2,
	.param .u64 where_u32_u32_param_3,
	.param .u64 where_u32_u32_param_4,
	.param .u64 where_u32_u32_param_5,
	.param .u64 where_u32_u32_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b32 	%r<93>;
	.reg .b64 	%rd<153>;


	ld.param.u64 	%rd54, [where_u32_u32_param_0];
	ld.param.u64 	%rd55, [where_u32_u32_param_1];
	ld.param.u64 	%rd59, [where_u32_u32_param_2];
	ld.param.u64 	%rd60, [where_u32_u32_param_3];
	ld.param.u64 	%rd56, [where_u32_u32_param_4];
	ld.param.u64 	%rd57, [where_u32_u32_param_5];
	ld.param.u64 	%rd58, [where_u32_u32_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB8_13;

	mov.u64 	%rd141, 1;
	mov.u32 	%r78, 0;

$L__BB8_2:
	not.b32 	%r36, %r78;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB8_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd141, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB8_13;

$L__BB8_4:
	mul.lo.s64 	%rd141, %rd10, %rd141;
	add.s32 	%r78, %r78, 1;
	cvt.u64.u32 	%rd69, %r78;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB8_2;

	mov.u64 	%rd142, 1;
	mov.u32 	%r79, 0;

$L__BB8_6:
	not.b32 	%r38, %r79;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB8_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd142, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB8_13;

$L__BB8_8:
	mul.lo.s64 	%rd142, %rd14, %rd142;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd78, %r79;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB8_6;

	mov.u64 	%rd143, 1;
	mov.u32 	%r80, 0;

$L__BB8_10:
	not.b32 	%r40, %r80;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB8_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd143, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB8_13;

$L__BB8_12:
	mul.lo.s64 	%rd143, %rd18, %rd143;
	add.s32 	%r80, %r80, 1;
	cvt.u64.u32 	%rd87, %r80;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB8_10;

$L__BB8_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r81, %r41, %r7, %r42;
	cvt.u64.u32 	%rd144, %r81;
	@%p32 bra 	$L__BB8_31;
	bra.uni 	$L__BB8_14;

$L__BB8_31:
	setp.ge.u64 	%p29, %rd144, %rd54;
	@%p29 bra 	$L__BB8_34;

	mov.u32 	%r75, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r75;

$L__BB8_33:
	shl.b64 	%rd136, %rd144, 2;
	add.s64 	%rd137, %rd4, %rd136;
	ld.global.u32 	%r76, [%rd137];
	setp.eq.s32 	%p30, %r76, 0;
	selp.b64 	%rd138, %rd2, %rd3, %p30;
	add.s64 	%rd139, %rd138, %rd136;
	ld.global.u32 	%r77, [%rd139];
	add.s64 	%rd140, %rd1, %rd136;
	st.global.u32 	[%rd140], %r77;
	add.s32 	%r81, %r81, %r32;
	cvt.u64.u32 	%rd144, %r81;
	setp.lt.u64 	%p31, %rd144, %rd54;
	@%p31 bra 	$L__BB8_33;
	bra.uni 	$L__BB8_34;

$L__BB8_14:
	setp.ge.u64 	%p17, %rd144, %rd54;
	@%p17 bra 	$L__BB8_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB8_30;

$L__BB8_16:
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r81;
	mov.u32 	%r84, %r82;

$L__BB8_17:
	not.b32 	%r46, %r82;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r83;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB8_19;

	div.u64 	%rd145, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd145, %rd24;
	sub.s64 	%rd146, %rd22, %rd93;
	bra.uni 	$L__BB8_20;

$L__BB8_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd145, %r49;
	cvt.u64.u32 	%rd146, %r51;

$L__BB8_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd146;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r84, %r84, %r54;
	cvt.u32.u64 	%r83, %rd145;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd98, %r82;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r81;
	mov.u32 	%r87, %r85;
	@%p20 bra 	$L__BB8_17;

$L__BB8_21:
	not.b32 	%r55, %r85;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r86;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB8_23;

	div.u64 	%rd147, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd147, %rd33;
	sub.s64 	%rd148, %rd31, %rd104;
	bra.uni 	$L__BB8_24;

$L__BB8_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd147, %r58;
	cvt.u64.u32 	%rd148, %r60;

$L__BB8_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd148;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r87, %r87, %r63;
	cvt.u32.u64 	%r86, %rd147;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd109, %r85;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r88, 0;
	mov.u32 	%r89, %r81;
	mov.u32 	%r90, %r88;
	@%p22 bra 	$L__BB8_21;

$L__BB8_25:
	not.b32 	%r64, %r88;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r89;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB8_27;

	div.u64 	%rd149, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd149, %rd42;
	sub.s64 	%rd150, %rd40, %rd115;
	bra.uni 	$L__BB8_28;

$L__BB8_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd149, %r67;
	cvt.u64.u32 	%rd150, %r69;

$L__BB8_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd150;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r90, %r90, %r70;
	cvt.u32.u64 	%r89, %rd149;
	add.s32 	%r88, %r88, 1;
	cvt.u64.u32 	%rd120, %r88;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB8_25;

	mul.wide.u32 	%rd121, %r84, 4;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u32 	%r71, [%rd122];
	setp.eq.s32 	%p25, %r71, 0;
	mul.wide.u32 	%rd124, %r87, 4;
	add.s64 	%rd125, %rd3, %rd124;
	mul.wide.u32 	%rd127, %r90, 4;
	add.s64 	%rd128, %rd2, %rd127;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.u32 	%r72, [%rd129];
	shl.b64 	%rd131, %rd144, 2;
	add.s64 	%rd132, %rd1, %rd131;
	st.global.u32 	[%rd132], %r72;
	add.s32 	%r81, %r81, %r9;
	cvt.u64.u32 	%rd144, %r81;
	setp.lt.u64 	%p26, %rd144, %rd54;
	@%p26 bra 	$L__BB8_16;
	bra.uni 	$L__BB8_34;

$L__BB8_30:
	ld.global.u32 	%r73, [%rd4];
	setp.eq.s32 	%p27, %r73, 0;
	selp.b64 	%rd133, %rd2, %rd3, %p27;
	ld.global.u32 	%r74, [%rd133];
	shl.b64 	%rd134, %rd144, 2;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.u32 	[%rd135], %r74;
	add.s32 	%r81, %r81, %r9;
	cvt.u64.u32 	%rd144, %r81;
	setp.lt.u64 	%p28, %rd144, %rd54;
	@%p28 bra 	$L__BB8_30;

$L__BB8_34:
	ret;

}
	// .globl	where_u32_i64
.visible .entry where_u32_i64(
	.param .u64 where_u32_i64_param_0,
	.param .u64 where_u32_i64_param_1,
	.param .u64 where_u32_i64_param_2,
	.param .u64 where_u32_i64_param_3,
	.param .u64 where_u32_i64_param_4,
	.param .u64 where_u32_i64_param_5,
	.param .u64 where_u32_i64_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<157>;


	ld.param.u64 	%rd54, [where_u32_i64_param_0];
	ld.param.u64 	%rd55, [where_u32_i64_param_1];
	ld.param.u64 	%rd59, [where_u32_i64_param_2];
	ld.param.u64 	%rd60, [where_u32_i64_param_3];
	ld.param.u64 	%rd56, [where_u32_i64_param_4];
	ld.param.u64 	%rd57, [where_u32_i64_param_5];
	ld.param.u64 	%rd58, [where_u32_i64_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB9_13;

	mov.u64 	%rd145, 1;
	mov.u32 	%r75, 0;

$L__BB9_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB9_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd145, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB9_13;

$L__BB9_4:
	mul.lo.s64 	%rd145, %rd10, %rd145;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd69, %r75;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB9_2;

	mov.u64 	%rd146, 1;
	mov.u32 	%r76, 0;

$L__BB9_6:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB9_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd146, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB9_13;

$L__BB9_8:
	mul.lo.s64 	%rd146, %rd14, %rd146;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd78, %r76;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB9_6;

	mov.u64 	%rd147, 1;
	mov.u32 	%r77, 0;

$L__BB9_10:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB9_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd147, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB9_13;

$L__BB9_12:
	mul.lo.s64 	%rd147, %rd18, %rd147;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd87, %r77;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB9_10;

$L__BB9_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd148, %r78;
	@%p32 bra 	$L__BB9_31;
	bra.uni 	$L__BB9_14;

$L__BB9_31:
	setp.ge.u64 	%p29, %rd148, %rd54;
	@%p29 bra 	$L__BB9_34;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB9_33:
	shl.b64 	%rd138, %rd148, 2;
	add.s64 	%rd139, %rd4, %rd138;
	ld.global.u32 	%r74, [%rd139];
	setp.eq.s32 	%p30, %r74, 0;
	selp.b64 	%rd140, %rd2, %rd3, %p30;
	shl.b64 	%rd141, %rd148, 3;
	add.s64 	%rd142, %rd140, %rd141;
	ld.global.u64 	%rd143, [%rd142];
	add.s64 	%rd144, %rd1, %rd141;
	st.global.u64 	[%rd144], %rd143;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p31, %rd148, %rd54;
	@%p31 bra 	$L__BB9_33;
	bra.uni 	$L__BB9_34;

$L__BB9_14:
	setp.ge.u64 	%p17, %rd148, %rd54;
	@%p17 bra 	$L__BB9_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB9_30;

$L__BB9_16:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB9_17:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r80;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB9_19;

	div.u64 	%rd149, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd149, %rd24;
	sub.s64 	%rd150, %rd22, %rd93;
	bra.uni 	$L__BB9_20;

$L__BB9_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd149, %r49;
	cvt.u64.u32 	%rd150, %r51;

$L__BB9_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd150;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd149;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd98, %r79;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p20 bra 	$L__BB9_17;

$L__BB9_21:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r83;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB9_23;

	div.u64 	%rd151, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd151, %rd33;
	sub.s64 	%rd152, %rd31, %rd104;
	bra.uni 	$L__BB9_24;

$L__BB9_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd151, %r58;
	cvt.u64.u32 	%rd152, %r60;

$L__BB9_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd152;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd151;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd109, %r82;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p22 bra 	$L__BB9_21;

$L__BB9_25:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r86;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB9_27;

	div.u64 	%rd153, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd153, %rd42;
	sub.s64 	%rd154, %rd40, %rd115;
	bra.uni 	$L__BB9_28;

$L__BB9_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd153, %r67;
	cvt.u64.u32 	%rd154, %r69;

$L__BB9_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd154;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd153;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd120, %r85;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB9_25;

	mul.wide.u32 	%rd121, %r81, 4;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u32 	%r71, [%rd122];
	setp.eq.s32 	%p25, %r71, 0;
	mul.wide.u32 	%rd124, %r84, 8;
	add.s64 	%rd125, %rd3, %rd124;
	mul.wide.u32 	%rd127, %r87, 8;
	add.s64 	%rd128, %rd2, %rd127;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.u64 	%rd130, [%rd129];
	shl.b64 	%rd132, %rd148, 3;
	add.s64 	%rd133, %rd1, %rd132;
	st.global.u64 	[%rd133], %rd130;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p26, %rd148, %rd54;
	@%p26 bra 	$L__BB9_16;
	bra.uni 	$L__BB9_34;

$L__BB9_30:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p27, %r72, 0;
	selp.b64 	%rd134, %rd2, %rd3, %p27;
	ld.global.u64 	%rd135, [%rd134];
	shl.b64 	%rd136, %rd148, 3;
	add.s64 	%rd137, %rd1, %rd136;
	st.global.u64 	[%rd137], %rd135;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p28, %rd148, %rd54;
	@%p28 bra 	$L__BB9_30;

$L__BB9_34:
	ret;

}
	// .globl	where_u8_f32
.visible .entry where_u8_f32(
	.param .u64 where_u8_f32_param_0,
	.param .u64 where_u8_f32_param_1,
	.param .u64 where_u8_f32_param_2,
	.param .u64 where_u8_f32_param_3,
	.param .u64 where_u8_f32_param_4,
	.param .u64 where_u8_f32_param_5,
	.param .u64 where_u8_f32_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<4>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<153>;


	ld.param.u64 	%rd54, [where_u8_f32_param_0];
	ld.param.u64 	%rd55, [where_u8_f32_param_1];
	ld.param.u64 	%rd59, [where_u8_f32_param_2];
	ld.param.u64 	%rd60, [where_u8_f32_param_3];
	ld.param.u64 	%rd56, [where_u8_f32_param_4];
	ld.param.u64 	%rd57, [where_u8_f32_param_5];
	ld.param.u64 	%rd58, [where_u8_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB10_13;

	mov.u64 	%rd141, 1;
	mov.u32 	%r72, 0;

$L__BB10_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB10_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd141, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB10_13;

$L__BB10_4:
	mul.lo.s64 	%rd141, %rd10, %rd141;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd69, %r72;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB10_2;

	mov.u64 	%rd142, 1;
	mov.u32 	%r73, 0;

$L__BB10_6:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB10_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd142, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB10_13;

$L__BB10_8:
	mul.lo.s64 	%rd142, %rd14, %rd142;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd78, %r73;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB10_6;

	mov.u64 	%rd143, 1;
	mov.u32 	%r74, 0;

$L__BB10_10:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB10_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd143, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB10_13;

$L__BB10_12:
	mul.lo.s64 	%rd143, %rd18, %rd143;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd87, %r74;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB10_10;

$L__BB10_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd144, %r75;
	@%p32 bra 	$L__BB10_31;
	bra.uni 	$L__BB10_14;

$L__BB10_31:
	setp.ge.u64 	%p29, %rd144, %rd54;
	@%p29 bra 	$L__BB10_34;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB10_33:
	add.s64 	%rd136, %rd4, %rd144;
	ld.global.u8 	%rs3, [%rd136];
	setp.eq.s16 	%p30, %rs3, 0;
	selp.b64 	%rd137, %rd2, %rd3, %p30;
	shl.b64 	%rd138, %rd144, 2;
	add.s64 	%rd139, %rd137, %rd138;
	ld.global.f32 	%f3, [%rd139];
	add.s64 	%rd140, %rd1, %rd138;
	st.global.f32 	[%rd140], %f3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p31, %rd144, %rd54;
	@%p31 bra 	$L__BB10_33;
	bra.uni 	$L__BB10_34;

$L__BB10_14:
	setp.ge.u64 	%p17, %rd144, %rd54;
	@%p17 bra 	$L__BB10_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB10_30;

$L__BB10_16:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB10_17:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r77;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB10_19;

	div.u64 	%rd145, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd145, %rd24;
	sub.s64 	%rd146, %rd22, %rd93;
	bra.uni 	$L__BB10_20;

$L__BB10_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd145, %r49;
	cvt.u64.u32 	%rd146, %r51;

$L__BB10_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd146;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd145;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd98, %r76;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p20 bra 	$L__BB10_17;

$L__BB10_21:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r80;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB10_23;

	div.u64 	%rd147, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd147, %rd33;
	sub.s64 	%rd148, %rd31, %rd104;
	bra.uni 	$L__BB10_24;

$L__BB10_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd147, %r58;
	cvt.u64.u32 	%rd148, %r60;

$L__BB10_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd148;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd147;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd109, %r79;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p22 bra 	$L__BB10_21;

$L__BB10_25:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r83;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB10_27;

	div.u64 	%rd149, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd149, %rd42;
	sub.s64 	%rd150, %rd40, %rd115;
	bra.uni 	$L__BB10_28;

$L__BB10_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd149, %r67;
	cvt.u64.u32 	%rd150, %r69;

$L__BB10_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd150;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd149;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd120, %r82;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB10_25;

	cvt.u64.u32 	%rd121, %r78;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u8 	%rs1, [%rd122];
	setp.eq.s16 	%p25, %rs1, 0;
	mul.wide.u32 	%rd124, %r81, 4;
	add.s64 	%rd125, %rd3, %rd124;
	mul.wide.u32 	%rd127, %r84, 4;
	add.s64 	%rd128, %rd2, %rd127;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.f32 	%f1, [%rd129];
	shl.b64 	%rd131, %rd144, 2;
	add.s64 	%rd132, %rd1, %rd131;
	st.global.f32 	[%rd132], %f1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p26, %rd144, %rd54;
	@%p26 bra 	$L__BB10_16;
	bra.uni 	$L__BB10_34;

$L__BB10_30:
	ld.global.u8 	%rs2, [%rd4];
	setp.eq.s16 	%p27, %rs2, 0;
	selp.b64 	%rd133, %rd2, %rd3, %p27;
	ld.global.f32 	%f2, [%rd133];
	shl.b64 	%rd134, %rd144, 2;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.f32 	[%rd135], %f2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p28, %rd144, %rd54;
	@%p28 bra 	$L__BB10_30;

$L__BB10_34:
	ret;

}
	// .globl	where_u8_f64
.visible .entry where_u8_f64(
	.param .u64 where_u8_f64_param_0,
	.param .u64 where_u8_f64_param_1,
	.param .u64 where_u8_f64_param_2,
	.param .u64 where_u8_f64_param_3,
	.param .u64 where_u8_f64_param_4,
	.param .u64 where_u8_f64_param_5,
	.param .u64 where_u8_f64_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<87>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<153>;


	ld.param.u64 	%rd54, [where_u8_f64_param_0];
	ld.param.u64 	%rd55, [where_u8_f64_param_1];
	ld.param.u64 	%rd59, [where_u8_f64_param_2];
	ld.param.u64 	%rd60, [where_u8_f64_param_3];
	ld.param.u64 	%rd56, [where_u8_f64_param_4];
	ld.param.u64 	%rd57, [where_u8_f64_param_5];
	ld.param.u64 	%rd58, [where_u8_f64_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB11_13;

	mov.u64 	%rd141, 1;
	mov.u32 	%r72, 0;

$L__BB11_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB11_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd141, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB11_13;

$L__BB11_4:
	mul.lo.s64 	%rd141, %rd10, %rd141;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd69, %r72;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB11_2;

	mov.u64 	%rd142, 1;
	mov.u32 	%r73, 0;

$L__BB11_6:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB11_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd142, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB11_13;

$L__BB11_8:
	mul.lo.s64 	%rd142, %rd14, %rd142;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd78, %r73;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB11_6;

	mov.u64 	%rd143, 1;
	mov.u32 	%r74, 0;

$L__BB11_10:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB11_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd143, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB11_13;

$L__BB11_12:
	mul.lo.s64 	%rd143, %rd18, %rd143;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd87, %r74;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB11_10;

$L__BB11_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd144, %r75;
	@%p32 bra 	$L__BB11_31;
	bra.uni 	$L__BB11_14;

$L__BB11_31:
	setp.ge.u64 	%p29, %rd144, %rd54;
	@%p29 bra 	$L__BB11_34;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB11_33:
	add.s64 	%rd136, %rd4, %rd144;
	ld.global.u8 	%rs3, [%rd136];
	setp.eq.s16 	%p30, %rs3, 0;
	selp.b64 	%rd137, %rd2, %rd3, %p30;
	shl.b64 	%rd138, %rd144, 3;
	add.s64 	%rd139, %rd137, %rd138;
	ld.global.f64 	%fd3, [%rd139];
	add.s64 	%rd140, %rd1, %rd138;
	st.global.f64 	[%rd140], %fd3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p31, %rd144, %rd54;
	@%p31 bra 	$L__BB11_33;
	bra.uni 	$L__BB11_34;

$L__BB11_14:
	setp.ge.u64 	%p17, %rd144, %rd54;
	@%p17 bra 	$L__BB11_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB11_30;

$L__BB11_16:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB11_17:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r77;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB11_19;

	div.u64 	%rd145, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd145, %rd24;
	sub.s64 	%rd146, %rd22, %rd93;
	bra.uni 	$L__BB11_20;

$L__BB11_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd145, %r49;
	cvt.u64.u32 	%rd146, %r51;

$L__BB11_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd146;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd145;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd98, %r76;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p20 bra 	$L__BB11_17;

$L__BB11_21:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r80;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB11_23;

	div.u64 	%rd147, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd147, %rd33;
	sub.s64 	%rd148, %rd31, %rd104;
	bra.uni 	$L__BB11_24;

$L__BB11_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd147, %r58;
	cvt.u64.u32 	%rd148, %r60;

$L__BB11_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd148;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd147;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd109, %r79;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p22 bra 	$L__BB11_21;

$L__BB11_25:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r83;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB11_27;

	div.u64 	%rd149, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd149, %rd42;
	sub.s64 	%rd150, %rd40, %rd115;
	bra.uni 	$L__BB11_28;

$L__BB11_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd149, %r67;
	cvt.u64.u32 	%rd150, %r69;

$L__BB11_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd150;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd149;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd120, %r82;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB11_25;

	cvt.u64.u32 	%rd121, %r78;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u8 	%rs1, [%rd122];
	setp.eq.s16 	%p25, %rs1, 0;
	mul.wide.u32 	%rd124, %r81, 8;
	add.s64 	%rd125, %rd3, %rd124;
	mul.wide.u32 	%rd127, %r84, 8;
	add.s64 	%rd128, %rd2, %rd127;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.f64 	%fd1, [%rd129];
	shl.b64 	%rd131, %rd144, 3;
	add.s64 	%rd132, %rd1, %rd131;
	st.global.f64 	[%rd132], %fd1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p26, %rd144, %rd54;
	@%p26 bra 	$L__BB11_16;
	bra.uni 	$L__BB11_34;

$L__BB11_30:
	ld.global.u8 	%rs2, [%rd4];
	setp.eq.s16 	%p27, %rs2, 0;
	selp.b64 	%rd133, %rd2, %rd3, %p27;
	ld.global.f64 	%fd2, [%rd133];
	shl.b64 	%rd134, %rd144, 3;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.f64 	[%rd135], %fd2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p28, %rd144, %rd54;
	@%p28 bra 	$L__BB11_30;

$L__BB11_34:
	ret;

}
	// .globl	where_u8_u8
.visible .entry where_u8_u8(
	.param .u64 where_u8_u8_param_0,
	.param .u64 where_u8_u8_param_1,
	.param .u64 where_u8_u8_param_2,
	.param .u64 where_u8_u8_param_3,
	.param .u64 where_u8_u8_param_4,
	.param .u64 where_u8_u8_param_5,
	.param .u64 where_u8_u8_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<150>;


	ld.param.u64 	%rd54, [where_u8_u8_param_0];
	ld.param.u64 	%rd55, [where_u8_u8_param_1];
	ld.param.u64 	%rd59, [where_u8_u8_param_2];
	ld.param.u64 	%rd60, [where_u8_u8_param_3];
	ld.param.u64 	%rd56, [where_u8_u8_param_4];
	ld.param.u64 	%rd57, [where_u8_u8_param_5];
	ld.param.u64 	%rd58, [where_u8_u8_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB12_13;

	mov.u64 	%rd138, 1;
	mov.u32 	%r72, 0;

$L__BB12_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB12_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd138, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB12_13;

$L__BB12_4:
	mul.lo.s64 	%rd138, %rd10, %rd138;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd69, %r72;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB12_2;

	mov.u64 	%rd139, 1;
	mov.u32 	%r73, 0;

$L__BB12_6:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB12_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd139, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB12_13;

$L__BB12_8:
	mul.lo.s64 	%rd139, %rd14, %rd139;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd78, %r73;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB12_6;

	mov.u64 	%rd140, 1;
	mov.u32 	%r74, 0;

$L__BB12_10:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB12_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd140, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB12_13;

$L__BB12_12:
	mul.lo.s64 	%rd140, %rd18, %rd140;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd87, %r74;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB12_10;

$L__BB12_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd141, %r75;
	@%p32 bra 	$L__BB12_31;
	bra.uni 	$L__BB12_14;

$L__BB12_31:
	setp.ge.u64 	%p29, %rd141, %rd54;
	@%p29 bra 	$L__BB12_34;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB12_33:
	add.s64 	%rd134, %rd4, %rd141;
	ld.global.u8 	%rs5, [%rd134];
	setp.eq.s16 	%p30, %rs5, 0;
	selp.b64 	%rd135, %rd2, %rd3, %p30;
	add.s64 	%rd136, %rd135, %rd141;
	ld.global.u8 	%rs6, [%rd136];
	add.s64 	%rd137, %rd1, %rd141;
	st.global.u8 	[%rd137], %rs6;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd141, %r75;
	setp.lt.u64 	%p31, %rd141, %rd54;
	@%p31 bra 	$L__BB12_33;
	bra.uni 	$L__BB12_34;

$L__BB12_14:
	setp.ge.u64 	%p17, %rd141, %rd54;
	@%p17 bra 	$L__BB12_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB12_30;

$L__BB12_16:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB12_17:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r77;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB12_19;

	div.u64 	%rd142, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd142, %rd24;
	sub.s64 	%rd143, %rd22, %rd93;
	bra.uni 	$L__BB12_20;

$L__BB12_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd142, %r49;
	cvt.u64.u32 	%rd143, %r51;

$L__BB12_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd143;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd142;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd98, %r76;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p20 bra 	$L__BB12_17;

$L__BB12_21:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r80;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB12_23;

	div.u64 	%rd144, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd144, %rd33;
	sub.s64 	%rd145, %rd31, %rd104;
	bra.uni 	$L__BB12_24;

$L__BB12_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd144, %r58;
	cvt.u64.u32 	%rd145, %r60;

$L__BB12_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd145;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd144;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd109, %r79;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p22 bra 	$L__BB12_21;

$L__BB12_25:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r83;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB12_27;

	div.u64 	%rd146, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd146, %rd42;
	sub.s64 	%rd147, %rd40, %rd115;
	bra.uni 	$L__BB12_28;

$L__BB12_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd146, %r67;
	cvt.u64.u32 	%rd147, %r69;

$L__BB12_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd147;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd146;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd120, %r82;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB12_25;

	cvt.u64.u32 	%rd121, %r78;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u8 	%rs1, [%rd122];
	setp.eq.s16 	%p25, %rs1, 0;
	cvt.u64.u32 	%rd123, %r81;
	add.s64 	%rd125, %rd3, %rd123;
	cvt.u64.u32 	%rd126, %r84;
	add.s64 	%rd128, %rd2, %rd126;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.u8 	%rs2, [%rd129];
	add.s64 	%rd131, %rd1, %rd141;
	st.global.u8 	[%rd131], %rs2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd141, %r75;
	setp.lt.u64 	%p26, %rd141, %rd54;
	@%p26 bra 	$L__BB12_16;
	bra.uni 	$L__BB12_34;

$L__BB12_30:
	ld.global.u8 	%rs3, [%rd4];
	setp.eq.s16 	%p27, %rs3, 0;
	selp.b64 	%rd132, %rd2, %rd3, %p27;
	ld.global.u8 	%rs4, [%rd132];
	add.s64 	%rd133, %rd1, %rd141;
	st.global.u8 	[%rd133], %rs4;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd141, %r75;
	setp.lt.u64 	%p28, %rd141, %rd54;
	@%p28 bra 	$L__BB12_30;

$L__BB12_34:
	ret;

}
	// .globl	where_u8_u32
.visible .entry where_u8_u32(
	.param .u64 where_u8_u32_param_0,
	.param .u64 where_u8_u32_param_1,
	.param .u64 where_u8_u32_param_2,
	.param .u64 where_u8_u32_param_3,
	.param .u64 where_u8_u32_param_4,
	.param .u64 where_u8_u32_param_5,
	.param .u64 where_u8_u32_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<153>;


	ld.param.u64 	%rd54, [where_u8_u32_param_0];
	ld.param.u64 	%rd55, [where_u8_u32_param_1];
	ld.param.u64 	%rd59, [where_u8_u32_param_2];
	ld.param.u64 	%rd60, [where_u8_u32_param_3];
	ld.param.u64 	%rd56, [where_u8_u32_param_4];
	ld.param.u64 	%rd57, [where_u8_u32_param_5];
	ld.param.u64 	%rd58, [where_u8_u32_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB13_13;

	mov.u64 	%rd141, 1;
	mov.u32 	%r75, 0;

$L__BB13_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB13_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd141, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB13_13;

$L__BB13_4:
	mul.lo.s64 	%rd141, %rd10, %rd141;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd69, %r75;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB13_2;

	mov.u64 	%rd142, 1;
	mov.u32 	%r76, 0;

$L__BB13_6:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB13_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd142, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB13_13;

$L__BB13_8:
	mul.lo.s64 	%rd142, %rd14, %rd142;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd78, %r76;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB13_6;

	mov.u64 	%rd143, 1;
	mov.u32 	%r77, 0;

$L__BB13_10:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB13_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd143, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB13_13;

$L__BB13_12:
	mul.lo.s64 	%rd143, %rd18, %rd143;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd87, %r77;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB13_10;

$L__BB13_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd144, %r78;
	@%p32 bra 	$L__BB13_31;
	bra.uni 	$L__BB13_14;

$L__BB13_31:
	setp.ge.u64 	%p29, %rd144, %rd54;
	@%p29 bra 	$L__BB13_34;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB13_33:
	add.s64 	%rd136, %rd4, %rd144;
	ld.global.u8 	%rs3, [%rd136];
	setp.eq.s16 	%p30, %rs3, 0;
	selp.b64 	%rd137, %rd2, %rd3, %p30;
	shl.b64 	%rd138, %rd144, 2;
	add.s64 	%rd139, %rd137, %rd138;
	ld.global.u32 	%r74, [%rd139];
	add.s64 	%rd140, %rd1, %rd138;
	st.global.u32 	[%rd140], %r74;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd144, %r78;
	setp.lt.u64 	%p31, %rd144, %rd54;
	@%p31 bra 	$L__BB13_33;
	bra.uni 	$L__BB13_34;

$L__BB13_14:
	setp.ge.u64 	%p17, %rd144, %rd54;
	@%p17 bra 	$L__BB13_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB13_30;

$L__BB13_16:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB13_17:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r80;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB13_19;

	div.u64 	%rd145, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd145, %rd24;
	sub.s64 	%rd146, %rd22, %rd93;
	bra.uni 	$L__BB13_20;

$L__BB13_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd145, %r49;
	cvt.u64.u32 	%rd146, %r51;

$L__BB13_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd146;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd145;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd98, %r79;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p20 bra 	$L__BB13_17;

$L__BB13_21:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r83;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB13_23;

	div.u64 	%rd147, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd147, %rd33;
	sub.s64 	%rd148, %rd31, %rd104;
	bra.uni 	$L__BB13_24;

$L__BB13_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd147, %r58;
	cvt.u64.u32 	%rd148, %r60;

$L__BB13_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd148;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd147;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd109, %r82;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p22 bra 	$L__BB13_21;

$L__BB13_25:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r86;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB13_27;

	div.u64 	%rd149, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd149, %rd42;
	sub.s64 	%rd150, %rd40, %rd115;
	bra.uni 	$L__BB13_28;

$L__BB13_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd149, %r67;
	cvt.u64.u32 	%rd150, %r69;

$L__BB13_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd150;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd149;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd120, %r85;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB13_25;

	cvt.u64.u32 	%rd121, %r81;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u8 	%rs1, [%rd122];
	setp.eq.s16 	%p25, %rs1, 0;
	mul.wide.u32 	%rd124, %r84, 4;
	add.s64 	%rd125, %rd3, %rd124;
	mul.wide.u32 	%rd127, %r87, 4;
	add.s64 	%rd128, %rd2, %rd127;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.u32 	%r71, [%rd129];
	shl.b64 	%rd131, %rd144, 2;
	add.s64 	%rd132, %rd1, %rd131;
	st.global.u32 	[%rd132], %r71;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd144, %r78;
	setp.lt.u64 	%p26, %rd144, %rd54;
	@%p26 bra 	$L__BB13_16;
	bra.uni 	$L__BB13_34;

$L__BB13_30:
	ld.global.u8 	%rs2, [%rd4];
	setp.eq.s16 	%p27, %rs2, 0;
	selp.b64 	%rd133, %rd2, %rd3, %p27;
	ld.global.u32 	%r72, [%rd133];
	shl.b64 	%rd134, %rd144, 2;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.u32 	[%rd135], %r72;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd144, %r78;
	setp.lt.u64 	%p28, %rd144, %rd54;
	@%p28 bra 	$L__BB13_30;

$L__BB13_34:
	ret;

}
	// .globl	where_u8_i64
.visible .entry where_u8_i64(
	.param .u64 where_u8_i64_param_0,
	.param .u64 where_u8_i64_param_1,
	.param .u64 where_u8_i64_param_2,
	.param .u64 where_u8_i64_param_3,
	.param .u64 where_u8_i64_param_4,
	.param .u64 where_u8_i64_param_5,
	.param .u64 where_u8_i64_param_6
)
{
	.reg .pred 	%p<33>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<156>;


	ld.param.u64 	%rd54, [where_u8_i64_param_0];
	ld.param.u64 	%rd55, [where_u8_i64_param_1];
	ld.param.u64 	%rd59, [where_u8_i64_param_2];
	ld.param.u64 	%rd60, [where_u8_i64_param_3];
	ld.param.u64 	%rd56, [where_u8_i64_param_4];
	ld.param.u64 	%rd57, [where_u8_i64_param_5];
	ld.param.u64 	%rd58, [where_u8_i64_param_6];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd60;
	cvta.to.global.u64 	%rd5, %rd59;
	shl.b64 	%rd6, %rd55, 1;
	mul.lo.s64 	%rd7, %rd55, 3;
	setp.eq.s64 	%p3, %rd55, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p32, %p2;
	@%p3 bra 	$L__BB14_13;

	mov.u64 	%rd144, 1;
	mov.u32 	%r72, 0;

$L__BB14_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd62, %r36;
	add.s64 	%rd63, %rd62, %rd55;
	shl.b64 	%rd64, %rd63, 3;
	and.b64  	%rd65, %rd64, 34359738360;
	add.s64 	%rd9, %rd5, %rd65;
	ld.global.u64 	%rd10, [%rd9];
	setp.lt.u64 	%p4, %rd10, 2;
	@%p4 bra 	$L__BB14_4;

	shl.b64 	%rd66, %rd55, 3;
	add.s64 	%rd67, %rd9, %rd66;
	ld.global.u64 	%rd68, [%rd67];
	setp.ne.s64 	%p6, %rd144, %rd68;
	mov.pred 	%p32, 0;
	@%p6 bra 	$L__BB14_13;

$L__BB14_4:
	mul.lo.s64 	%rd144, %rd10, %rd144;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd69, %r72;
	setp.lt.u64 	%p7, %rd69, %rd55;
	@%p7 bra 	$L__BB14_2;

	mov.u64 	%rd145, 1;
	mov.u32 	%r73, 0;

$L__BB14_6:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd71, %r38;
	add.s64 	%rd72, %rd71, %rd55;
	shl.b64 	%rd73, %rd72, 3;
	and.b64  	%rd74, %rd73, 34359738360;
	add.s64 	%rd13, %rd5, %rd74;
	ld.global.u64 	%rd14, [%rd13];
	setp.lt.u64 	%p8, %rd14, 2;
	@%p8 bra 	$L__BB14_8;

	shl.b64 	%rd75, %rd7, 3;
	add.s64 	%rd76, %rd13, %rd75;
	ld.global.u64 	%rd77, [%rd76];
	setp.ne.s64 	%p10, %rd145, %rd77;
	mov.pred 	%p32, 0;
	@%p10 bra 	$L__BB14_13;

$L__BB14_8:
	mul.lo.s64 	%rd145, %rd14, %rd145;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd78, %r73;
	setp.lt.u64 	%p11, %rd78, %rd55;
	@%p11 bra 	$L__BB14_6;

	mov.u64 	%rd146, 1;
	mov.u32 	%r74, 0;

$L__BB14_10:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd80, %r40;
	add.s64 	%rd81, %rd80, %rd55;
	shl.b64 	%rd82, %rd81, 3;
	and.b64  	%rd83, %rd82, 34359738360;
	add.s64 	%rd17, %rd5, %rd83;
	ld.global.u64 	%rd18, [%rd17];
	setp.lt.u64 	%p12, %rd18, 2;
	@%p12 bra 	$L__BB14_12;

	shl.b64 	%rd84, %rd6, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p14, %rd146, %rd86;
	mov.pred 	%p32, 0;
	@%p14 bra 	$L__BB14_13;

$L__BB14_12:
	mul.lo.s64 	%rd146, %rd18, %rd146;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd87, %r74;
	setp.lt.u64 	%p16, %rd87, %rd55;
	mov.pred 	%p32, %p2;
	@%p16 bra 	$L__BB14_10;

$L__BB14_13:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd147, %r75;
	@%p32 bra 	$L__BB14_31;
	bra.uni 	$L__BB14_14;

$L__BB14_31:
	setp.ge.u64 	%p29, %rd147, %rd54;
	@%p29 bra 	$L__BB14_34;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB14_33:
	add.s64 	%rd138, %rd4, %rd147;
	ld.global.u8 	%rs3, [%rd138];
	setp.eq.s16 	%p30, %rs3, 0;
	selp.b64 	%rd139, %rd2, %rd3, %p30;
	shl.b64 	%rd140, %rd147, 3;
	add.s64 	%rd141, %rd139, %rd140;
	ld.global.u64 	%rd142, [%rd141];
	add.s64 	%rd143, %rd1, %rd140;
	st.global.u64 	[%rd143], %rd142;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p31, %rd147, %rd54;
	@%p31 bra 	$L__BB14_33;
	bra.uni 	$L__BB14_34;

$L__BB14_14:
	setp.ge.u64 	%p17, %rd147, %rd54;
	@%p17 bra 	$L__BB14_34;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB14_30;

$L__BB14_16:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB14_17:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd88, %r46;
	add.s64 	%rd89, %rd88, %rd55;
	cvt.u64.u32 	%rd22, %r77;
	shl.b64 	%rd90, %rd89, 3;
	and.b64  	%rd91, %rd90, 34359738360;
	add.s64 	%rd23, %rd5, %rd91;
	ld.global.u64 	%rd24, [%rd23];
	and.b64  	%rd92, %rd24, -4294967296;
	setp.eq.s64 	%p19, %rd92, 0;
	@%p19 bra 	$L__BB14_19;

	div.u64 	%rd148, %rd22, %rd24;
	mul.lo.s64 	%rd93, %rd148, %rd24;
	sub.s64 	%rd149, %rd22, %rd93;
	bra.uni 	$L__BB14_20;

$L__BB14_19:
	cvt.u32.u64 	%r47, %rd24;
	cvt.u32.u64 	%r48, %rd22;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd148, %r49;
	cvt.u64.u32 	%rd149, %r51;

$L__BB14_20:
	shl.b64 	%rd94, %rd55, 3;
	add.s64 	%rd95, %rd23, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	mul.lo.s64 	%rd97, %rd96, %rd149;
	cvt.u32.u64 	%r54, %rd97;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd148;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd98, %r76;
	setp.lt.u64 	%p20, %rd98, %rd55;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p20 bra 	$L__BB14_17;

$L__BB14_21:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd99, %r55;
	add.s64 	%rd100, %rd99, %rd55;
	cvt.u64.u32 	%rd31, %r80;
	shl.b64 	%rd101, %rd100, 3;
	and.b64  	%rd102, %rd101, 34359738360;
	add.s64 	%rd32, %rd5, %rd102;
	ld.global.u64 	%rd33, [%rd32];
	and.b64  	%rd103, %rd33, -4294967296;
	setp.eq.s64 	%p21, %rd103, 0;
	@%p21 bra 	$L__BB14_23;

	div.u64 	%rd150, %rd31, %rd33;
	mul.lo.s64 	%rd104, %rd150, %rd33;
	sub.s64 	%rd151, %rd31, %rd104;
	bra.uni 	$L__BB14_24;

$L__BB14_23:
	cvt.u32.u64 	%r56, %rd33;
	cvt.u32.u64 	%r57, %rd31;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd150, %r58;
	cvt.u64.u32 	%rd151, %r60;

$L__BB14_24:
	shl.b64 	%rd105, %rd6, 3;
	add.s64 	%rd106, %rd32, %rd105;
	ld.global.u64 	%rd107, [%rd106];
	mul.lo.s64 	%rd108, %rd107, %rd151;
	cvt.u32.u64 	%r63, %rd108;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd150;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd109, %r79;
	setp.lt.u64 	%p22, %rd109, %rd55;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p22 bra 	$L__BB14_21;

$L__BB14_25:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd110, %r64;
	add.s64 	%rd111, %rd110, %rd55;
	cvt.u64.u32 	%rd40, %r83;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd41, %rd5, %rd113;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd114, %rd42, -4294967296;
	setp.eq.s64 	%p23, %rd114, 0;
	@%p23 bra 	$L__BB14_27;

	div.u64 	%rd152, %rd40, %rd42;
	mul.lo.s64 	%rd115, %rd152, %rd42;
	sub.s64 	%rd153, %rd40, %rd115;
	bra.uni 	$L__BB14_28;

$L__BB14_27:
	cvt.u32.u64 	%r65, %rd42;
	cvt.u32.u64 	%r66, %rd40;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd152, %r67;
	cvt.u64.u32 	%rd153, %r69;

$L__BB14_28:
	shl.b64 	%rd116, %rd7, 3;
	add.s64 	%rd117, %rd41, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd153;
	cvt.u32.u64 	%r70, %rd119;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd152;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd120, %r82;
	setp.lt.u64 	%p24, %rd120, %rd55;
	@%p24 bra 	$L__BB14_25;

	cvt.u64.u32 	%rd121, %r78;
	add.s64 	%rd122, %rd4, %rd121;
	ld.global.u8 	%rs1, [%rd122];
	setp.eq.s16 	%p25, %rs1, 0;
	mul.wide.u32 	%rd124, %r81, 8;
	add.s64 	%rd125, %rd3, %rd124;
	mul.wide.u32 	%rd127, %r84, 8;
	add.s64 	%rd128, %rd2, %rd127;
	selp.b64 	%rd129, %rd128, %rd125, %p25;
	ld.global.u64 	%rd130, [%rd129];
	shl.b64 	%rd132, %rd147, 3;
	add.s64 	%rd133, %rd1, %rd132;
	st.global.u64 	[%rd133], %rd130;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p26, %rd147, %rd54;
	@%p26 bra 	$L__BB14_16;
	bra.uni 	$L__BB14_34;

$L__BB14_30:
	ld.global.u8 	%rs2, [%rd4];
	setp.eq.s16 	%p27, %rs2, 0;
	selp.b64 	%rd134, %rd2, %rd3, %p27;
	ld.global.u64 	%rd135, [%rd134];
	shl.b64 	%rd136, %rd147, 3;
	add.s64 	%rd137, %rd1, %rd136;
	st.global.u64 	[%rd137], %rd135;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p28, %rd147, %rd54;
	@%p28 bra 	$L__BB14_30;

$L__BB14_34:
	ret;

}

