//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35813241
// Cuda compilation tools, release 12.9, V12.9.41
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_52
.address_size 64

	// .globl	is_i64_f32
.extern .func __assertfail
(
	.param .b64 __assertfail_param_0,
	.param .b64 __assertfail_param_1,
	.param .b32 __assertfail_param_2,
	.param .b64 __assertfail_param_3,
	.param .b64 __assertfail_param_4
)
;
.global .align 2 .b8 $str[50] = {105, 0, 100, 0, 115, 0, 91, 0, 105, 0, 100, 0, 95, 0, 105, 0, 93, 0, 32, 0, 60, 0, 32, 0, 115, 0, 114, 0, 99, 0, 95, 0, 100, 0, 105, 0, 109, 0, 95, 0, 115, 0, 105, 0, 122, 0, 101};
.global .align 2 .b8 $str$1[24] = {105, 0, 110, 0, 100, 0, 101, 0, 120, 0, 105, 0, 110, 0, 103, 0, 46, 0, 99, 0, 117};
.global .align 2 .b8 $str$2[38] = {105, 0, 100, 0, 120, 0, 32, 0, 60, 0, 32, 0, 115, 0, 114, 0, 99, 0, 95, 0, 100, 0, 105, 0, 109, 0, 95, 0, 115, 0, 105, 0, 122, 0, 101};
.global .align 2 .b8 $str$3[38] = {105, 0, 100, 0, 120, 0, 32, 0, 60, 0, 32, 0, 100, 0, 115, 0, 116, 0, 95, 0, 100, 0, 105, 0, 109, 0, 95, 0, 115, 0, 105, 0, 122, 0, 101};

.visible .entry is_i64_f32(
	.param .u64 is_i64_f32_param_0,
	.param .u64 is_i64_f32_param_1,
	.param .u64 is_i64_f32_param_2,
	.param .u64 is_i64_f32_param_3,
	.param .u64 is_i64_f32_param_4,
	.param .u64 is_i64_f32_param_5,
	.param .u64 is_i64_f32_param_6,
	.param .u64 is_i64_f32_param_7,
	.param .u64 is_i64_f32_param_8,
	.param .u64 is_i64_f32_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<139>;


	ld.param.u64 	%rd60, [is_i64_f32_param_0];
	ld.param.u64 	%rd61, [is_i64_f32_param_1];
	ld.param.u64 	%rd65, [is_i64_f32_param_2];
	ld.param.u64 	%rd66, [is_i64_f32_param_3];
	ld.param.u64 	%rd67, [is_i64_f32_param_4];
	ld.param.u64 	%rd68, [is_i64_f32_param_5];
	ld.param.u64 	%rd62, [is_i64_f32_param_7];
	ld.param.u64 	%rd63, [is_i64_f32_param_8];
	ld.param.u64 	%rd64, [is_i64_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB0_5;

	mov.u64 	%rd123, 1;
	mov.u32 	%r54, 0;

$L__BB0_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB0_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd123, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB0_5;

$L__BB0_4:
	mul.lo.s64 	%rd123, %rd7, %rd123;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd77, %r54;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB0_2;

$L__BB0_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd124, %r55;
	setp.ge.u64 	%p5, %rd124, %rd60;
	@%p5 bra 	$L__BB0_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB0_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB0_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB0_10;

	div.u64 	%rd125, %rd124, %rd10;
	bra.uni 	$L__BB0_11;

$L__BB0_10:
	cvt.u32.u64 	%r21, %rd124;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd125, %r22;

$L__BB0_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB0_13;

	div.u64 	%rd126, %rd124, %rd64;
	mul.lo.s64 	%rd80, %rd126, %rd64;
	sub.s64 	%rd127, %rd124, %rd80;
	bra.uni 	$L__BB0_14;

$L__BB0_13:
	cvt.u32.u64 	%r24, %rd124;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd126, %r25;
	cvt.u64.u32 	%rd127, %r27;

$L__BB0_14:
	or.b64  	%rd81, %rd126, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB0_16;

	rem.u64 	%rd128, %rd126, %rd63;
	bra.uni 	$L__BB0_17;

$L__BB0_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd126;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd128, %r30;

$L__BB0_17:
	shl.b64 	%rd83, %rd128, 3;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u64 	%rd129, [%rd24];
	setp.eq.s64 	%p10, %rd129, 9223372036854775807;
	shl.b64 	%rd84, %rd124, 2;
	add.s64 	%rd26, %rd1, %rd84;
	@%p10 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_18;

$L__BB0_21:
	mov.u32 	%r31, 0;
	st.global.u32 	[%rd26], %r31;
	bra.uni 	$L__BB0_22;

$L__BB0_18:
	setp.lt.u64 	%p11, %rd129, %rd62;
	@%p11 bra 	$L__BB0_20;

	mov.u64 	%rd85, $str;
	cvta.global.u64 	%rd86, %rd85;
	mov.u64 	%rd87, $str$1;
	cvta.global.u64 	%rd88, %rd87;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 0
	ld.global.u64 	%rd129, [%rd24];

$L__BB0_20:
	mul.lo.s64 	%rd89, %rd125, %rd62;
	add.s64 	%rd90, %rd129, %rd89;
	mul.lo.s64 	%rd91, %rd90, %rd64;
	add.s64 	%rd92, %rd91, %rd127;
	shl.b64 	%rd93, %rd92, 2;
	and.b64  	%rd94, %rd93, 17179869180;
	add.s64 	%rd95, %rd2, %rd94;
	ld.global.f32 	%f1, [%rd95];
	st.global.f32 	[%rd26], %f1;

$L__BB0_22:
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd124, %r55;
	setp.lt.u64 	%p12, %rd124, %rd60;
	@%p12 bra 	$L__BB0_8;
	bra.uni 	$L__BB0_44;

$L__BB0_23:
	and.b64  	%rd96, %rd10, -4294967296;
	cvt.u32.u64 	%r32, %rd10;
	cvt.u32.u64 	%r35, %rd64;

$L__BB0_24:
	setp.eq.s64 	%p13, %rd96, 0;
	@%p13 bra 	$L__BB0_26;

	div.u64 	%rd131, %rd124, %rd10;
	bra.uni 	$L__BB0_27;

$L__BB0_26:
	cvt.u32.u64 	%r33, %rd124;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd131, %r34;

$L__BB0_27:
	and.b64  	%rd97, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd97, 0;
	@%p14 bra 	$L__BB0_29;

	div.u64 	%rd132, %rd124, %rd64;
	mul.lo.s64 	%rd98, %rd132, %rd64;
	sub.s64 	%rd133, %rd124, %rd98;
	bra.uni 	$L__BB0_30;

$L__BB0_29:
	cvt.u32.u64 	%r36, %rd124;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd132, %r37;
	cvt.u64.u32 	%rd133, %r39;

$L__BB0_30:
	or.b64  	%rd99, %rd132, %rd63;
	and.b64  	%rd100, %rd99, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB0_32;

	rem.u64 	%rd134, %rd132, %rd63;
	bra.uni 	$L__BB0_33;

$L__BB0_32:
	cvt.u32.u64 	%r40, %rd63;
	cvt.u32.u64 	%r41, %rd132;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd134, %r42;

$L__BB0_33:
	shl.b64 	%rd101, %rd134, 3;
	add.s64 	%rd43, %rd3, %rd101;
	ld.global.u64 	%rd135, [%rd43];
	setp.eq.s64 	%p16, %rd135, 9223372036854775807;
	shl.b64 	%rd102, %rd124, 2;
	add.s64 	%rd45, %rd1, %rd102;
	@%p16 bra 	$L__BB0_42;
	bra.uni 	$L__BB0_34;

$L__BB0_42:
	mov.u32 	%r53, 0;
	st.global.u32 	[%rd45], %r53;
	bra.uni 	$L__BB0_43;

$L__BB0_34:
	setp.lt.u64 	%p17, %rd135, %rd62;
	@%p17 bra 	$L__BB0_36;

	mov.u64 	%rd103, $str;
	cvta.global.u64 	%rd104, %rd103;
	mov.u64 	%rd105, $str$1;
	cvta.global.u64 	%rd106, %rd105;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd104;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd106;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 1
	ld.global.u64 	%rd135, [%rd43];

$L__BB0_36:
	mul.lo.s64 	%rd107, %rd131, %rd62;
	add.s64 	%rd108, %rd135, %rd107;
	mul.lo.s64 	%rd109, %rd108, %rd64;
	add.s64 	%rd136, %rd109, %rd133;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB0_41;

$L__BB0_37:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd110, %r46;
	add.s64 	%rd111, %rd110, %rd61;
	and.b64  	%rd50, %rd136, 4294967295;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd51, %rd4, %rd113;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd114, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd114, 0;
	@%p19 bra 	$L__BB0_39;

	div.u64 	%rd136, %rd50, %rd52;
	mul.lo.s64 	%rd115, %rd136, %rd52;
	sub.s64 	%rd138, %rd50, %rd115;
	bra.uni 	$L__BB0_40;

$L__BB0_39:
	cvt.u32.u64 	%r47, %rd52;
	cvt.u32.u64 	%r48, %rd50;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd136, %r49;
	cvt.u64.u32 	%rd138, %r51;

$L__BB0_40:
	shl.b64 	%rd116, %rd61, 3;
	add.s64 	%rd117, %rd51, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd138;
	cvt.u32.u64 	%r52, %rd119;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd120, %r57;
	setp.lt.u64 	%p20, %rd120, %rd61;
	@%p20 bra 	$L__BB0_37;

$L__BB0_41:
	mul.wide.u32 	%rd121, %r58, 4;
	add.s64 	%rd122, %rd2, %rd121;
	ld.global.f32 	%f2, [%rd122];
	st.global.f32 	[%rd45], %f2;

$L__BB0_43:
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd124, %r55;
	setp.lt.u64 	%p21, %rd124, %rd60;
	@%p21 bra 	$L__BB0_24;

$L__BB0_44:
	ret;

}
	// .globl	is_i64_f64
.visible .entry is_i64_f64(
	.param .u64 is_i64_f64_param_0,
	.param .u64 is_i64_f64_param_1,
	.param .u64 is_i64_f64_param_2,
	.param .u64 is_i64_f64_param_3,
	.param .u64 is_i64_f64_param_4,
	.param .u64 is_i64_f64_param_5,
	.param .u64 is_i64_f64_param_6,
	.param .u64 is_i64_f64_param_7,
	.param .u64 is_i64_f64_param_8,
	.param .u64 is_i64_f64_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<141>;


	ld.param.u64 	%rd60, [is_i64_f64_param_0];
	ld.param.u64 	%rd61, [is_i64_f64_param_1];
	ld.param.u64 	%rd65, [is_i64_f64_param_2];
	ld.param.u64 	%rd66, [is_i64_f64_param_3];
	ld.param.u64 	%rd67, [is_i64_f64_param_4];
	ld.param.u64 	%rd68, [is_i64_f64_param_5];
	ld.param.u64 	%rd62, [is_i64_f64_param_7];
	ld.param.u64 	%rd63, [is_i64_f64_param_8];
	ld.param.u64 	%rd64, [is_i64_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB1_5;

	mov.u64 	%rd125, 1;
	mov.u32 	%r52, 0;

$L__BB1_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB1_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd125, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB1_5;

$L__BB1_4:
	mul.lo.s64 	%rd125, %rd7, %rd125;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB1_2;

$L__BB1_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd126, %r53;
	setp.ge.u64 	%p5, %rd126, %rd60;
	@%p5 bra 	$L__BB1_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB1_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB1_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB1_10;

	div.u64 	%rd127, %rd126, %rd10;
	bra.uni 	$L__BB1_11;

$L__BB1_10:
	cvt.u32.u64 	%r21, %rd126;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd127, %r22;

$L__BB1_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB1_13;

	div.u64 	%rd128, %rd126, %rd64;
	mul.lo.s64 	%rd80, %rd128, %rd64;
	sub.s64 	%rd129, %rd126, %rd80;
	bra.uni 	$L__BB1_14;

$L__BB1_13:
	cvt.u32.u64 	%r24, %rd126;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd128, %r25;
	cvt.u64.u32 	%rd129, %r27;

$L__BB1_14:
	or.b64  	%rd81, %rd128, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB1_16;

	rem.u64 	%rd130, %rd128, %rd63;
	bra.uni 	$L__BB1_17;

$L__BB1_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd128;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd130, %r30;

$L__BB1_17:
	shl.b64 	%rd83, %rd130, 3;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u64 	%rd131, [%rd24];
	setp.eq.s64 	%p10, %rd131, 9223372036854775807;
	shl.b64 	%rd84, %rd126, 3;
	add.s64 	%rd26, %rd1, %rd84;
	@%p10 bra 	$L__BB1_21;
	bra.uni 	$L__BB1_18;

$L__BB1_21:
	mov.u64 	%rd96, 0;
	st.global.u64 	[%rd26], %rd96;
	bra.uni 	$L__BB1_22;

$L__BB1_18:
	setp.lt.u64 	%p11, %rd131, %rd62;
	@%p11 bra 	$L__BB1_20;

	mov.u64 	%rd85, $str;
	cvta.global.u64 	%rd86, %rd85;
	mov.u64 	%rd87, $str$1;
	cvta.global.u64 	%rd88, %rd87;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 2
	ld.global.u64 	%rd131, [%rd24];

$L__BB1_20:
	mul.lo.s64 	%rd89, %rd127, %rd62;
	add.s64 	%rd90, %rd131, %rd89;
	mul.lo.s64 	%rd91, %rd90, %rd64;
	add.s64 	%rd92, %rd91, %rd129;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd95, %rd2, %rd94;
	ld.global.f64 	%fd1, [%rd95];
	st.global.f64 	[%rd26], %fd1;

$L__BB1_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd126, %r53;
	setp.lt.u64 	%p12, %rd126, %rd60;
	@%p12 bra 	$L__BB1_8;
	bra.uni 	$L__BB1_44;

$L__BB1_23:
	and.b64  	%rd97, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB1_24:
	setp.eq.s64 	%p13, %rd97, 0;
	@%p13 bra 	$L__BB1_26;

	div.u64 	%rd133, %rd126, %rd10;
	bra.uni 	$L__BB1_27;

$L__BB1_26:
	cvt.u32.u64 	%r32, %rd126;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd133, %r33;

$L__BB1_27:
	and.b64  	%rd98, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd98, 0;
	@%p14 bra 	$L__BB1_29;

	div.u64 	%rd134, %rd126, %rd64;
	mul.lo.s64 	%rd99, %rd134, %rd64;
	sub.s64 	%rd135, %rd126, %rd99;
	bra.uni 	$L__BB1_30;

$L__BB1_29:
	cvt.u32.u64 	%r35, %rd126;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd134, %r36;
	cvt.u64.u32 	%rd135, %r38;

$L__BB1_30:
	or.b64  	%rd100, %rd134, %rd63;
	and.b64  	%rd101, %rd100, -4294967296;
	setp.eq.s64 	%p15, %rd101, 0;
	@%p15 bra 	$L__BB1_32;

	rem.u64 	%rd136, %rd134, %rd63;
	bra.uni 	$L__BB1_33;

$L__BB1_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd134;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd136, %r41;

$L__BB1_33:
	shl.b64 	%rd102, %rd136, 3;
	add.s64 	%rd43, %rd3, %rd102;
	ld.global.u64 	%rd137, [%rd43];
	setp.eq.s64 	%p16, %rd137, 9223372036854775807;
	shl.b64 	%rd103, %rd126, 3;
	add.s64 	%rd45, %rd1, %rd103;
	@%p16 bra 	$L__BB1_42;
	bra.uni 	$L__BB1_34;

$L__BB1_42:
	mov.u64 	%rd124, 0;
	st.global.u64 	[%rd45], %rd124;
	bra.uni 	$L__BB1_43;

$L__BB1_34:
	setp.lt.u64 	%p17, %rd137, %rd62;
	@%p17 bra 	$L__BB1_36;

	mov.u64 	%rd104, $str;
	cvta.global.u64 	%rd105, %rd104;
	mov.u64 	%rd106, $str$1;
	cvta.global.u64 	%rd107, %rd106;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd105;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd107;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 3
	ld.global.u64 	%rd137, [%rd43];

$L__BB1_36:
	mul.lo.s64 	%rd108, %rd133, %rd62;
	add.s64 	%rd109, %rd137, %rd108;
	mul.lo.s64 	%rd110, %rd109, %rd64;
	add.s64 	%rd138, %rd110, %rd135;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB1_41;

$L__BB1_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd111, %r45;
	add.s64 	%rd112, %rd111, %rd61;
	and.b64  	%rd50, %rd138, 4294967295;
	shl.b64 	%rd113, %rd112, 3;
	and.b64  	%rd114, %rd113, 34359738360;
	add.s64 	%rd51, %rd4, %rd114;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd115, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd115, 0;
	@%p19 bra 	$L__BB1_39;

	div.u64 	%rd138, %rd50, %rd52;
	mul.lo.s64 	%rd116, %rd138, %rd52;
	sub.s64 	%rd140, %rd50, %rd116;
	bra.uni 	$L__BB1_40;

$L__BB1_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd138, %r48;
	cvt.u64.u32 	%rd140, %r50;

$L__BB1_40:
	shl.b64 	%rd117, %rd61, 3;
	add.s64 	%rd118, %rd51, %rd117;
	ld.global.u64 	%rd119, [%rd118];
	mul.lo.s64 	%rd120, %rd119, %rd140;
	cvt.u32.u64 	%r51, %rd120;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd121, %r55;
	setp.lt.u64 	%p20, %rd121, %rd61;
	@%p20 bra 	$L__BB1_37;

$L__BB1_41:
	mul.wide.u32 	%rd122, %r56, 8;
	add.s64 	%rd123, %rd2, %rd122;
	ld.global.f64 	%fd2, [%rd123];
	st.global.f64 	[%rd45], %fd2;

$L__BB1_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd126, %r53;
	setp.lt.u64 	%p21, %rd126, %rd60;
	@%p21 bra 	$L__BB1_24;

$L__BB1_44:
	ret;

}
	// .globl	is_i64_u8
.visible .entry is_i64_u8(
	.param .u64 is_i64_u8_param_0,
	.param .u64 is_i64_u8_param_1,
	.param .u64 is_i64_u8_param_2,
	.param .u64 is_i64_u8_param_3,
	.param .u64 is_i64_u8_param_4,
	.param .u64 is_i64_u8_param_5,
	.param .u64 is_i64_u8_param_6,
	.param .u64 is_i64_u8_param_7,
	.param .u64 is_i64_u8_param_8,
	.param .u64 is_i64_u8_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<136>;


	ld.param.u64 	%rd60, [is_i64_u8_param_0];
	ld.param.u64 	%rd61, [is_i64_u8_param_1];
	ld.param.u64 	%rd65, [is_i64_u8_param_2];
	ld.param.u64 	%rd66, [is_i64_u8_param_3];
	ld.param.u64 	%rd67, [is_i64_u8_param_4];
	ld.param.u64 	%rd68, [is_i64_u8_param_5];
	ld.param.u64 	%rd62, [is_i64_u8_param_7];
	ld.param.u64 	%rd63, [is_i64_u8_param_8];
	ld.param.u64 	%rd64, [is_i64_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs9, %rs2;
	@%p1 bra 	$L__BB2_5;

	mov.u64 	%rd120, 1;
	mov.u32 	%r52, 0;

$L__BB2_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB2_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd120, %rd76;
	mov.u16 	%rs9, 0;
	@%p3 bra 	$L__BB2_5;

$L__BB2_4:
	mul.lo.s64 	%rd120, %rd7, %rd120;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs9, %rs2;
	@%p4 bra 	$L__BB2_2;

$L__BB2_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd121, %r53;
	setp.ge.u64 	%p5, %rd121, %rd60;
	@%p5 bra 	$L__BB2_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs9, 0;
	@%p6 bra 	$L__BB2_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB2_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB2_10;

	div.u64 	%rd122, %rd121, %rd10;
	bra.uni 	$L__BB2_11;

$L__BB2_10:
	cvt.u32.u64 	%r21, %rd121;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd122, %r22;

$L__BB2_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB2_13;

	div.u64 	%rd123, %rd121, %rd64;
	mul.lo.s64 	%rd80, %rd123, %rd64;
	sub.s64 	%rd124, %rd121, %rd80;
	bra.uni 	$L__BB2_14;

$L__BB2_13:
	cvt.u32.u64 	%r24, %rd121;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd123, %r25;
	cvt.u64.u32 	%rd124, %r27;

$L__BB2_14:
	or.b64  	%rd81, %rd123, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB2_16;

	rem.u64 	%rd125, %rd123, %rd63;
	bra.uni 	$L__BB2_17;

$L__BB2_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd123;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd125, %r30;

$L__BB2_17:
	shl.b64 	%rd83, %rd125, 3;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u64 	%rd126, [%rd24];
	setp.eq.s64 	%p10, %rd126, 9223372036854775807;
	add.s64 	%rd26, %rd1, %rd121;
	@%p10 bra 	$L__BB2_21;
	bra.uni 	$L__BB2_18;

$L__BB2_21:
	mov.u16 	%rs6, 0;
	st.global.u8 	[%rd26], %rs6;
	bra.uni 	$L__BB2_22;

$L__BB2_18:
	setp.lt.u64 	%p11, %rd126, %rd62;
	@%p11 bra 	$L__BB2_20;

	mov.u64 	%rd84, $str;
	cvta.global.u64 	%rd85, %rd84;
	mov.u64 	%rd86, $str$1;
	cvta.global.u64 	%rd87, %rd86;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 4
	ld.global.u64 	%rd126, [%rd24];

$L__BB2_20:
	mul.lo.s64 	%rd88, %rd122, %rd62;
	add.s64 	%rd89, %rd126, %rd88;
	mul.lo.s64 	%rd90, %rd89, %rd64;
	add.s64 	%rd91, %rd90, %rd124;
	and.b64  	%rd92, %rd91, 4294967295;
	add.s64 	%rd93, %rd2, %rd92;
	ld.global.u8 	%rs5, [%rd93];
	st.global.u8 	[%rd26], %rs5;

$L__BB2_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd121, %r53;
	setp.lt.u64 	%p12, %rd121, %rd60;
	@%p12 bra 	$L__BB2_8;
	bra.uni 	$L__BB2_44;

$L__BB2_23:
	and.b64  	%rd94, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB2_24:
	setp.eq.s64 	%p13, %rd94, 0;
	@%p13 bra 	$L__BB2_26;

	div.u64 	%rd128, %rd121, %rd10;
	bra.uni 	$L__BB2_27;

$L__BB2_26:
	cvt.u32.u64 	%r32, %rd121;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd128, %r33;

$L__BB2_27:
	and.b64  	%rd95, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd95, 0;
	@%p14 bra 	$L__BB2_29;

	div.u64 	%rd129, %rd121, %rd64;
	mul.lo.s64 	%rd96, %rd129, %rd64;
	sub.s64 	%rd130, %rd121, %rd96;
	bra.uni 	$L__BB2_30;

$L__BB2_29:
	cvt.u32.u64 	%r35, %rd121;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd129, %r36;
	cvt.u64.u32 	%rd130, %r38;

$L__BB2_30:
	or.b64  	%rd97, %rd129, %rd63;
	and.b64  	%rd98, %rd97, -4294967296;
	setp.eq.s64 	%p15, %rd98, 0;
	@%p15 bra 	$L__BB2_32;

	rem.u64 	%rd131, %rd129, %rd63;
	bra.uni 	$L__BB2_33;

$L__BB2_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd129;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd131, %r41;

$L__BB2_33:
	shl.b64 	%rd99, %rd131, 3;
	add.s64 	%rd43, %rd3, %rd99;
	ld.global.u64 	%rd132, [%rd43];
	setp.eq.s64 	%p16, %rd132, 9223372036854775807;
	add.s64 	%rd45, %rd1, %rd121;
	@%p16 bra 	$L__BB2_42;
	bra.uni 	$L__BB2_34;

$L__BB2_42:
	mov.u16 	%rs8, 0;
	st.global.u8 	[%rd45], %rs8;
	bra.uni 	$L__BB2_43;

$L__BB2_34:
	setp.lt.u64 	%p17, %rd132, %rd62;
	@%p17 bra 	$L__BB2_36;

	mov.u64 	%rd100, $str;
	cvta.global.u64 	%rd101, %rd100;
	mov.u64 	%rd102, $str$1;
	cvta.global.u64 	%rd103, %rd102;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd101;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 5
	ld.global.u64 	%rd132, [%rd43];

$L__BB2_36:
	mul.lo.s64 	%rd104, %rd128, %rd62;
	add.s64 	%rd105, %rd132, %rd104;
	mul.lo.s64 	%rd106, %rd105, %rd64;
	add.s64 	%rd133, %rd106, %rd130;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB2_41;

$L__BB2_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd107, %r45;
	add.s64 	%rd108, %rd107, %rd61;
	and.b64  	%rd50, %rd133, 4294967295;
	shl.b64 	%rd109, %rd108, 3;
	and.b64  	%rd110, %rd109, 34359738360;
	add.s64 	%rd51, %rd4, %rd110;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd111, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd111, 0;
	@%p19 bra 	$L__BB2_39;

	div.u64 	%rd133, %rd50, %rd52;
	mul.lo.s64 	%rd112, %rd133, %rd52;
	sub.s64 	%rd135, %rd50, %rd112;
	bra.uni 	$L__BB2_40;

$L__BB2_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd133, %r48;
	cvt.u64.u32 	%rd135, %r50;

$L__BB2_40:
	shl.b64 	%rd113, %rd61, 3;
	add.s64 	%rd114, %rd51, %rd113;
	ld.global.u64 	%rd115, [%rd114];
	mul.lo.s64 	%rd116, %rd115, %rd135;
	cvt.u32.u64 	%r51, %rd116;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd117, %r55;
	setp.lt.u64 	%p20, %rd117, %rd61;
	@%p20 bra 	$L__BB2_37;

$L__BB2_41:
	cvt.u64.u32 	%rd118, %r56;
	add.s64 	%rd119, %rd2, %rd118;
	ld.global.u8 	%rs7, [%rd119];
	st.global.u8 	[%rd45], %rs7;

$L__BB2_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd121, %r53;
	setp.lt.u64 	%p21, %rd121, %rd60;
	@%p21 bra 	$L__BB2_24;

$L__BB2_44:
	ret;

}
	// .globl	is_i64_u32
.visible .entry is_i64_u32(
	.param .u64 is_i64_u32_param_0,
	.param .u64 is_i64_u32_param_1,
	.param .u64 is_i64_u32_param_2,
	.param .u64 is_i64_u32_param_3,
	.param .u64 is_i64_u32_param_4,
	.param .u64 is_i64_u32_param_5,
	.param .u64 is_i64_u32_param_6,
	.param .u64 is_i64_u32_param_7,
	.param .u64 is_i64_u32_param_8,
	.param .u64 is_i64_u32_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<139>;


	ld.param.u64 	%rd60, [is_i64_u32_param_0];
	ld.param.u64 	%rd61, [is_i64_u32_param_1];
	ld.param.u64 	%rd65, [is_i64_u32_param_2];
	ld.param.u64 	%rd66, [is_i64_u32_param_3];
	ld.param.u64 	%rd67, [is_i64_u32_param_4];
	ld.param.u64 	%rd68, [is_i64_u32_param_5];
	ld.param.u64 	%rd62, [is_i64_u32_param_7];
	ld.param.u64 	%rd63, [is_i64_u32_param_8];
	ld.param.u64 	%rd64, [is_i64_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB3_5;

	mov.u64 	%rd123, 1;
	mov.u32 	%r56, 0;

$L__BB3_2:
	not.b32 	%r16, %r56;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB3_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd123, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB3_5;

$L__BB3_4:
	mul.lo.s64 	%rd123, %rd7, %rd123;
	add.s32 	%r56, %r56, 1;
	cvt.u64.u32 	%rd77, %r56;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB3_2;

$L__BB3_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r57, %r17, %r3, %r18;
	cvt.u64.u32 	%rd124, %r57;
	setp.ge.u64 	%p5, %rd124, %rd60;
	@%p5 bra 	$L__BB3_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB3_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB3_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB3_10;

	div.u64 	%rd125, %rd124, %rd10;
	bra.uni 	$L__BB3_11;

$L__BB3_10:
	cvt.u32.u64 	%r21, %rd124;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd125, %r22;

$L__BB3_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB3_13;

	div.u64 	%rd126, %rd124, %rd64;
	mul.lo.s64 	%rd80, %rd126, %rd64;
	sub.s64 	%rd127, %rd124, %rd80;
	bra.uni 	$L__BB3_14;

$L__BB3_13:
	cvt.u32.u64 	%r24, %rd124;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd126, %r25;
	cvt.u64.u32 	%rd127, %r27;

$L__BB3_14:
	or.b64  	%rd81, %rd126, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB3_16;

	rem.u64 	%rd128, %rd126, %rd63;
	bra.uni 	$L__BB3_17;

$L__BB3_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd126;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd128, %r30;

$L__BB3_17:
	shl.b64 	%rd83, %rd128, 3;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u64 	%rd129, [%rd24];
	setp.eq.s64 	%p10, %rd129, 9223372036854775807;
	shl.b64 	%rd84, %rd124, 2;
	add.s64 	%rd26, %rd1, %rd84;
	@%p10 bra 	$L__BB3_21;
	bra.uni 	$L__BB3_18;

$L__BB3_21:
	mov.u32 	%r32, 0;
	st.global.u32 	[%rd26], %r32;
	bra.uni 	$L__BB3_22;

$L__BB3_18:
	setp.lt.u64 	%p11, %rd129, %rd62;
	@%p11 bra 	$L__BB3_20;

	mov.u64 	%rd85, $str;
	cvta.global.u64 	%rd86, %rd85;
	mov.u64 	%rd87, $str$1;
	cvta.global.u64 	%rd88, %rd87;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 6
	ld.global.u64 	%rd129, [%rd24];

$L__BB3_20:
	mul.lo.s64 	%rd89, %rd125, %rd62;
	add.s64 	%rd90, %rd129, %rd89;
	mul.lo.s64 	%rd91, %rd90, %rd64;
	add.s64 	%rd92, %rd91, %rd127;
	shl.b64 	%rd93, %rd92, 2;
	and.b64  	%rd94, %rd93, 17179869180;
	add.s64 	%rd95, %rd2, %rd94;
	ld.global.u32 	%r31, [%rd95];
	st.global.u32 	[%rd26], %r31;

$L__BB3_22:
	add.s32 	%r57, %r57, %r5;
	cvt.u64.u32 	%rd124, %r57;
	setp.lt.u64 	%p12, %rd124, %rd60;
	@%p12 bra 	$L__BB3_8;
	bra.uni 	$L__BB3_44;

$L__BB3_23:
	and.b64  	%rd96, %rd10, -4294967296;
	cvt.u32.u64 	%r33, %rd10;
	cvt.u32.u64 	%r36, %rd64;

$L__BB3_24:
	setp.eq.s64 	%p13, %rd96, 0;
	@%p13 bra 	$L__BB3_26;

	div.u64 	%rd131, %rd124, %rd10;
	bra.uni 	$L__BB3_27;

$L__BB3_26:
	cvt.u32.u64 	%r34, %rd124;
	div.u32 	%r35, %r34, %r33;
	cvt.u64.u32 	%rd131, %r35;

$L__BB3_27:
	and.b64  	%rd97, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd97, 0;
	@%p14 bra 	$L__BB3_29;

	div.u64 	%rd132, %rd124, %rd64;
	mul.lo.s64 	%rd98, %rd132, %rd64;
	sub.s64 	%rd133, %rd124, %rd98;
	bra.uni 	$L__BB3_30;

$L__BB3_29:
	cvt.u32.u64 	%r37, %rd124;
	div.u32 	%r38, %r37, %r36;
	mul.lo.s32 	%r39, %r38, %r36;
	sub.s32 	%r40, %r37, %r39;
	cvt.u64.u32 	%rd132, %r38;
	cvt.u64.u32 	%rd133, %r40;

$L__BB3_30:
	or.b64  	%rd99, %rd132, %rd63;
	and.b64  	%rd100, %rd99, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB3_32;

	rem.u64 	%rd134, %rd132, %rd63;
	bra.uni 	$L__BB3_33;

$L__BB3_32:
	cvt.u32.u64 	%r41, %rd63;
	cvt.u32.u64 	%r42, %rd132;
	rem.u32 	%r43, %r42, %r41;
	cvt.u64.u32 	%rd134, %r43;

$L__BB3_33:
	shl.b64 	%rd101, %rd134, 3;
	add.s64 	%rd43, %rd3, %rd101;
	ld.global.u64 	%rd135, [%rd43];
	setp.eq.s64 	%p16, %rd135, 9223372036854775807;
	shl.b64 	%rd102, %rd124, 2;
	add.s64 	%rd45, %rd1, %rd102;
	@%p16 bra 	$L__BB3_42;
	bra.uni 	$L__BB3_34;

$L__BB3_42:
	mov.u32 	%r55, 0;
	st.global.u32 	[%rd45], %r55;
	bra.uni 	$L__BB3_43;

$L__BB3_34:
	setp.lt.u64 	%p17, %rd135, %rd62;
	@%p17 bra 	$L__BB3_36;

	mov.u64 	%rd103, $str;
	cvta.global.u64 	%rd104, %rd103;
	mov.u64 	%rd105, $str$1;
	cvta.global.u64 	%rd106, %rd105;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd104;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd106;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 7
	ld.global.u64 	%rd135, [%rd43];

$L__BB3_36:
	mul.lo.s64 	%rd107, %rd131, %rd62;
	add.s64 	%rd108, %rd135, %rd107;
	mul.lo.s64 	%rd109, %rd108, %rd64;
	add.s64 	%rd136, %rd109, %rd133;
	mov.u32 	%r59, 0;
	mov.u32 	%r60, %r59;
	@%p1 bra 	$L__BB3_41;

$L__BB3_37:
	not.b32 	%r47, %r59;
	cvt.u64.u32 	%rd110, %r47;
	add.s64 	%rd111, %rd110, %rd61;
	and.b64  	%rd50, %rd136, 4294967295;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd51, %rd4, %rd113;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd114, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd114, 0;
	@%p19 bra 	$L__BB3_39;

	div.u64 	%rd136, %rd50, %rd52;
	mul.lo.s64 	%rd115, %rd136, %rd52;
	sub.s64 	%rd138, %rd50, %rd115;
	bra.uni 	$L__BB3_40;

$L__BB3_39:
	cvt.u32.u64 	%r48, %rd52;
	cvt.u32.u64 	%r49, %rd50;
	div.u32 	%r50, %r49, %r48;
	mul.lo.s32 	%r51, %r50, %r48;
	sub.s32 	%r52, %r49, %r51;
	cvt.u64.u32 	%rd136, %r50;
	cvt.u64.u32 	%rd138, %r52;

$L__BB3_40:
	shl.b64 	%rd116, %rd61, 3;
	add.s64 	%rd117, %rd51, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd138;
	cvt.u32.u64 	%r53, %rd119;
	add.s32 	%r60, %r60, %r53;
	add.s32 	%r59, %r59, 1;
	cvt.u64.u32 	%rd120, %r59;
	setp.lt.u64 	%p20, %rd120, %rd61;
	@%p20 bra 	$L__BB3_37;

$L__BB3_41:
	mul.wide.u32 	%rd121, %r60, 4;
	add.s64 	%rd122, %rd2, %rd121;
	ld.global.u32 	%r54, [%rd122];
	st.global.u32 	[%rd45], %r54;

$L__BB3_43:
	add.s32 	%r57, %r57, %r5;
	cvt.u64.u32 	%rd124, %r57;
	setp.lt.u64 	%p21, %rd124, %rd60;
	@%p21 bra 	$L__BB3_24;

$L__BB3_44:
	ret;

}
	// .globl	is_i64_i64
.visible .entry is_i64_i64(
	.param .u64 is_i64_i64_param_0,
	.param .u64 is_i64_i64_param_1,
	.param .u64 is_i64_i64_param_2,
	.param .u64 is_i64_i64_param_3,
	.param .u64 is_i64_i64_param_4,
	.param .u64 is_i64_i64_param_5,
	.param .u64 is_i64_i64_param_6,
	.param .u64 is_i64_i64_param_7,
	.param .u64 is_i64_i64_param_8,
	.param .u64 is_i64_i64_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<143>;


	ld.param.u64 	%rd60, [is_i64_i64_param_0];
	ld.param.u64 	%rd61, [is_i64_i64_param_1];
	ld.param.u64 	%rd65, [is_i64_i64_param_2];
	ld.param.u64 	%rd66, [is_i64_i64_param_3];
	ld.param.u64 	%rd67, [is_i64_i64_param_4];
	ld.param.u64 	%rd68, [is_i64_i64_param_5];
	ld.param.u64 	%rd62, [is_i64_i64_param_7];
	ld.param.u64 	%rd63, [is_i64_i64_param_8];
	ld.param.u64 	%rd64, [is_i64_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB4_5;

	mov.u64 	%rd127, 1;
	mov.u32 	%r52, 0;

$L__BB4_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB4_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd127, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB4_5;

$L__BB4_4:
	mul.lo.s64 	%rd127, %rd7, %rd127;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB4_2;

$L__BB4_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd128, %r53;
	setp.ge.u64 	%p5, %rd128, %rd60;
	@%p5 bra 	$L__BB4_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB4_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB4_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB4_10;

	div.u64 	%rd129, %rd128, %rd10;
	bra.uni 	$L__BB4_11;

$L__BB4_10:
	cvt.u32.u64 	%r21, %rd128;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd129, %r22;

$L__BB4_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB4_13;

	div.u64 	%rd130, %rd128, %rd64;
	mul.lo.s64 	%rd80, %rd130, %rd64;
	sub.s64 	%rd131, %rd128, %rd80;
	bra.uni 	$L__BB4_14;

$L__BB4_13:
	cvt.u32.u64 	%r24, %rd128;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd130, %r25;
	cvt.u64.u32 	%rd131, %r27;

$L__BB4_14:
	or.b64  	%rd81, %rd130, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB4_16;

	rem.u64 	%rd132, %rd130, %rd63;
	bra.uni 	$L__BB4_17;

$L__BB4_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd130;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd132, %r30;

$L__BB4_17:
	shl.b64 	%rd83, %rd132, 3;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u64 	%rd133, [%rd24];
	setp.eq.s64 	%p10, %rd133, 9223372036854775807;
	shl.b64 	%rd84, %rd128, 3;
	add.s64 	%rd26, %rd1, %rd84;
	@%p10 bra 	$L__BB4_21;
	bra.uni 	$L__BB4_18;

$L__BB4_21:
	mov.u64 	%rd97, 0;
	st.global.u64 	[%rd26], %rd97;
	bra.uni 	$L__BB4_22;

$L__BB4_18:
	setp.lt.u64 	%p11, %rd133, %rd62;
	@%p11 bra 	$L__BB4_20;

	mov.u64 	%rd85, $str;
	cvta.global.u64 	%rd86, %rd85;
	mov.u64 	%rd87, $str$1;
	cvta.global.u64 	%rd88, %rd87;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 8
	ld.global.u64 	%rd133, [%rd24];

$L__BB4_20:
	mul.lo.s64 	%rd89, %rd129, %rd62;
	add.s64 	%rd90, %rd133, %rd89;
	mul.lo.s64 	%rd91, %rd90, %rd64;
	add.s64 	%rd92, %rd91, %rd131;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd95, %rd2, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	st.global.u64 	[%rd26], %rd96;

$L__BB4_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd128, %r53;
	setp.lt.u64 	%p12, %rd128, %rd60;
	@%p12 bra 	$L__BB4_8;
	bra.uni 	$L__BB4_44;

$L__BB4_23:
	and.b64  	%rd98, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB4_24:
	setp.eq.s64 	%p13, %rd98, 0;
	@%p13 bra 	$L__BB4_26;

	div.u64 	%rd135, %rd128, %rd10;
	bra.uni 	$L__BB4_27;

$L__BB4_26:
	cvt.u32.u64 	%r32, %rd128;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd135, %r33;

$L__BB4_27:
	and.b64  	%rd99, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd99, 0;
	@%p14 bra 	$L__BB4_29;

	div.u64 	%rd136, %rd128, %rd64;
	mul.lo.s64 	%rd100, %rd136, %rd64;
	sub.s64 	%rd137, %rd128, %rd100;
	bra.uni 	$L__BB4_30;

$L__BB4_29:
	cvt.u32.u64 	%r35, %rd128;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd136, %r36;
	cvt.u64.u32 	%rd137, %r38;

$L__BB4_30:
	or.b64  	%rd101, %rd136, %rd63;
	and.b64  	%rd102, %rd101, -4294967296;
	setp.eq.s64 	%p15, %rd102, 0;
	@%p15 bra 	$L__BB4_32;

	rem.u64 	%rd138, %rd136, %rd63;
	bra.uni 	$L__BB4_33;

$L__BB4_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd136;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd138, %r41;

$L__BB4_33:
	shl.b64 	%rd103, %rd138, 3;
	add.s64 	%rd43, %rd3, %rd103;
	ld.global.u64 	%rd139, [%rd43];
	setp.eq.s64 	%p16, %rd139, 9223372036854775807;
	shl.b64 	%rd104, %rd128, 3;
	add.s64 	%rd45, %rd1, %rd104;
	@%p16 bra 	$L__BB4_42;
	bra.uni 	$L__BB4_34;

$L__BB4_42:
	mov.u64 	%rd126, 0;
	st.global.u64 	[%rd45], %rd126;
	bra.uni 	$L__BB4_43;

$L__BB4_34:
	setp.lt.u64 	%p17, %rd139, %rd62;
	@%p17 bra 	$L__BB4_36;

	mov.u64 	%rd105, $str;
	cvta.global.u64 	%rd106, %rd105;
	mov.u64 	%rd107, $str$1;
	cvta.global.u64 	%rd108, %rd107;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd106;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd108;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 9
	ld.global.u64 	%rd139, [%rd43];

$L__BB4_36:
	mul.lo.s64 	%rd109, %rd135, %rd62;
	add.s64 	%rd110, %rd139, %rd109;
	mul.lo.s64 	%rd111, %rd110, %rd64;
	add.s64 	%rd140, %rd111, %rd137;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB4_41;

$L__BB4_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd112, %r45;
	add.s64 	%rd113, %rd112, %rd61;
	and.b64  	%rd50, %rd140, 4294967295;
	shl.b64 	%rd114, %rd113, 3;
	and.b64  	%rd115, %rd114, 34359738360;
	add.s64 	%rd51, %rd4, %rd115;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd116, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd116, 0;
	@%p19 bra 	$L__BB4_39;

	div.u64 	%rd140, %rd50, %rd52;
	mul.lo.s64 	%rd117, %rd140, %rd52;
	sub.s64 	%rd142, %rd50, %rd117;
	bra.uni 	$L__BB4_40;

$L__BB4_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd140, %r48;
	cvt.u64.u32 	%rd142, %r50;

$L__BB4_40:
	shl.b64 	%rd118, %rd61, 3;
	add.s64 	%rd119, %rd51, %rd118;
	ld.global.u64 	%rd120, [%rd119];
	mul.lo.s64 	%rd121, %rd120, %rd142;
	cvt.u32.u64 	%r51, %rd121;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd122, %r55;
	setp.lt.u64 	%p20, %rd122, %rd61;
	@%p20 bra 	$L__BB4_37;

$L__BB4_41:
	mul.wide.u32 	%rd123, %r56, 8;
	add.s64 	%rd124, %rd2, %rd123;
	ld.global.u64 	%rd125, [%rd124];
	st.global.u64 	[%rd45], %rd125;

$L__BB4_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd128, %r53;
	setp.lt.u64 	%p21, %rd128, %rd60;
	@%p21 bra 	$L__BB4_24;

$L__BB4_44:
	ret;

}
	// .globl	is_u32_f32
.visible .entry is_u32_f32(
	.param .u64 is_u32_f32_param_0,
	.param .u64 is_u32_f32_param_1,
	.param .u64 is_u32_f32_param_2,
	.param .u64 is_u32_f32_param_3,
	.param .u64 is_u32_f32_param_4,
	.param .u64 is_u32_f32_param_5,
	.param .u64 is_u32_f32_param_6,
	.param .u64 is_u32_f32_param_7,
	.param .u64 is_u32_f32_param_8,
	.param .u64 is_u32_f32_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<139>;


	ld.param.u64 	%rd60, [is_u32_f32_param_0];
	ld.param.u64 	%rd61, [is_u32_f32_param_1];
	ld.param.u64 	%rd65, [is_u32_f32_param_2];
	ld.param.u64 	%rd66, [is_u32_f32_param_3];
	ld.param.u64 	%rd67, [is_u32_f32_param_4];
	ld.param.u64 	%rd68, [is_u32_f32_param_5];
	ld.param.u64 	%rd62, [is_u32_f32_param_7];
	ld.param.u64 	%rd63, [is_u32_f32_param_8];
	ld.param.u64 	%rd64, [is_u32_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB5_5;

	mov.u64 	%rd123, 1;
	mov.u32 	%r54, 0;

$L__BB5_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB5_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd123, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB5_5;

$L__BB5_4:
	mul.lo.s64 	%rd123, %rd7, %rd123;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd77, %r54;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB5_2;

$L__BB5_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd124, %r55;
	setp.ge.u64 	%p5, %rd124, %rd60;
	@%p5 bra 	$L__BB5_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB5_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB5_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB5_10;

	div.u64 	%rd125, %rd124, %rd10;
	bra.uni 	$L__BB5_11;

$L__BB5_10:
	cvt.u32.u64 	%r21, %rd124;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd125, %r22;

$L__BB5_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB5_13;

	div.u64 	%rd126, %rd124, %rd64;
	mul.lo.s64 	%rd80, %rd126, %rd64;
	sub.s64 	%rd127, %rd124, %rd80;
	bra.uni 	$L__BB5_14;

$L__BB5_13:
	cvt.u32.u64 	%r24, %rd124;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd126, %r25;
	cvt.u64.u32 	%rd127, %r27;

$L__BB5_14:
	or.b64  	%rd81, %rd126, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB5_16;

	rem.u64 	%rd128, %rd126, %rd63;
	bra.uni 	$L__BB5_17;

$L__BB5_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd126;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd128, %r30;

$L__BB5_17:
	shl.b64 	%rd83, %rd128, 2;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u32 	%rd129, [%rd24];
	setp.eq.s64 	%p10, %rd129, 4294967295;
	shl.b64 	%rd84, %rd124, 2;
	add.s64 	%rd26, %rd1, %rd84;
	@%p10 bra 	$L__BB5_21;

	setp.lt.u64 	%p11, %rd129, %rd62;
	@%p11 bra 	$L__BB5_20;

	mov.u64 	%rd85, $str;
	cvta.global.u64 	%rd86, %rd85;
	mov.u64 	%rd87, $str$1;
	cvta.global.u64 	%rd88, %rd87;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 10
	ld.global.u32 	%rd129, [%rd24];

$L__BB5_20:
	mul.lo.s64 	%rd89, %rd125, %rd62;
	add.s64 	%rd90, %rd89, %rd129;
	mul.lo.s64 	%rd91, %rd90, %rd64;
	add.s64 	%rd92, %rd91, %rd127;
	shl.b64 	%rd93, %rd92, 2;
	and.b64  	%rd94, %rd93, 17179869180;
	add.s64 	%rd95, %rd2, %rd94;
	ld.global.f32 	%f1, [%rd95];
	st.global.f32 	[%rd26], %f1;
	bra.uni 	$L__BB5_22;

$L__BB5_21:
	mov.u32 	%r31, 0;
	st.global.u32 	[%rd26], %r31;

$L__BB5_22:
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd124, %r55;
	setp.lt.u64 	%p12, %rd124, %rd60;
	@%p12 bra 	$L__BB5_8;
	bra.uni 	$L__BB5_44;

$L__BB5_23:
	and.b64  	%rd96, %rd10, -4294967296;
	cvt.u32.u64 	%r32, %rd10;
	cvt.u32.u64 	%r35, %rd64;

$L__BB5_24:
	setp.eq.s64 	%p13, %rd96, 0;
	@%p13 bra 	$L__BB5_26;

	div.u64 	%rd131, %rd124, %rd10;
	bra.uni 	$L__BB5_27;

$L__BB5_26:
	cvt.u32.u64 	%r33, %rd124;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd131, %r34;

$L__BB5_27:
	and.b64  	%rd97, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd97, 0;
	@%p14 bra 	$L__BB5_29;

	div.u64 	%rd132, %rd124, %rd64;
	mul.lo.s64 	%rd98, %rd132, %rd64;
	sub.s64 	%rd133, %rd124, %rd98;
	bra.uni 	$L__BB5_30;

$L__BB5_29:
	cvt.u32.u64 	%r36, %rd124;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd132, %r37;
	cvt.u64.u32 	%rd133, %r39;

$L__BB5_30:
	or.b64  	%rd99, %rd132, %rd63;
	and.b64  	%rd100, %rd99, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB5_32;

	rem.u64 	%rd134, %rd132, %rd63;
	bra.uni 	$L__BB5_33;

$L__BB5_32:
	cvt.u32.u64 	%r40, %rd63;
	cvt.u32.u64 	%r41, %rd132;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd134, %r42;

$L__BB5_33:
	shl.b64 	%rd101, %rd134, 2;
	add.s64 	%rd43, %rd3, %rd101;
	ld.global.u32 	%rd135, [%rd43];
	setp.eq.s64 	%p16, %rd135, 4294967295;
	shl.b64 	%rd102, %rd124, 2;
	add.s64 	%rd45, %rd1, %rd102;
	@%p16 bra 	$L__BB5_42;

	setp.lt.u64 	%p17, %rd135, %rd62;
	@%p17 bra 	$L__BB5_36;

	mov.u64 	%rd103, $str;
	cvta.global.u64 	%rd104, %rd103;
	mov.u64 	%rd105, $str$1;
	cvta.global.u64 	%rd106, %rd105;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd104;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd106;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 11
	ld.global.u32 	%rd135, [%rd43];

$L__BB5_36:
	mul.lo.s64 	%rd107, %rd131, %rd62;
	add.s64 	%rd108, %rd107, %rd135;
	mul.lo.s64 	%rd109, %rd108, %rd64;
	add.s64 	%rd136, %rd109, %rd133;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB5_41;

$L__BB5_37:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd110, %r46;
	add.s64 	%rd111, %rd110, %rd61;
	and.b64  	%rd50, %rd136, 4294967295;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd51, %rd4, %rd113;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd114, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd114, 0;
	@%p19 bra 	$L__BB5_39;

	div.u64 	%rd136, %rd50, %rd52;
	mul.lo.s64 	%rd115, %rd136, %rd52;
	sub.s64 	%rd138, %rd50, %rd115;
	bra.uni 	$L__BB5_40;

$L__BB5_39:
	cvt.u32.u64 	%r47, %rd52;
	cvt.u32.u64 	%r48, %rd50;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd136, %r49;
	cvt.u64.u32 	%rd138, %r51;

$L__BB5_40:
	shl.b64 	%rd116, %rd61, 3;
	add.s64 	%rd117, %rd51, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd138;
	cvt.u32.u64 	%r52, %rd119;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd120, %r57;
	setp.lt.u64 	%p20, %rd120, %rd61;
	@%p20 bra 	$L__BB5_37;

$L__BB5_41:
	mul.wide.u32 	%rd121, %r58, 4;
	add.s64 	%rd122, %rd2, %rd121;
	ld.global.f32 	%f2, [%rd122];
	st.global.f32 	[%rd45], %f2;
	bra.uni 	$L__BB5_43;

$L__BB5_42:
	mov.u32 	%r53, 0;
	st.global.u32 	[%rd45], %r53;

$L__BB5_43:
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd124, %r55;
	setp.lt.u64 	%p21, %rd124, %rd60;
	@%p21 bra 	$L__BB5_24;

$L__BB5_44:
	ret;

}
	// .globl	is_u32_f64
.visible .entry is_u32_f64(
	.param .u64 is_u32_f64_param_0,
	.param .u64 is_u32_f64_param_1,
	.param .u64 is_u32_f64_param_2,
	.param .u64 is_u32_f64_param_3,
	.param .u64 is_u32_f64_param_4,
	.param .u64 is_u32_f64_param_5,
	.param .u64 is_u32_f64_param_6,
	.param .u64 is_u32_f64_param_7,
	.param .u64 is_u32_f64_param_8,
	.param .u64 is_u32_f64_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<141>;


	ld.param.u64 	%rd60, [is_u32_f64_param_0];
	ld.param.u64 	%rd61, [is_u32_f64_param_1];
	ld.param.u64 	%rd65, [is_u32_f64_param_2];
	ld.param.u64 	%rd66, [is_u32_f64_param_3];
	ld.param.u64 	%rd67, [is_u32_f64_param_4];
	ld.param.u64 	%rd68, [is_u32_f64_param_5];
	ld.param.u64 	%rd62, [is_u32_f64_param_7];
	ld.param.u64 	%rd63, [is_u32_f64_param_8];
	ld.param.u64 	%rd64, [is_u32_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB6_5;

	mov.u64 	%rd125, 1;
	mov.u32 	%r52, 0;

$L__BB6_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB6_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd125, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB6_5;

$L__BB6_4:
	mul.lo.s64 	%rd125, %rd7, %rd125;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB6_2;

$L__BB6_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd126, %r53;
	setp.ge.u64 	%p5, %rd126, %rd60;
	@%p5 bra 	$L__BB6_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB6_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB6_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB6_10;

	div.u64 	%rd127, %rd126, %rd10;
	bra.uni 	$L__BB6_11;

$L__BB6_10:
	cvt.u32.u64 	%r21, %rd126;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd127, %r22;

$L__BB6_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB6_13;

	div.u64 	%rd128, %rd126, %rd64;
	mul.lo.s64 	%rd80, %rd128, %rd64;
	sub.s64 	%rd129, %rd126, %rd80;
	bra.uni 	$L__BB6_14;

$L__BB6_13:
	cvt.u32.u64 	%r24, %rd126;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd128, %r25;
	cvt.u64.u32 	%rd129, %r27;

$L__BB6_14:
	or.b64  	%rd81, %rd128, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB6_16;

	rem.u64 	%rd130, %rd128, %rd63;
	bra.uni 	$L__BB6_17;

$L__BB6_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd128;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd130, %r30;

$L__BB6_17:
	shl.b64 	%rd83, %rd130, 2;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u32 	%rd131, [%rd24];
	setp.eq.s64 	%p10, %rd131, 4294967295;
	shl.b64 	%rd84, %rd126, 3;
	add.s64 	%rd26, %rd1, %rd84;
	@%p10 bra 	$L__BB6_21;

	setp.lt.u64 	%p11, %rd131, %rd62;
	@%p11 bra 	$L__BB6_20;

	mov.u64 	%rd85, $str;
	cvta.global.u64 	%rd86, %rd85;
	mov.u64 	%rd87, $str$1;
	cvta.global.u64 	%rd88, %rd87;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 12
	ld.global.u32 	%rd131, [%rd24];

$L__BB6_20:
	mul.lo.s64 	%rd89, %rd127, %rd62;
	add.s64 	%rd90, %rd89, %rd131;
	mul.lo.s64 	%rd91, %rd90, %rd64;
	add.s64 	%rd92, %rd91, %rd129;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd95, %rd2, %rd94;
	ld.global.f64 	%fd1, [%rd95];
	st.global.f64 	[%rd26], %fd1;
	bra.uni 	$L__BB6_22;

$L__BB6_21:
	mov.u64 	%rd96, 0;
	st.global.u64 	[%rd26], %rd96;

$L__BB6_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd126, %r53;
	setp.lt.u64 	%p12, %rd126, %rd60;
	@%p12 bra 	$L__BB6_8;
	bra.uni 	$L__BB6_44;

$L__BB6_23:
	and.b64  	%rd97, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB6_24:
	setp.eq.s64 	%p13, %rd97, 0;
	@%p13 bra 	$L__BB6_26;

	div.u64 	%rd133, %rd126, %rd10;
	bra.uni 	$L__BB6_27;

$L__BB6_26:
	cvt.u32.u64 	%r32, %rd126;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd133, %r33;

$L__BB6_27:
	and.b64  	%rd98, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd98, 0;
	@%p14 bra 	$L__BB6_29;

	div.u64 	%rd134, %rd126, %rd64;
	mul.lo.s64 	%rd99, %rd134, %rd64;
	sub.s64 	%rd135, %rd126, %rd99;
	bra.uni 	$L__BB6_30;

$L__BB6_29:
	cvt.u32.u64 	%r35, %rd126;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd134, %r36;
	cvt.u64.u32 	%rd135, %r38;

$L__BB6_30:
	or.b64  	%rd100, %rd134, %rd63;
	and.b64  	%rd101, %rd100, -4294967296;
	setp.eq.s64 	%p15, %rd101, 0;
	@%p15 bra 	$L__BB6_32;

	rem.u64 	%rd136, %rd134, %rd63;
	bra.uni 	$L__BB6_33;

$L__BB6_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd134;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd136, %r41;

$L__BB6_33:
	shl.b64 	%rd102, %rd136, 2;
	add.s64 	%rd43, %rd3, %rd102;
	ld.global.u32 	%rd137, [%rd43];
	setp.eq.s64 	%p16, %rd137, 4294967295;
	shl.b64 	%rd103, %rd126, 3;
	add.s64 	%rd45, %rd1, %rd103;
	@%p16 bra 	$L__BB6_42;

	setp.lt.u64 	%p17, %rd137, %rd62;
	@%p17 bra 	$L__BB6_36;

	mov.u64 	%rd104, $str;
	cvta.global.u64 	%rd105, %rd104;
	mov.u64 	%rd106, $str$1;
	cvta.global.u64 	%rd107, %rd106;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd105;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd107;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 13
	ld.global.u32 	%rd137, [%rd43];

$L__BB6_36:
	mul.lo.s64 	%rd108, %rd133, %rd62;
	add.s64 	%rd109, %rd108, %rd137;
	mul.lo.s64 	%rd110, %rd109, %rd64;
	add.s64 	%rd138, %rd110, %rd135;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB6_41;

$L__BB6_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd111, %r45;
	add.s64 	%rd112, %rd111, %rd61;
	and.b64  	%rd50, %rd138, 4294967295;
	shl.b64 	%rd113, %rd112, 3;
	and.b64  	%rd114, %rd113, 34359738360;
	add.s64 	%rd51, %rd4, %rd114;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd115, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd115, 0;
	@%p19 bra 	$L__BB6_39;

	div.u64 	%rd138, %rd50, %rd52;
	mul.lo.s64 	%rd116, %rd138, %rd52;
	sub.s64 	%rd140, %rd50, %rd116;
	bra.uni 	$L__BB6_40;

$L__BB6_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd138, %r48;
	cvt.u64.u32 	%rd140, %r50;

$L__BB6_40:
	shl.b64 	%rd117, %rd61, 3;
	add.s64 	%rd118, %rd51, %rd117;
	ld.global.u64 	%rd119, [%rd118];
	mul.lo.s64 	%rd120, %rd119, %rd140;
	cvt.u32.u64 	%r51, %rd120;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd121, %r55;
	setp.lt.u64 	%p20, %rd121, %rd61;
	@%p20 bra 	$L__BB6_37;

$L__BB6_41:
	mul.wide.u32 	%rd122, %r56, 8;
	add.s64 	%rd123, %rd2, %rd122;
	ld.global.f64 	%fd2, [%rd123];
	st.global.f64 	[%rd45], %fd2;
	bra.uni 	$L__BB6_43;

$L__BB6_42:
	mov.u64 	%rd124, 0;
	st.global.u64 	[%rd45], %rd124;

$L__BB6_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd126, %r53;
	setp.lt.u64 	%p21, %rd126, %rd60;
	@%p21 bra 	$L__BB6_24;

$L__BB6_44:
	ret;

}
	// .globl	is_u32_u8
.visible .entry is_u32_u8(
	.param .u64 is_u32_u8_param_0,
	.param .u64 is_u32_u8_param_1,
	.param .u64 is_u32_u8_param_2,
	.param .u64 is_u32_u8_param_3,
	.param .u64 is_u32_u8_param_4,
	.param .u64 is_u32_u8_param_5,
	.param .u64 is_u32_u8_param_6,
	.param .u64 is_u32_u8_param_7,
	.param .u64 is_u32_u8_param_8,
	.param .u64 is_u32_u8_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<136>;


	ld.param.u64 	%rd60, [is_u32_u8_param_0];
	ld.param.u64 	%rd61, [is_u32_u8_param_1];
	ld.param.u64 	%rd65, [is_u32_u8_param_2];
	ld.param.u64 	%rd66, [is_u32_u8_param_3];
	ld.param.u64 	%rd67, [is_u32_u8_param_4];
	ld.param.u64 	%rd68, [is_u32_u8_param_5];
	ld.param.u64 	%rd62, [is_u32_u8_param_7];
	ld.param.u64 	%rd63, [is_u32_u8_param_8];
	ld.param.u64 	%rd64, [is_u32_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs9, %rs2;
	@%p1 bra 	$L__BB7_5;

	mov.u64 	%rd120, 1;
	mov.u32 	%r52, 0;

$L__BB7_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB7_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd120, %rd76;
	mov.u16 	%rs9, 0;
	@%p3 bra 	$L__BB7_5;

$L__BB7_4:
	mul.lo.s64 	%rd120, %rd7, %rd120;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs9, %rs2;
	@%p4 bra 	$L__BB7_2;

$L__BB7_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd121, %r53;
	setp.ge.u64 	%p5, %rd121, %rd60;
	@%p5 bra 	$L__BB7_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs9, 0;
	@%p6 bra 	$L__BB7_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB7_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB7_10;

	div.u64 	%rd122, %rd121, %rd10;
	bra.uni 	$L__BB7_11;

$L__BB7_10:
	cvt.u32.u64 	%r21, %rd121;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd122, %r22;

$L__BB7_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB7_13;

	div.u64 	%rd123, %rd121, %rd64;
	mul.lo.s64 	%rd80, %rd123, %rd64;
	sub.s64 	%rd124, %rd121, %rd80;
	bra.uni 	$L__BB7_14;

$L__BB7_13:
	cvt.u32.u64 	%r24, %rd121;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd123, %r25;
	cvt.u64.u32 	%rd124, %r27;

$L__BB7_14:
	or.b64  	%rd81, %rd123, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB7_16;

	rem.u64 	%rd125, %rd123, %rd63;
	bra.uni 	$L__BB7_17;

$L__BB7_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd123;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd125, %r30;

$L__BB7_17:
	shl.b64 	%rd83, %rd125, 2;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u32 	%rd126, [%rd24];
	setp.eq.s64 	%p10, %rd126, 4294967295;
	add.s64 	%rd26, %rd1, %rd121;
	@%p10 bra 	$L__BB7_21;

	setp.lt.u64 	%p11, %rd126, %rd62;
	@%p11 bra 	$L__BB7_20;

	mov.u64 	%rd84, $str;
	cvta.global.u64 	%rd85, %rd84;
	mov.u64 	%rd86, $str$1;
	cvta.global.u64 	%rd87, %rd86;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 14
	ld.global.u32 	%rd126, [%rd24];

$L__BB7_20:
	mul.lo.s64 	%rd88, %rd122, %rd62;
	add.s64 	%rd89, %rd88, %rd126;
	mul.lo.s64 	%rd90, %rd89, %rd64;
	add.s64 	%rd91, %rd90, %rd124;
	and.b64  	%rd92, %rd91, 4294967295;
	add.s64 	%rd93, %rd2, %rd92;
	ld.global.u8 	%rs5, [%rd93];
	st.global.u8 	[%rd26], %rs5;
	bra.uni 	$L__BB7_22;

$L__BB7_21:
	mov.u16 	%rs6, 0;
	st.global.u8 	[%rd26], %rs6;

$L__BB7_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd121, %r53;
	setp.lt.u64 	%p12, %rd121, %rd60;
	@%p12 bra 	$L__BB7_8;
	bra.uni 	$L__BB7_44;

$L__BB7_23:
	and.b64  	%rd94, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB7_24:
	setp.eq.s64 	%p13, %rd94, 0;
	@%p13 bra 	$L__BB7_26;

	div.u64 	%rd128, %rd121, %rd10;
	bra.uni 	$L__BB7_27;

$L__BB7_26:
	cvt.u32.u64 	%r32, %rd121;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd128, %r33;

$L__BB7_27:
	and.b64  	%rd95, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd95, 0;
	@%p14 bra 	$L__BB7_29;

	div.u64 	%rd129, %rd121, %rd64;
	mul.lo.s64 	%rd96, %rd129, %rd64;
	sub.s64 	%rd130, %rd121, %rd96;
	bra.uni 	$L__BB7_30;

$L__BB7_29:
	cvt.u32.u64 	%r35, %rd121;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd129, %r36;
	cvt.u64.u32 	%rd130, %r38;

$L__BB7_30:
	or.b64  	%rd97, %rd129, %rd63;
	and.b64  	%rd98, %rd97, -4294967296;
	setp.eq.s64 	%p15, %rd98, 0;
	@%p15 bra 	$L__BB7_32;

	rem.u64 	%rd131, %rd129, %rd63;
	bra.uni 	$L__BB7_33;

$L__BB7_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd129;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd131, %r41;

$L__BB7_33:
	shl.b64 	%rd99, %rd131, 2;
	add.s64 	%rd43, %rd3, %rd99;
	ld.global.u32 	%rd132, [%rd43];
	setp.eq.s64 	%p16, %rd132, 4294967295;
	add.s64 	%rd45, %rd1, %rd121;
	@%p16 bra 	$L__BB7_42;

	setp.lt.u64 	%p17, %rd132, %rd62;
	@%p17 bra 	$L__BB7_36;

	mov.u64 	%rd100, $str;
	cvta.global.u64 	%rd101, %rd100;
	mov.u64 	%rd102, $str$1;
	cvta.global.u64 	%rd103, %rd102;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd101;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 15
	ld.global.u32 	%rd132, [%rd43];

$L__BB7_36:
	mul.lo.s64 	%rd104, %rd128, %rd62;
	add.s64 	%rd105, %rd104, %rd132;
	mul.lo.s64 	%rd106, %rd105, %rd64;
	add.s64 	%rd133, %rd106, %rd130;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB7_41;

$L__BB7_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd107, %r45;
	add.s64 	%rd108, %rd107, %rd61;
	and.b64  	%rd50, %rd133, 4294967295;
	shl.b64 	%rd109, %rd108, 3;
	and.b64  	%rd110, %rd109, 34359738360;
	add.s64 	%rd51, %rd4, %rd110;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd111, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd111, 0;
	@%p19 bra 	$L__BB7_39;

	div.u64 	%rd133, %rd50, %rd52;
	mul.lo.s64 	%rd112, %rd133, %rd52;
	sub.s64 	%rd135, %rd50, %rd112;
	bra.uni 	$L__BB7_40;

$L__BB7_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd133, %r48;
	cvt.u64.u32 	%rd135, %r50;

$L__BB7_40:
	shl.b64 	%rd113, %rd61, 3;
	add.s64 	%rd114, %rd51, %rd113;
	ld.global.u64 	%rd115, [%rd114];
	mul.lo.s64 	%rd116, %rd115, %rd135;
	cvt.u32.u64 	%r51, %rd116;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd117, %r55;
	setp.lt.u64 	%p20, %rd117, %rd61;
	@%p20 bra 	$L__BB7_37;

$L__BB7_41:
	cvt.u64.u32 	%rd118, %r56;
	add.s64 	%rd119, %rd2, %rd118;
	ld.global.u8 	%rs7, [%rd119];
	st.global.u8 	[%rd45], %rs7;
	bra.uni 	$L__BB7_43;

$L__BB7_42:
	mov.u16 	%rs8, 0;
	st.global.u8 	[%rd45], %rs8;

$L__BB7_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd121, %r53;
	setp.lt.u64 	%p21, %rd121, %rd60;
	@%p21 bra 	$L__BB7_24;

$L__BB7_44:
	ret;

}
	// .globl	is_u32_i64
.visible .entry is_u32_i64(
	.param .u64 is_u32_i64_param_0,
	.param .u64 is_u32_i64_param_1,
	.param .u64 is_u32_i64_param_2,
	.param .u64 is_u32_i64_param_3,
	.param .u64 is_u32_i64_param_4,
	.param .u64 is_u32_i64_param_5,
	.param .u64 is_u32_i64_param_6,
	.param .u64 is_u32_i64_param_7,
	.param .u64 is_u32_i64_param_8,
	.param .u64 is_u32_i64_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<143>;


	ld.param.u64 	%rd60, [is_u32_i64_param_0];
	ld.param.u64 	%rd61, [is_u32_i64_param_1];
	ld.param.u64 	%rd65, [is_u32_i64_param_2];
	ld.param.u64 	%rd66, [is_u32_i64_param_3];
	ld.param.u64 	%rd67, [is_u32_i64_param_4];
	ld.param.u64 	%rd68, [is_u32_i64_param_5];
	ld.param.u64 	%rd62, [is_u32_i64_param_7];
	ld.param.u64 	%rd63, [is_u32_i64_param_8];
	ld.param.u64 	%rd64, [is_u32_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB8_5;

	mov.u64 	%rd127, 1;
	mov.u32 	%r52, 0;

$L__BB8_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB8_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd127, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB8_5;

$L__BB8_4:
	mul.lo.s64 	%rd127, %rd7, %rd127;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB8_2;

$L__BB8_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd128, %r53;
	setp.ge.u64 	%p5, %rd128, %rd60;
	@%p5 bra 	$L__BB8_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB8_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB8_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB8_10;

	div.u64 	%rd129, %rd128, %rd10;
	bra.uni 	$L__BB8_11;

$L__BB8_10:
	cvt.u32.u64 	%r21, %rd128;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd129, %r22;

$L__BB8_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB8_13;

	div.u64 	%rd130, %rd128, %rd64;
	mul.lo.s64 	%rd80, %rd130, %rd64;
	sub.s64 	%rd131, %rd128, %rd80;
	bra.uni 	$L__BB8_14;

$L__BB8_13:
	cvt.u32.u64 	%r24, %rd128;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd130, %r25;
	cvt.u64.u32 	%rd131, %r27;

$L__BB8_14:
	or.b64  	%rd81, %rd130, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB8_16;

	rem.u64 	%rd132, %rd130, %rd63;
	bra.uni 	$L__BB8_17;

$L__BB8_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd130;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd132, %r30;

$L__BB8_17:
	shl.b64 	%rd83, %rd132, 2;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u32 	%rd133, [%rd24];
	setp.eq.s64 	%p10, %rd133, 4294967295;
	shl.b64 	%rd84, %rd128, 3;
	add.s64 	%rd26, %rd1, %rd84;
	@%p10 bra 	$L__BB8_21;

	setp.lt.u64 	%p11, %rd133, %rd62;
	@%p11 bra 	$L__BB8_20;

	mov.u64 	%rd85, $str;
	cvta.global.u64 	%rd86, %rd85;
	mov.u64 	%rd87, $str$1;
	cvta.global.u64 	%rd88, %rd87;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 16
	ld.global.u32 	%rd133, [%rd24];

$L__BB8_20:
	mul.lo.s64 	%rd89, %rd129, %rd62;
	add.s64 	%rd90, %rd89, %rd133;
	mul.lo.s64 	%rd91, %rd90, %rd64;
	add.s64 	%rd92, %rd91, %rd131;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd95, %rd2, %rd94;
	ld.global.u64 	%rd96, [%rd95];
	st.global.u64 	[%rd26], %rd96;
	bra.uni 	$L__BB8_22;

$L__BB8_21:
	mov.u64 	%rd97, 0;
	st.global.u64 	[%rd26], %rd97;

$L__BB8_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd128, %r53;
	setp.lt.u64 	%p12, %rd128, %rd60;
	@%p12 bra 	$L__BB8_8;
	bra.uni 	$L__BB8_44;

$L__BB8_23:
	and.b64  	%rd98, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB8_24:
	setp.eq.s64 	%p13, %rd98, 0;
	@%p13 bra 	$L__BB8_26;

	div.u64 	%rd135, %rd128, %rd10;
	bra.uni 	$L__BB8_27;

$L__BB8_26:
	cvt.u32.u64 	%r32, %rd128;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd135, %r33;

$L__BB8_27:
	and.b64  	%rd99, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd99, 0;
	@%p14 bra 	$L__BB8_29;

	div.u64 	%rd136, %rd128, %rd64;
	mul.lo.s64 	%rd100, %rd136, %rd64;
	sub.s64 	%rd137, %rd128, %rd100;
	bra.uni 	$L__BB8_30;

$L__BB8_29:
	cvt.u32.u64 	%r35, %rd128;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd136, %r36;
	cvt.u64.u32 	%rd137, %r38;

$L__BB8_30:
	or.b64  	%rd101, %rd136, %rd63;
	and.b64  	%rd102, %rd101, -4294967296;
	setp.eq.s64 	%p15, %rd102, 0;
	@%p15 bra 	$L__BB8_32;

	rem.u64 	%rd138, %rd136, %rd63;
	bra.uni 	$L__BB8_33;

$L__BB8_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd136;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd138, %r41;

$L__BB8_33:
	shl.b64 	%rd103, %rd138, 2;
	add.s64 	%rd43, %rd3, %rd103;
	ld.global.u32 	%rd139, [%rd43];
	setp.eq.s64 	%p16, %rd139, 4294967295;
	shl.b64 	%rd104, %rd128, 3;
	add.s64 	%rd45, %rd1, %rd104;
	@%p16 bra 	$L__BB8_42;

	setp.lt.u64 	%p17, %rd139, %rd62;
	@%p17 bra 	$L__BB8_36;

	mov.u64 	%rd105, $str;
	cvta.global.u64 	%rd106, %rd105;
	mov.u64 	%rd107, $str$1;
	cvta.global.u64 	%rd108, %rd107;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd106;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd108;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 17
	ld.global.u32 	%rd139, [%rd43];

$L__BB8_36:
	mul.lo.s64 	%rd109, %rd135, %rd62;
	add.s64 	%rd110, %rd109, %rd139;
	mul.lo.s64 	%rd111, %rd110, %rd64;
	add.s64 	%rd140, %rd111, %rd137;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB8_41;

$L__BB8_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd112, %r45;
	add.s64 	%rd113, %rd112, %rd61;
	and.b64  	%rd50, %rd140, 4294967295;
	shl.b64 	%rd114, %rd113, 3;
	and.b64  	%rd115, %rd114, 34359738360;
	add.s64 	%rd51, %rd4, %rd115;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd116, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd116, 0;
	@%p19 bra 	$L__BB8_39;

	div.u64 	%rd140, %rd50, %rd52;
	mul.lo.s64 	%rd117, %rd140, %rd52;
	sub.s64 	%rd142, %rd50, %rd117;
	bra.uni 	$L__BB8_40;

$L__BB8_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd140, %r48;
	cvt.u64.u32 	%rd142, %r50;

$L__BB8_40:
	shl.b64 	%rd118, %rd61, 3;
	add.s64 	%rd119, %rd51, %rd118;
	ld.global.u64 	%rd120, [%rd119];
	mul.lo.s64 	%rd121, %rd120, %rd142;
	cvt.u32.u64 	%r51, %rd121;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd122, %r55;
	setp.lt.u64 	%p20, %rd122, %rd61;
	@%p20 bra 	$L__BB8_37;

$L__BB8_41:
	mul.wide.u32 	%rd123, %r56, 8;
	add.s64 	%rd124, %rd2, %rd123;
	ld.global.u64 	%rd125, [%rd124];
	st.global.u64 	[%rd45], %rd125;
	bra.uni 	$L__BB8_43;

$L__BB8_42:
	mov.u64 	%rd126, 0;
	st.global.u64 	[%rd45], %rd126;

$L__BB8_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd128, %r53;
	setp.lt.u64 	%p21, %rd128, %rd60;
	@%p21 bra 	$L__BB8_24;

$L__BB8_44:
	ret;

}
	// .globl	is_u32_u32
.visible .entry is_u32_u32(
	.param .u64 is_u32_u32_param_0,
	.param .u64 is_u32_u32_param_1,
	.param .u64 is_u32_u32_param_2,
	.param .u64 is_u32_u32_param_3,
	.param .u64 is_u32_u32_param_4,
	.param .u64 is_u32_u32_param_5,
	.param .u64 is_u32_u32_param_6,
	.param .u64 is_u32_u32_param_7,
	.param .u64 is_u32_u32_param_8,
	.param .u64 is_u32_u32_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<139>;


	ld.param.u64 	%rd60, [is_u32_u32_param_0];
	ld.param.u64 	%rd61, [is_u32_u32_param_1];
	ld.param.u64 	%rd65, [is_u32_u32_param_2];
	ld.param.u64 	%rd66, [is_u32_u32_param_3];
	ld.param.u64 	%rd67, [is_u32_u32_param_4];
	ld.param.u64 	%rd68, [is_u32_u32_param_5];
	ld.param.u64 	%rd62, [is_u32_u32_param_7];
	ld.param.u64 	%rd63, [is_u32_u32_param_8];
	ld.param.u64 	%rd64, [is_u32_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB9_5;

	mov.u64 	%rd123, 1;
	mov.u32 	%r56, 0;

$L__BB9_2:
	not.b32 	%r16, %r56;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB9_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd123, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB9_5;

$L__BB9_4:
	mul.lo.s64 	%rd123, %rd7, %rd123;
	add.s32 	%r56, %r56, 1;
	cvt.u64.u32 	%rd77, %r56;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB9_2;

$L__BB9_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r57, %r17, %r3, %r18;
	cvt.u64.u32 	%rd124, %r57;
	setp.ge.u64 	%p5, %rd124, %rd60;
	@%p5 bra 	$L__BB9_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB9_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB9_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB9_10;

	div.u64 	%rd125, %rd124, %rd10;
	bra.uni 	$L__BB9_11;

$L__BB9_10:
	cvt.u32.u64 	%r21, %rd124;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd125, %r22;

$L__BB9_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB9_13;

	div.u64 	%rd126, %rd124, %rd64;
	mul.lo.s64 	%rd80, %rd126, %rd64;
	sub.s64 	%rd127, %rd124, %rd80;
	bra.uni 	$L__BB9_14;

$L__BB9_13:
	cvt.u32.u64 	%r24, %rd124;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd126, %r25;
	cvt.u64.u32 	%rd127, %r27;

$L__BB9_14:
	or.b64  	%rd81, %rd126, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB9_16;

	rem.u64 	%rd128, %rd126, %rd63;
	bra.uni 	$L__BB9_17;

$L__BB9_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd126;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd128, %r30;

$L__BB9_17:
	shl.b64 	%rd83, %rd128, 2;
	add.s64 	%rd24, %rd3, %rd83;
	ld.global.u32 	%rd129, [%rd24];
	setp.eq.s64 	%p10, %rd129, 4294967295;
	shl.b64 	%rd84, %rd124, 2;
	add.s64 	%rd26, %rd1, %rd84;
	@%p10 bra 	$L__BB9_21;

	setp.lt.u64 	%p11, %rd129, %rd62;
	@%p11 bra 	$L__BB9_20;

	mov.u64 	%rd85, $str;
	cvta.global.u64 	%rd86, %rd85;
	mov.u64 	%rd87, $str$1;
	cvta.global.u64 	%rd88, %rd87;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 18
	ld.global.u32 	%rd129, [%rd24];

$L__BB9_20:
	mul.lo.s64 	%rd89, %rd125, %rd62;
	add.s64 	%rd90, %rd89, %rd129;
	mul.lo.s64 	%rd91, %rd90, %rd64;
	add.s64 	%rd92, %rd91, %rd127;
	shl.b64 	%rd93, %rd92, 2;
	and.b64  	%rd94, %rd93, 17179869180;
	add.s64 	%rd95, %rd2, %rd94;
	ld.global.u32 	%r31, [%rd95];
	st.global.u32 	[%rd26], %r31;
	bra.uni 	$L__BB9_22;

$L__BB9_21:
	mov.u32 	%r32, 0;
	st.global.u32 	[%rd26], %r32;

$L__BB9_22:
	add.s32 	%r57, %r57, %r5;
	cvt.u64.u32 	%rd124, %r57;
	setp.lt.u64 	%p12, %rd124, %rd60;
	@%p12 bra 	$L__BB9_8;
	bra.uni 	$L__BB9_44;

$L__BB9_23:
	and.b64  	%rd96, %rd10, -4294967296;
	cvt.u32.u64 	%r33, %rd10;
	cvt.u32.u64 	%r36, %rd64;

$L__BB9_24:
	setp.eq.s64 	%p13, %rd96, 0;
	@%p13 bra 	$L__BB9_26;

	div.u64 	%rd131, %rd124, %rd10;
	bra.uni 	$L__BB9_27;

$L__BB9_26:
	cvt.u32.u64 	%r34, %rd124;
	div.u32 	%r35, %r34, %r33;
	cvt.u64.u32 	%rd131, %r35;

$L__BB9_27:
	and.b64  	%rd97, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd97, 0;
	@%p14 bra 	$L__BB9_29;

	div.u64 	%rd132, %rd124, %rd64;
	mul.lo.s64 	%rd98, %rd132, %rd64;
	sub.s64 	%rd133, %rd124, %rd98;
	bra.uni 	$L__BB9_30;

$L__BB9_29:
	cvt.u32.u64 	%r37, %rd124;
	div.u32 	%r38, %r37, %r36;
	mul.lo.s32 	%r39, %r38, %r36;
	sub.s32 	%r40, %r37, %r39;
	cvt.u64.u32 	%rd132, %r38;
	cvt.u64.u32 	%rd133, %r40;

$L__BB9_30:
	or.b64  	%rd99, %rd132, %rd63;
	and.b64  	%rd100, %rd99, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB9_32;

	rem.u64 	%rd134, %rd132, %rd63;
	bra.uni 	$L__BB9_33;

$L__BB9_32:
	cvt.u32.u64 	%r41, %rd63;
	cvt.u32.u64 	%r42, %rd132;
	rem.u32 	%r43, %r42, %r41;
	cvt.u64.u32 	%rd134, %r43;

$L__BB9_33:
	shl.b64 	%rd101, %rd134, 2;
	add.s64 	%rd43, %rd3, %rd101;
	ld.global.u32 	%rd135, [%rd43];
	setp.eq.s64 	%p16, %rd135, 4294967295;
	shl.b64 	%rd102, %rd124, 2;
	add.s64 	%rd45, %rd1, %rd102;
	@%p16 bra 	$L__BB9_42;

	setp.lt.u64 	%p17, %rd135, %rd62;
	@%p17 bra 	$L__BB9_36;

	mov.u64 	%rd103, $str;
	cvta.global.u64 	%rd104, %rd103;
	mov.u64 	%rd105, $str$1;
	cvta.global.u64 	%rd106, %rd105;
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd104;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd106;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 19
	ld.global.u32 	%rd135, [%rd43];

$L__BB9_36:
	mul.lo.s64 	%rd107, %rd131, %rd62;
	add.s64 	%rd108, %rd107, %rd135;
	mul.lo.s64 	%rd109, %rd108, %rd64;
	add.s64 	%rd136, %rd109, %rd133;
	mov.u32 	%r59, 0;
	mov.u32 	%r60, %r59;
	@%p1 bra 	$L__BB9_41;

$L__BB9_37:
	not.b32 	%r47, %r59;
	cvt.u64.u32 	%rd110, %r47;
	add.s64 	%rd111, %rd110, %rd61;
	and.b64  	%rd50, %rd136, 4294967295;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd51, %rd4, %rd113;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd114, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd114, 0;
	@%p19 bra 	$L__BB9_39;

	div.u64 	%rd136, %rd50, %rd52;
	mul.lo.s64 	%rd115, %rd136, %rd52;
	sub.s64 	%rd138, %rd50, %rd115;
	bra.uni 	$L__BB9_40;

$L__BB9_39:
	cvt.u32.u64 	%r48, %rd52;
	cvt.u32.u64 	%r49, %rd50;
	div.u32 	%r50, %r49, %r48;
	mul.lo.s32 	%r51, %r50, %r48;
	sub.s32 	%r52, %r49, %r51;
	cvt.u64.u32 	%rd136, %r50;
	cvt.u64.u32 	%rd138, %r52;

$L__BB9_40:
	shl.b64 	%rd116, %rd61, 3;
	add.s64 	%rd117, %rd51, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd138;
	cvt.u32.u64 	%r53, %rd119;
	add.s32 	%r60, %r60, %r53;
	add.s32 	%r59, %r59, 1;
	cvt.u64.u32 	%rd120, %r59;
	setp.lt.u64 	%p20, %rd120, %rd61;
	@%p20 bra 	$L__BB9_37;

$L__BB9_41:
	mul.wide.u32 	%rd121, %r60, 4;
	add.s64 	%rd122, %rd2, %rd121;
	ld.global.u32 	%r54, [%rd122];
	st.global.u32 	[%rd45], %r54;
	bra.uni 	$L__BB9_43;

$L__BB9_42:
	mov.u32 	%r55, 0;
	st.global.u32 	[%rd45], %r55;

$L__BB9_43:
	add.s32 	%r57, %r57, %r5;
	cvt.u64.u32 	%rd124, %r57;
	setp.lt.u64 	%p21, %rd124, %rd60;
	@%p21 bra 	$L__BB9_24;

$L__BB9_44:
	ret;

}
	// .globl	is_u8_f32
.visible .entry is_u8_f32(
	.param .u64 is_u8_f32_param_0,
	.param .u64 is_u8_f32_param_1,
	.param .u64 is_u8_f32_param_2,
	.param .u64 is_u8_f32_param_3,
	.param .u64 is_u8_f32_param_4,
	.param .u64 is_u8_f32_param_5,
	.param .u64 is_u8_f32_param_6,
	.param .u64 is_u8_f32_param_7,
	.param .u64 is_u8_f32_param_8,
	.param .u64 is_u8_f32_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<137>;


	ld.param.u64 	%rd60, [is_u8_f32_param_0];
	ld.param.u64 	%rd61, [is_u8_f32_param_1];
	ld.param.u64 	%rd65, [is_u8_f32_param_2];
	ld.param.u64 	%rd66, [is_u8_f32_param_3];
	ld.param.u64 	%rd67, [is_u8_f32_param_4];
	ld.param.u64 	%rd68, [is_u8_f32_param_5];
	ld.param.u64 	%rd62, [is_u8_f32_param_7];
	ld.param.u64 	%rd63, [is_u8_f32_param_8];
	ld.param.u64 	%rd64, [is_u8_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB10_5;

	mov.u64 	%rd121, 1;
	mov.u32 	%r54, 0;

$L__BB10_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB10_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd121, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB10_5;

$L__BB10_4:
	mul.lo.s64 	%rd121, %rd7, %rd121;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd77, %r54;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB10_2;

$L__BB10_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd122, %r55;
	setp.ge.u64 	%p5, %rd122, %rd60;
	@%p5 bra 	$L__BB10_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB10_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB10_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB10_10;

	div.u64 	%rd123, %rd122, %rd10;
	bra.uni 	$L__BB10_11;

$L__BB10_10:
	cvt.u32.u64 	%r21, %rd122;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd123, %r22;

$L__BB10_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB10_13;

	div.u64 	%rd124, %rd122, %rd64;
	mul.lo.s64 	%rd80, %rd124, %rd64;
	sub.s64 	%rd125, %rd122, %rd80;
	bra.uni 	$L__BB10_14;

$L__BB10_13:
	cvt.u32.u64 	%r24, %rd122;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd124, %r25;
	cvt.u64.u32 	%rd125, %r27;

$L__BB10_14:
	or.b64  	%rd81, %rd124, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB10_16;

	rem.u64 	%rd126, %rd124, %rd63;
	bra.uni 	$L__BB10_17;

$L__BB10_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd124;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd126, %r30;

$L__BB10_17:
	add.s64 	%rd24, %rd3, %rd126;
	ld.global.u8 	%rd127, [%rd24];
	setp.eq.s64 	%p10, %rd127, 255;
	shl.b64 	%rd83, %rd122, 2;
	add.s64 	%rd26, %rd1, %rd83;
	@%p10 bra 	$L__BB10_21;

	setp.lt.u64 	%p11, %rd127, %rd62;
	@%p11 bra 	$L__BB10_20;

	mov.u64 	%rd84, $str;
	cvta.global.u64 	%rd85, %rd84;
	mov.u64 	%rd86, $str$1;
	cvta.global.u64 	%rd87, %rd86;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 20
	ld.global.u8 	%rd127, [%rd24];

$L__BB10_20:
	mul.lo.s64 	%rd88, %rd123, %rd62;
	add.s64 	%rd89, %rd88, %rd127;
	mul.lo.s64 	%rd90, %rd89, %rd64;
	add.s64 	%rd91, %rd90, %rd125;
	shl.b64 	%rd92, %rd91, 2;
	and.b64  	%rd93, %rd92, 17179869180;
	add.s64 	%rd94, %rd2, %rd93;
	ld.global.f32 	%f1, [%rd94];
	st.global.f32 	[%rd26], %f1;
	bra.uni 	$L__BB10_22;

$L__BB10_21:
	mov.u32 	%r31, 0;
	st.global.u32 	[%rd26], %r31;

$L__BB10_22:
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd122, %r55;
	setp.lt.u64 	%p12, %rd122, %rd60;
	@%p12 bra 	$L__BB10_8;
	bra.uni 	$L__BB10_44;

$L__BB10_23:
	and.b64  	%rd95, %rd10, -4294967296;
	cvt.u32.u64 	%r32, %rd10;
	cvt.u32.u64 	%r35, %rd64;

$L__BB10_24:
	setp.eq.s64 	%p13, %rd95, 0;
	@%p13 bra 	$L__BB10_26;

	div.u64 	%rd129, %rd122, %rd10;
	bra.uni 	$L__BB10_27;

$L__BB10_26:
	cvt.u32.u64 	%r33, %rd122;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd129, %r34;

$L__BB10_27:
	and.b64  	%rd96, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd96, 0;
	@%p14 bra 	$L__BB10_29;

	div.u64 	%rd130, %rd122, %rd64;
	mul.lo.s64 	%rd97, %rd130, %rd64;
	sub.s64 	%rd131, %rd122, %rd97;
	bra.uni 	$L__BB10_30;

$L__BB10_29:
	cvt.u32.u64 	%r36, %rd122;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd130, %r37;
	cvt.u64.u32 	%rd131, %r39;

$L__BB10_30:
	or.b64  	%rd98, %rd130, %rd63;
	and.b64  	%rd99, %rd98, -4294967296;
	setp.eq.s64 	%p15, %rd99, 0;
	@%p15 bra 	$L__BB10_32;

	rem.u64 	%rd132, %rd130, %rd63;
	bra.uni 	$L__BB10_33;

$L__BB10_32:
	cvt.u32.u64 	%r40, %rd63;
	cvt.u32.u64 	%r41, %rd130;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd132, %r42;

$L__BB10_33:
	add.s64 	%rd43, %rd3, %rd132;
	ld.global.u8 	%rd133, [%rd43];
	setp.eq.s64 	%p16, %rd133, 255;
	shl.b64 	%rd100, %rd122, 2;
	add.s64 	%rd45, %rd1, %rd100;
	@%p16 bra 	$L__BB10_42;

	setp.lt.u64 	%p17, %rd133, %rd62;
	@%p17 bra 	$L__BB10_36;

	mov.u64 	%rd101, $str;
	cvta.global.u64 	%rd102, %rd101;
	mov.u64 	%rd103, $str$1;
	cvta.global.u64 	%rd104, %rd103;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd102;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd104;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 21
	ld.global.u8 	%rd133, [%rd43];

$L__BB10_36:
	mul.lo.s64 	%rd105, %rd129, %rd62;
	add.s64 	%rd106, %rd105, %rd133;
	mul.lo.s64 	%rd107, %rd106, %rd64;
	add.s64 	%rd134, %rd107, %rd131;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB10_41;

$L__BB10_37:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd108, %r46;
	add.s64 	%rd109, %rd108, %rd61;
	and.b64  	%rd50, %rd134, 4294967295;
	shl.b64 	%rd110, %rd109, 3;
	and.b64  	%rd111, %rd110, 34359738360;
	add.s64 	%rd51, %rd4, %rd111;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd112, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd112, 0;
	@%p19 bra 	$L__BB10_39;

	div.u64 	%rd134, %rd50, %rd52;
	mul.lo.s64 	%rd113, %rd134, %rd52;
	sub.s64 	%rd136, %rd50, %rd113;
	bra.uni 	$L__BB10_40;

$L__BB10_39:
	cvt.u32.u64 	%r47, %rd52;
	cvt.u32.u64 	%r48, %rd50;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd134, %r49;
	cvt.u64.u32 	%rd136, %r51;

$L__BB10_40:
	shl.b64 	%rd114, %rd61, 3;
	add.s64 	%rd115, %rd51, %rd114;
	ld.global.u64 	%rd116, [%rd115];
	mul.lo.s64 	%rd117, %rd116, %rd136;
	cvt.u32.u64 	%r52, %rd117;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd118, %r57;
	setp.lt.u64 	%p20, %rd118, %rd61;
	@%p20 bra 	$L__BB10_37;

$L__BB10_41:
	mul.wide.u32 	%rd119, %r58, 4;
	add.s64 	%rd120, %rd2, %rd119;
	ld.global.f32 	%f2, [%rd120];
	st.global.f32 	[%rd45], %f2;
	bra.uni 	$L__BB10_43;

$L__BB10_42:
	mov.u32 	%r53, 0;
	st.global.u32 	[%rd45], %r53;

$L__BB10_43:
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd122, %r55;
	setp.lt.u64 	%p21, %rd122, %rd60;
	@%p21 bra 	$L__BB10_24;

$L__BB10_44:
	ret;

}
	// .globl	is_u8_f64
.visible .entry is_u8_f64(
	.param .u64 is_u8_f64_param_0,
	.param .u64 is_u8_f64_param_1,
	.param .u64 is_u8_f64_param_2,
	.param .u64 is_u8_f64_param_3,
	.param .u64 is_u8_f64_param_4,
	.param .u64 is_u8_f64_param_5,
	.param .u64 is_u8_f64_param_6,
	.param .u64 is_u8_f64_param_7,
	.param .u64 is_u8_f64_param_8,
	.param .u64 is_u8_f64_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<139>;


	ld.param.u64 	%rd60, [is_u8_f64_param_0];
	ld.param.u64 	%rd61, [is_u8_f64_param_1];
	ld.param.u64 	%rd65, [is_u8_f64_param_2];
	ld.param.u64 	%rd66, [is_u8_f64_param_3];
	ld.param.u64 	%rd67, [is_u8_f64_param_4];
	ld.param.u64 	%rd68, [is_u8_f64_param_5];
	ld.param.u64 	%rd62, [is_u8_f64_param_7];
	ld.param.u64 	%rd63, [is_u8_f64_param_8];
	ld.param.u64 	%rd64, [is_u8_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB11_5;

	mov.u64 	%rd123, 1;
	mov.u32 	%r52, 0;

$L__BB11_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB11_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd123, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB11_5;

$L__BB11_4:
	mul.lo.s64 	%rd123, %rd7, %rd123;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB11_2;

$L__BB11_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd124, %r53;
	setp.ge.u64 	%p5, %rd124, %rd60;
	@%p5 bra 	$L__BB11_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB11_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB11_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB11_10;

	div.u64 	%rd125, %rd124, %rd10;
	bra.uni 	$L__BB11_11;

$L__BB11_10:
	cvt.u32.u64 	%r21, %rd124;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd125, %r22;

$L__BB11_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB11_13;

	div.u64 	%rd126, %rd124, %rd64;
	mul.lo.s64 	%rd80, %rd126, %rd64;
	sub.s64 	%rd127, %rd124, %rd80;
	bra.uni 	$L__BB11_14;

$L__BB11_13:
	cvt.u32.u64 	%r24, %rd124;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd126, %r25;
	cvt.u64.u32 	%rd127, %r27;

$L__BB11_14:
	or.b64  	%rd81, %rd126, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB11_16;

	rem.u64 	%rd128, %rd126, %rd63;
	bra.uni 	$L__BB11_17;

$L__BB11_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd126;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd128, %r30;

$L__BB11_17:
	add.s64 	%rd24, %rd3, %rd128;
	ld.global.u8 	%rd129, [%rd24];
	setp.eq.s64 	%p10, %rd129, 255;
	shl.b64 	%rd83, %rd124, 3;
	add.s64 	%rd26, %rd1, %rd83;
	@%p10 bra 	$L__BB11_21;

	setp.lt.u64 	%p11, %rd129, %rd62;
	@%p11 bra 	$L__BB11_20;

	mov.u64 	%rd84, $str;
	cvta.global.u64 	%rd85, %rd84;
	mov.u64 	%rd86, $str$1;
	cvta.global.u64 	%rd87, %rd86;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 22
	ld.global.u8 	%rd129, [%rd24];

$L__BB11_20:
	mul.lo.s64 	%rd88, %rd125, %rd62;
	add.s64 	%rd89, %rd88, %rd129;
	mul.lo.s64 	%rd90, %rd89, %rd64;
	add.s64 	%rd91, %rd90, %rd127;
	shl.b64 	%rd92, %rd91, 3;
	and.b64  	%rd93, %rd92, 34359738360;
	add.s64 	%rd94, %rd2, %rd93;
	ld.global.f64 	%fd1, [%rd94];
	st.global.f64 	[%rd26], %fd1;
	bra.uni 	$L__BB11_22;

$L__BB11_21:
	mov.u64 	%rd95, 0;
	st.global.u64 	[%rd26], %rd95;

$L__BB11_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd124, %r53;
	setp.lt.u64 	%p12, %rd124, %rd60;
	@%p12 bra 	$L__BB11_8;
	bra.uni 	$L__BB11_44;

$L__BB11_23:
	and.b64  	%rd96, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB11_24:
	setp.eq.s64 	%p13, %rd96, 0;
	@%p13 bra 	$L__BB11_26;

	div.u64 	%rd131, %rd124, %rd10;
	bra.uni 	$L__BB11_27;

$L__BB11_26:
	cvt.u32.u64 	%r32, %rd124;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd131, %r33;

$L__BB11_27:
	and.b64  	%rd97, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd97, 0;
	@%p14 bra 	$L__BB11_29;

	div.u64 	%rd132, %rd124, %rd64;
	mul.lo.s64 	%rd98, %rd132, %rd64;
	sub.s64 	%rd133, %rd124, %rd98;
	bra.uni 	$L__BB11_30;

$L__BB11_29:
	cvt.u32.u64 	%r35, %rd124;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd132, %r36;
	cvt.u64.u32 	%rd133, %r38;

$L__BB11_30:
	or.b64  	%rd99, %rd132, %rd63;
	and.b64  	%rd100, %rd99, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB11_32;

	rem.u64 	%rd134, %rd132, %rd63;
	bra.uni 	$L__BB11_33;

$L__BB11_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd132;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd134, %r41;

$L__BB11_33:
	add.s64 	%rd43, %rd3, %rd134;
	ld.global.u8 	%rd135, [%rd43];
	setp.eq.s64 	%p16, %rd135, 255;
	shl.b64 	%rd101, %rd124, 3;
	add.s64 	%rd45, %rd1, %rd101;
	@%p16 bra 	$L__BB11_42;

	setp.lt.u64 	%p17, %rd135, %rd62;
	@%p17 bra 	$L__BB11_36;

	mov.u64 	%rd102, $str;
	cvta.global.u64 	%rd103, %rd102;
	mov.u64 	%rd104, $str$1;
	cvta.global.u64 	%rd105, %rd104;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd103;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd105;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 23
	ld.global.u8 	%rd135, [%rd43];

$L__BB11_36:
	mul.lo.s64 	%rd106, %rd131, %rd62;
	add.s64 	%rd107, %rd106, %rd135;
	mul.lo.s64 	%rd108, %rd107, %rd64;
	add.s64 	%rd136, %rd108, %rd133;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB11_41;

$L__BB11_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd109, %r45;
	add.s64 	%rd110, %rd109, %rd61;
	and.b64  	%rd50, %rd136, 4294967295;
	shl.b64 	%rd111, %rd110, 3;
	and.b64  	%rd112, %rd111, 34359738360;
	add.s64 	%rd51, %rd4, %rd112;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd113, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd113, 0;
	@%p19 bra 	$L__BB11_39;

	div.u64 	%rd136, %rd50, %rd52;
	mul.lo.s64 	%rd114, %rd136, %rd52;
	sub.s64 	%rd138, %rd50, %rd114;
	bra.uni 	$L__BB11_40;

$L__BB11_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd136, %r48;
	cvt.u64.u32 	%rd138, %r50;

$L__BB11_40:
	shl.b64 	%rd115, %rd61, 3;
	add.s64 	%rd116, %rd51, %rd115;
	ld.global.u64 	%rd117, [%rd116];
	mul.lo.s64 	%rd118, %rd117, %rd138;
	cvt.u32.u64 	%r51, %rd118;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd119, %r55;
	setp.lt.u64 	%p20, %rd119, %rd61;
	@%p20 bra 	$L__BB11_37;

$L__BB11_41:
	mul.wide.u32 	%rd120, %r56, 8;
	add.s64 	%rd121, %rd2, %rd120;
	ld.global.f64 	%fd2, [%rd121];
	st.global.f64 	[%rd45], %fd2;
	bra.uni 	$L__BB11_43;

$L__BB11_42:
	mov.u64 	%rd122, 0;
	st.global.u64 	[%rd45], %rd122;

$L__BB11_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd124, %r53;
	setp.lt.u64 	%p21, %rd124, %rd60;
	@%p21 bra 	$L__BB11_24;

$L__BB11_44:
	ret;

}
	// .globl	is_u8_u8
.visible .entry is_u8_u8(
	.param .u64 is_u8_u8_param_0,
	.param .u64 is_u8_u8_param_1,
	.param .u64 is_u8_u8_param_2,
	.param .u64 is_u8_u8_param_3,
	.param .u64 is_u8_u8_param_4,
	.param .u64 is_u8_u8_param_5,
	.param .u64 is_u8_u8_param_6,
	.param .u64 is_u8_u8_param_7,
	.param .u64 is_u8_u8_param_8,
	.param .u64 is_u8_u8_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<10>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<134>;


	ld.param.u64 	%rd60, [is_u8_u8_param_0];
	ld.param.u64 	%rd61, [is_u8_u8_param_1];
	ld.param.u64 	%rd65, [is_u8_u8_param_2];
	ld.param.u64 	%rd66, [is_u8_u8_param_3];
	ld.param.u64 	%rd67, [is_u8_u8_param_4];
	ld.param.u64 	%rd68, [is_u8_u8_param_5];
	ld.param.u64 	%rd62, [is_u8_u8_param_7];
	ld.param.u64 	%rd63, [is_u8_u8_param_8];
	ld.param.u64 	%rd64, [is_u8_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs9, %rs2;
	@%p1 bra 	$L__BB12_5;

	mov.u64 	%rd118, 1;
	mov.u32 	%r52, 0;

$L__BB12_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB12_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd118, %rd76;
	mov.u16 	%rs9, 0;
	@%p3 bra 	$L__BB12_5;

$L__BB12_4:
	mul.lo.s64 	%rd118, %rd7, %rd118;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs9, %rs2;
	@%p4 bra 	$L__BB12_2;

$L__BB12_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd119, %r53;
	setp.ge.u64 	%p5, %rd119, %rd60;
	@%p5 bra 	$L__BB12_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs9, 0;
	@%p6 bra 	$L__BB12_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB12_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB12_10;

	div.u64 	%rd120, %rd119, %rd10;
	bra.uni 	$L__BB12_11;

$L__BB12_10:
	cvt.u32.u64 	%r21, %rd119;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd120, %r22;

$L__BB12_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB12_13;

	div.u64 	%rd121, %rd119, %rd64;
	mul.lo.s64 	%rd80, %rd121, %rd64;
	sub.s64 	%rd122, %rd119, %rd80;
	bra.uni 	$L__BB12_14;

$L__BB12_13:
	cvt.u32.u64 	%r24, %rd119;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd121, %r25;
	cvt.u64.u32 	%rd122, %r27;

$L__BB12_14:
	or.b64  	%rd81, %rd121, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB12_16;

	rem.u64 	%rd123, %rd121, %rd63;
	bra.uni 	$L__BB12_17;

$L__BB12_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd121;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd123, %r30;

$L__BB12_17:
	add.s64 	%rd24, %rd3, %rd123;
	ld.global.u8 	%rd124, [%rd24];
	setp.eq.s64 	%p10, %rd124, 255;
	add.s64 	%rd26, %rd1, %rd119;
	@%p10 bra 	$L__BB12_21;

	setp.lt.u64 	%p11, %rd124, %rd62;
	@%p11 bra 	$L__BB12_20;

	mov.u64 	%rd83, $str;
	cvta.global.u64 	%rd84, %rd83;
	mov.u64 	%rd85, $str$1;
	cvta.global.u64 	%rd86, %rd85;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd84;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd86;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 24
	ld.global.u8 	%rd124, [%rd24];

$L__BB12_20:
	mul.lo.s64 	%rd87, %rd120, %rd62;
	add.s64 	%rd88, %rd87, %rd124;
	mul.lo.s64 	%rd89, %rd88, %rd64;
	add.s64 	%rd90, %rd89, %rd122;
	and.b64  	%rd91, %rd90, 4294967295;
	add.s64 	%rd92, %rd2, %rd91;
	ld.global.u8 	%rs5, [%rd92];
	st.global.u8 	[%rd26], %rs5;
	bra.uni 	$L__BB12_22;

$L__BB12_21:
	mov.u16 	%rs6, 0;
	st.global.u8 	[%rd26], %rs6;

$L__BB12_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd119, %r53;
	setp.lt.u64 	%p12, %rd119, %rd60;
	@%p12 bra 	$L__BB12_8;
	bra.uni 	$L__BB12_44;

$L__BB12_23:
	and.b64  	%rd93, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB12_24:
	setp.eq.s64 	%p13, %rd93, 0;
	@%p13 bra 	$L__BB12_26;

	div.u64 	%rd126, %rd119, %rd10;
	bra.uni 	$L__BB12_27;

$L__BB12_26:
	cvt.u32.u64 	%r32, %rd119;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd126, %r33;

$L__BB12_27:
	and.b64  	%rd94, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd94, 0;
	@%p14 bra 	$L__BB12_29;

	div.u64 	%rd127, %rd119, %rd64;
	mul.lo.s64 	%rd95, %rd127, %rd64;
	sub.s64 	%rd128, %rd119, %rd95;
	bra.uni 	$L__BB12_30;

$L__BB12_29:
	cvt.u32.u64 	%r35, %rd119;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd127, %r36;
	cvt.u64.u32 	%rd128, %r38;

$L__BB12_30:
	or.b64  	%rd96, %rd127, %rd63;
	and.b64  	%rd97, %rd96, -4294967296;
	setp.eq.s64 	%p15, %rd97, 0;
	@%p15 bra 	$L__BB12_32;

	rem.u64 	%rd129, %rd127, %rd63;
	bra.uni 	$L__BB12_33;

$L__BB12_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd127;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd129, %r41;

$L__BB12_33:
	add.s64 	%rd43, %rd3, %rd129;
	ld.global.u8 	%rd130, [%rd43];
	setp.eq.s64 	%p16, %rd130, 255;
	add.s64 	%rd45, %rd1, %rd119;
	@%p16 bra 	$L__BB12_42;

	setp.lt.u64 	%p17, %rd130, %rd62;
	@%p17 bra 	$L__BB12_36;

	mov.u64 	%rd98, $str;
	cvta.global.u64 	%rd99, %rd98;
	mov.u64 	%rd100, $str$1;
	cvta.global.u64 	%rd101, %rd100;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd99;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd101;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 25
	ld.global.u8 	%rd130, [%rd43];

$L__BB12_36:
	mul.lo.s64 	%rd102, %rd126, %rd62;
	add.s64 	%rd103, %rd102, %rd130;
	mul.lo.s64 	%rd104, %rd103, %rd64;
	add.s64 	%rd131, %rd104, %rd128;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB12_41;

$L__BB12_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd105, %r45;
	add.s64 	%rd106, %rd105, %rd61;
	and.b64  	%rd50, %rd131, 4294967295;
	shl.b64 	%rd107, %rd106, 3;
	and.b64  	%rd108, %rd107, 34359738360;
	add.s64 	%rd51, %rd4, %rd108;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd109, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd109, 0;
	@%p19 bra 	$L__BB12_39;

	div.u64 	%rd131, %rd50, %rd52;
	mul.lo.s64 	%rd110, %rd131, %rd52;
	sub.s64 	%rd133, %rd50, %rd110;
	bra.uni 	$L__BB12_40;

$L__BB12_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd131, %r48;
	cvt.u64.u32 	%rd133, %r50;

$L__BB12_40:
	shl.b64 	%rd111, %rd61, 3;
	add.s64 	%rd112, %rd51, %rd111;
	ld.global.u64 	%rd113, [%rd112];
	mul.lo.s64 	%rd114, %rd113, %rd133;
	cvt.u32.u64 	%r51, %rd114;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd115, %r55;
	setp.lt.u64 	%p20, %rd115, %rd61;
	@%p20 bra 	$L__BB12_37;

$L__BB12_41:
	cvt.u64.u32 	%rd116, %r56;
	add.s64 	%rd117, %rd2, %rd116;
	ld.global.u8 	%rs7, [%rd117];
	st.global.u8 	[%rd45], %rs7;
	bra.uni 	$L__BB12_43;

$L__BB12_42:
	mov.u16 	%rs8, 0;
	st.global.u8 	[%rd45], %rs8;

$L__BB12_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd119, %r53;
	setp.lt.u64 	%p21, %rd119, %rd60;
	@%p21 bra 	$L__BB12_24;

$L__BB12_44:
	ret;

}
	// .globl	is_u8_u32
.visible .entry is_u8_u32(
	.param .u64 is_u8_u32_param_0,
	.param .u64 is_u8_u32_param_1,
	.param .u64 is_u8_u32_param_2,
	.param .u64 is_u8_u32_param_3,
	.param .u64 is_u8_u32_param_4,
	.param .u64 is_u8_u32_param_5,
	.param .u64 is_u8_u32_param_6,
	.param .u64 is_u8_u32_param_7,
	.param .u64 is_u8_u32_param_8,
	.param .u64 is_u8_u32_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<137>;


	ld.param.u64 	%rd60, [is_u8_u32_param_0];
	ld.param.u64 	%rd61, [is_u8_u32_param_1];
	ld.param.u64 	%rd65, [is_u8_u32_param_2];
	ld.param.u64 	%rd66, [is_u8_u32_param_3];
	ld.param.u64 	%rd67, [is_u8_u32_param_4];
	ld.param.u64 	%rd68, [is_u8_u32_param_5];
	ld.param.u64 	%rd62, [is_u8_u32_param_7];
	ld.param.u64 	%rd63, [is_u8_u32_param_8];
	ld.param.u64 	%rd64, [is_u8_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB13_5;

	mov.u64 	%rd121, 1;
	mov.u32 	%r56, 0;

$L__BB13_2:
	not.b32 	%r16, %r56;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB13_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd121, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB13_5;

$L__BB13_4:
	mul.lo.s64 	%rd121, %rd7, %rd121;
	add.s32 	%r56, %r56, 1;
	cvt.u64.u32 	%rd77, %r56;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB13_2;

$L__BB13_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r57, %r17, %r3, %r18;
	cvt.u64.u32 	%rd122, %r57;
	setp.ge.u64 	%p5, %rd122, %rd60;
	@%p5 bra 	$L__BB13_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB13_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB13_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB13_10;

	div.u64 	%rd123, %rd122, %rd10;
	bra.uni 	$L__BB13_11;

$L__BB13_10:
	cvt.u32.u64 	%r21, %rd122;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd123, %r22;

$L__BB13_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB13_13;

	div.u64 	%rd124, %rd122, %rd64;
	mul.lo.s64 	%rd80, %rd124, %rd64;
	sub.s64 	%rd125, %rd122, %rd80;
	bra.uni 	$L__BB13_14;

$L__BB13_13:
	cvt.u32.u64 	%r24, %rd122;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd124, %r25;
	cvt.u64.u32 	%rd125, %r27;

$L__BB13_14:
	or.b64  	%rd81, %rd124, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB13_16;

	rem.u64 	%rd126, %rd124, %rd63;
	bra.uni 	$L__BB13_17;

$L__BB13_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd124;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd126, %r30;

$L__BB13_17:
	add.s64 	%rd24, %rd3, %rd126;
	ld.global.u8 	%rd127, [%rd24];
	setp.eq.s64 	%p10, %rd127, 255;
	shl.b64 	%rd83, %rd122, 2;
	add.s64 	%rd26, %rd1, %rd83;
	@%p10 bra 	$L__BB13_21;

	setp.lt.u64 	%p11, %rd127, %rd62;
	@%p11 bra 	$L__BB13_20;

	mov.u64 	%rd84, $str;
	cvta.global.u64 	%rd85, %rd84;
	mov.u64 	%rd86, $str$1;
	cvta.global.u64 	%rd87, %rd86;
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 26
	ld.global.u8 	%rd127, [%rd24];

$L__BB13_20:
	mul.lo.s64 	%rd88, %rd123, %rd62;
	add.s64 	%rd89, %rd88, %rd127;
	mul.lo.s64 	%rd90, %rd89, %rd64;
	add.s64 	%rd91, %rd90, %rd125;
	shl.b64 	%rd92, %rd91, 2;
	and.b64  	%rd93, %rd92, 17179869180;
	add.s64 	%rd94, %rd2, %rd93;
	ld.global.u32 	%r31, [%rd94];
	st.global.u32 	[%rd26], %r31;
	bra.uni 	$L__BB13_22;

$L__BB13_21:
	mov.u32 	%r32, 0;
	st.global.u32 	[%rd26], %r32;

$L__BB13_22:
	add.s32 	%r57, %r57, %r5;
	cvt.u64.u32 	%rd122, %r57;
	setp.lt.u64 	%p12, %rd122, %rd60;
	@%p12 bra 	$L__BB13_8;
	bra.uni 	$L__BB13_44;

$L__BB13_23:
	and.b64  	%rd95, %rd10, -4294967296;
	cvt.u32.u64 	%r33, %rd10;
	cvt.u32.u64 	%r36, %rd64;

$L__BB13_24:
	setp.eq.s64 	%p13, %rd95, 0;
	@%p13 bra 	$L__BB13_26;

	div.u64 	%rd129, %rd122, %rd10;
	bra.uni 	$L__BB13_27;

$L__BB13_26:
	cvt.u32.u64 	%r34, %rd122;
	div.u32 	%r35, %r34, %r33;
	cvt.u64.u32 	%rd129, %r35;

$L__BB13_27:
	and.b64  	%rd96, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd96, 0;
	@%p14 bra 	$L__BB13_29;

	div.u64 	%rd130, %rd122, %rd64;
	mul.lo.s64 	%rd97, %rd130, %rd64;
	sub.s64 	%rd131, %rd122, %rd97;
	bra.uni 	$L__BB13_30;

$L__BB13_29:
	cvt.u32.u64 	%r37, %rd122;
	div.u32 	%r38, %r37, %r36;
	mul.lo.s32 	%r39, %r38, %r36;
	sub.s32 	%r40, %r37, %r39;
	cvt.u64.u32 	%rd130, %r38;
	cvt.u64.u32 	%rd131, %r40;

$L__BB13_30:
	or.b64  	%rd98, %rd130, %rd63;
	and.b64  	%rd99, %rd98, -4294967296;
	setp.eq.s64 	%p15, %rd99, 0;
	@%p15 bra 	$L__BB13_32;

	rem.u64 	%rd132, %rd130, %rd63;
	bra.uni 	$L__BB13_33;

$L__BB13_32:
	cvt.u32.u64 	%r41, %rd63;
	cvt.u32.u64 	%r42, %rd130;
	rem.u32 	%r43, %r42, %r41;
	cvt.u64.u32 	%rd132, %r43;

$L__BB13_33:
	add.s64 	%rd43, %rd3, %rd132;
	ld.global.u8 	%rd133, [%rd43];
	setp.eq.s64 	%p16, %rd133, 255;
	shl.b64 	%rd100, %rd122, 2;
	add.s64 	%rd45, %rd1, %rd100;
	@%p16 bra 	$L__BB13_42;

	setp.lt.u64 	%p17, %rd133, %rd62;
	@%p17 bra 	$L__BB13_36;

	mov.u64 	%rd101, $str;
	cvta.global.u64 	%rd102, %rd101;
	mov.u64 	%rd103, $str$1;
	cvta.global.u64 	%rd104, %rd103;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd102;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd104;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 27
	ld.global.u8 	%rd133, [%rd43];

$L__BB13_36:
	mul.lo.s64 	%rd105, %rd129, %rd62;
	add.s64 	%rd106, %rd105, %rd133;
	mul.lo.s64 	%rd107, %rd106, %rd64;
	add.s64 	%rd134, %rd107, %rd131;
	mov.u32 	%r59, 0;
	mov.u32 	%r60, %r59;
	@%p1 bra 	$L__BB13_41;

$L__BB13_37:
	not.b32 	%r47, %r59;
	cvt.u64.u32 	%rd108, %r47;
	add.s64 	%rd109, %rd108, %rd61;
	and.b64  	%rd50, %rd134, 4294967295;
	shl.b64 	%rd110, %rd109, 3;
	and.b64  	%rd111, %rd110, 34359738360;
	add.s64 	%rd51, %rd4, %rd111;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd112, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd112, 0;
	@%p19 bra 	$L__BB13_39;

	div.u64 	%rd134, %rd50, %rd52;
	mul.lo.s64 	%rd113, %rd134, %rd52;
	sub.s64 	%rd136, %rd50, %rd113;
	bra.uni 	$L__BB13_40;

$L__BB13_39:
	cvt.u32.u64 	%r48, %rd52;
	cvt.u32.u64 	%r49, %rd50;
	div.u32 	%r50, %r49, %r48;
	mul.lo.s32 	%r51, %r50, %r48;
	sub.s32 	%r52, %r49, %r51;
	cvt.u64.u32 	%rd134, %r50;
	cvt.u64.u32 	%rd136, %r52;

$L__BB13_40:
	shl.b64 	%rd114, %rd61, 3;
	add.s64 	%rd115, %rd51, %rd114;
	ld.global.u64 	%rd116, [%rd115];
	mul.lo.s64 	%rd117, %rd116, %rd136;
	cvt.u32.u64 	%r53, %rd117;
	add.s32 	%r60, %r60, %r53;
	add.s32 	%r59, %r59, 1;
	cvt.u64.u32 	%rd118, %r59;
	setp.lt.u64 	%p20, %rd118, %rd61;
	@%p20 bra 	$L__BB13_37;

$L__BB13_41:
	mul.wide.u32 	%rd119, %r60, 4;
	add.s64 	%rd120, %rd2, %rd119;
	ld.global.u32 	%r54, [%rd120];
	st.global.u32 	[%rd45], %r54;
	bra.uni 	$L__BB13_43;

$L__BB13_42:
	mov.u32 	%r55, 0;
	st.global.u32 	[%rd45], %r55;

$L__BB13_43:
	add.s32 	%r57, %r57, %r5;
	cvt.u64.u32 	%rd122, %r57;
	setp.lt.u64 	%p21, %rd122, %rd60;
	@%p21 bra 	$L__BB13_24;

$L__BB13_44:
	ret;

}
	// .globl	is_u8_i64
.visible .entry is_u8_i64(
	.param .u64 is_u8_i64_param_0,
	.param .u64 is_u8_i64_param_1,
	.param .u64 is_u8_i64_param_2,
	.param .u64 is_u8_i64_param_3,
	.param .u64 is_u8_i64_param_4,
	.param .u64 is_u8_i64_param_5,
	.param .u64 is_u8_i64_param_6,
	.param .u64 is_u8_i64_param_7,
	.param .u64 is_u8_i64_param_8,
	.param .u64 is_u8_i64_param_9
)
{
	.reg .pred 	%p<22>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<141>;


	ld.param.u64 	%rd60, [is_u8_i64_param_0];
	ld.param.u64 	%rd61, [is_u8_i64_param_1];
	ld.param.u64 	%rd65, [is_u8_i64_param_2];
	ld.param.u64 	%rd66, [is_u8_i64_param_3];
	ld.param.u64 	%rd67, [is_u8_i64_param_4];
	ld.param.u64 	%rd68, [is_u8_i64_param_5];
	ld.param.u64 	%rd62, [is_u8_i64_param_7];
	ld.param.u64 	%rd63, [is_u8_i64_param_8];
	ld.param.u64 	%rd64, [is_u8_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd68;
	cvta.to.global.u64 	%rd2, %rd67;
	cvta.to.global.u64 	%rd3, %rd66;
	cvta.to.global.u64 	%rd4, %rd65;
	setp.eq.s64 	%p1, %rd61, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB14_5;

	mov.u64 	%rd125, 1;
	mov.u32 	%r52, 0;

$L__BB14_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd70, %r16;
	add.s64 	%rd71, %rd70, %rd61;
	shl.b64 	%rd72, %rd71, 3;
	and.b64  	%rd73, %rd72, 34359738360;
	add.s64 	%rd6, %rd4, %rd73;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB14_4;

	shl.b64 	%rd74, %rd61, 3;
	add.s64 	%rd75, %rd6, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	setp.ne.s64 	%p3, %rd125, %rd76;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB14_5;

$L__BB14_4:
	mul.lo.s64 	%rd125, %rd7, %rd125;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd77, %r52;
	setp.lt.u64 	%p4, %rd77, %rd61;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB14_2;

$L__BB14_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd126, %r53;
	setp.ge.u64 	%p5, %rd126, %rd60;
	@%p5 bra 	$L__BB14_44;

	mul.lo.s64 	%rd10, %rd64, %rd63;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB14_23;

	and.b64  	%rd78, %rd10, -4294967296;
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r23, %rd64;

$L__BB14_8:
	setp.eq.s64 	%p7, %rd78, 0;
	@%p7 bra 	$L__BB14_10;

	div.u64 	%rd127, %rd126, %rd10;
	bra.uni 	$L__BB14_11;

$L__BB14_10:
	cvt.u32.u64 	%r21, %rd126;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd127, %r22;

$L__BB14_11:
	and.b64  	%rd79, %rd64, -4294967296;
	setp.eq.s64 	%p8, %rd79, 0;
	@%p8 bra 	$L__BB14_13;

	div.u64 	%rd128, %rd126, %rd64;
	mul.lo.s64 	%rd80, %rd128, %rd64;
	sub.s64 	%rd129, %rd126, %rd80;
	bra.uni 	$L__BB14_14;

$L__BB14_13:
	cvt.u32.u64 	%r24, %rd126;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd128, %r25;
	cvt.u64.u32 	%rd129, %r27;

$L__BB14_14:
	or.b64  	%rd81, %rd128, %rd63;
	and.b64  	%rd82, %rd81, -4294967296;
	setp.eq.s64 	%p9, %rd82, 0;
	@%p9 bra 	$L__BB14_16;

	rem.u64 	%rd130, %rd128, %rd63;
	bra.uni 	$L__BB14_17;

$L__BB14_16:
	cvt.u32.u64 	%r28, %rd63;
	cvt.u32.u64 	%r29, %rd128;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd130, %r30;

$L__BB14_17:
	add.s64 	%rd24, %rd3, %rd130;
	ld.global.u8 	%rd131, [%rd24];
	setp.eq.s64 	%p10, %rd131, 255;
	shl.b64 	%rd83, %rd126, 3;
	add.s64 	%rd26, %rd1, %rd83;
	@%p10 bra 	$L__BB14_21;

	setp.lt.u64 	%p11, %rd131, %rd62;
	@%p11 bra 	$L__BB14_20;

	mov.u64 	%rd84, $str;
	cvta.global.u64 	%rd85, %rd84;
	mov.u64 	%rd86, $str$1;
	cvta.global.u64 	%rd87, %rd86;
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 28
	ld.global.u8 	%rd131, [%rd24];

$L__BB14_20:
	mul.lo.s64 	%rd88, %rd127, %rd62;
	add.s64 	%rd89, %rd88, %rd131;
	mul.lo.s64 	%rd90, %rd89, %rd64;
	add.s64 	%rd91, %rd90, %rd129;
	shl.b64 	%rd92, %rd91, 3;
	and.b64  	%rd93, %rd92, 34359738360;
	add.s64 	%rd94, %rd2, %rd93;
	ld.global.u64 	%rd95, [%rd94];
	st.global.u64 	[%rd26], %rd95;
	bra.uni 	$L__BB14_22;

$L__BB14_21:
	mov.u64 	%rd96, 0;
	st.global.u64 	[%rd26], %rd96;

$L__BB14_22:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd126, %r53;
	setp.lt.u64 	%p12, %rd126, %rd60;
	@%p12 bra 	$L__BB14_8;
	bra.uni 	$L__BB14_44;

$L__BB14_23:
	and.b64  	%rd97, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd64;

$L__BB14_24:
	setp.eq.s64 	%p13, %rd97, 0;
	@%p13 bra 	$L__BB14_26;

	div.u64 	%rd133, %rd126, %rd10;
	bra.uni 	$L__BB14_27;

$L__BB14_26:
	cvt.u32.u64 	%r32, %rd126;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd133, %r33;

$L__BB14_27:
	and.b64  	%rd98, %rd64, -4294967296;
	setp.eq.s64 	%p14, %rd98, 0;
	@%p14 bra 	$L__BB14_29;

	div.u64 	%rd134, %rd126, %rd64;
	mul.lo.s64 	%rd99, %rd134, %rd64;
	sub.s64 	%rd135, %rd126, %rd99;
	bra.uni 	$L__BB14_30;

$L__BB14_29:
	cvt.u32.u64 	%r35, %rd126;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd134, %r36;
	cvt.u64.u32 	%rd135, %r38;

$L__BB14_30:
	or.b64  	%rd100, %rd134, %rd63;
	and.b64  	%rd101, %rd100, -4294967296;
	setp.eq.s64 	%p15, %rd101, 0;
	@%p15 bra 	$L__BB14_32;

	rem.u64 	%rd136, %rd134, %rd63;
	bra.uni 	$L__BB14_33;

$L__BB14_32:
	cvt.u32.u64 	%r39, %rd63;
	cvt.u32.u64 	%r40, %rd134;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd136, %r41;

$L__BB14_33:
	add.s64 	%rd43, %rd3, %rd136;
	ld.global.u8 	%rd137, [%rd43];
	setp.eq.s64 	%p16, %rd137, 255;
	shl.b64 	%rd102, %rd126, 3;
	add.s64 	%rd45, %rd1, %rd102;
	@%p16 bra 	$L__BB14_42;

	setp.lt.u64 	%p17, %rd137, %rd62;
	@%p17 bra 	$L__BB14_36;

	mov.u64 	%rd103, $str;
	cvta.global.u64 	%rd104, %rd103;
	mov.u64 	%rd105, $str$1;
	cvta.global.u64 	%rd106, %rd105;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd104;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd106;
	.param .b32 param2;
	st.param.b32 	[param2+0], 66;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 29
	ld.global.u8 	%rd137, [%rd43];

$L__BB14_36:
	mul.lo.s64 	%rd107, %rd133, %rd62;
	add.s64 	%rd108, %rd107, %rd137;
	mul.lo.s64 	%rd109, %rd108, %rd64;
	add.s64 	%rd138, %rd109, %rd135;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB14_41;

$L__BB14_37:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd110, %r45;
	add.s64 	%rd111, %rd110, %rd61;
	and.b64  	%rd50, %rd138, 4294967295;
	shl.b64 	%rd112, %rd111, 3;
	and.b64  	%rd113, %rd112, 34359738360;
	add.s64 	%rd51, %rd4, %rd113;
	ld.global.u64 	%rd52, [%rd51];
	and.b64  	%rd114, %rd52, -4294967296;
	setp.eq.s64 	%p19, %rd114, 0;
	@%p19 bra 	$L__BB14_39;

	div.u64 	%rd138, %rd50, %rd52;
	mul.lo.s64 	%rd115, %rd138, %rd52;
	sub.s64 	%rd140, %rd50, %rd115;
	bra.uni 	$L__BB14_40;

$L__BB14_39:
	cvt.u32.u64 	%r46, %rd52;
	cvt.u32.u64 	%r47, %rd50;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd138, %r48;
	cvt.u64.u32 	%rd140, %r50;

$L__BB14_40:
	shl.b64 	%rd116, %rd61, 3;
	add.s64 	%rd117, %rd51, %rd116;
	ld.global.u64 	%rd118, [%rd117];
	mul.lo.s64 	%rd119, %rd118, %rd140;
	cvt.u32.u64 	%r51, %rd119;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd120, %r55;
	setp.lt.u64 	%p20, %rd120, %rd61;
	@%p20 bra 	$L__BB14_37;

$L__BB14_41:
	mul.wide.u32 	%rd121, %r56, 8;
	add.s64 	%rd122, %rd2, %rd121;
	ld.global.u64 	%rd123, [%rd122];
	st.global.u64 	[%rd45], %rd123;
	bra.uni 	$L__BB14_43;

$L__BB14_42:
	mov.u64 	%rd124, 0;
	st.global.u64 	[%rd45], %rd124;

$L__BB14_43:
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd126, %r53;
	setp.lt.u64 	%p21, %rd126, %rd60;
	@%p21 bra 	$L__BB14_24;

$L__BB14_44:
	ret;

}
	// .globl	gather_i64_f32
.visible .entry gather_i64_f32(
	.param .u64 gather_i64_f32_param_0,
	.param .u64 gather_i64_f32_param_1,
	.param .u64 gather_i64_f32_param_2,
	.param .u64 gather_i64_f32_param_3,
	.param .u64 gather_i64_f32_param_4,
	.param .u64 gather_i64_f32_param_5,
	.param .u64 gather_i64_f32_param_6,
	.param .u64 gather_i64_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<41>;


	ld.param.u64 	%rd16, [gather_i64_f32_param_0];
	ld.param.u64 	%rd17, [gather_i64_f32_param_1];
	ld.param.u64 	%rd18, [gather_i64_f32_param_2];
	ld.param.u64 	%rd19, [gather_i64_f32_param_3];
	ld.param.u64 	%rd20, [gather_i64_f32_param_5];
	ld.param.u64 	%rd21, [gather_i64_f32_param_6];
	ld.param.u64 	%rd22, [gather_i64_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r16, %r6, %r1, %r7;
	cvt.u64.u32 	%rd38, %r16;
	setp.ge.u64 	%p1, %rd38, %rd16;
	@%p1 bra 	$L__BB15_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB15_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB15_4;

	rem.u64 	%rd39, %rd38, %rd22;
	bra.uni 	$L__BB15_5;

$L__BB15_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd38;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd39, %r11;

$L__BB15_5:
	shl.b64 	%rd24, %rd38, 3;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u64 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 9223372036854775807;
	shl.b64 	%rd26, %rd38, 2;
	add.s64 	%rd11, %rd5, %rd26;
	@%p3 bra 	$L__BB15_12;
	bra.uni 	$L__BB15_6;

$L__BB15_12:
	mov.u32 	%r15, 0;
	st.global.u32 	[%rd11], %r15;
	bra.uni 	$L__BB15_13;

$L__BB15_6:
	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB15_8;

	mov.u64 	%rd27, $str$2;
	cvta.global.u64 	%rd28, %rd27;
	mov.u64 	%rd29, $str$1;
	cvta.global.u64 	%rd30, %rd29;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd28;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 30

$L__BB15_8:
	and.b64  	%rd31, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd31, 0;
	@%p5 bra 	$L__BB15_10;

	div.u64 	%rd40, %rd38, %rd2;
	bra.uni 	$L__BB15_11;

$L__BB15_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd38;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd40, %r14;

$L__BB15_11:
	mul.lo.s64 	%rd32, %rd40, %rd20;
	add.s64 	%rd33, %rd32, %rd10;
	mul.lo.s64 	%rd34, %rd33, %rd22;
	add.s64 	%rd35, %rd34, %rd39;
	shl.b64 	%rd36, %rd35, 2;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.f32 	%f1, [%rd37];
	st.global.f32 	[%rd11], %f1;

$L__BB15_13:
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd38, %r16;
	setp.lt.u64 	%p6, %rd38, %rd16;
	@%p6 bra 	$L__BB15_2;

$L__BB15_14:
	ret;

}
	// .globl	gather_i64_f64
.visible .entry gather_i64_f64(
	.param .u64 gather_i64_f64_param_0,
	.param .u64 gather_i64_f64_param_1,
	.param .u64 gather_i64_f64_param_2,
	.param .u64 gather_i64_f64_param_3,
	.param .u64 gather_i64_f64_param_4,
	.param .u64 gather_i64_f64_param_5,
	.param .u64 gather_i64_f64_param_6,
	.param .u64 gather_i64_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<41>;


	ld.param.u64 	%rd16, [gather_i64_f64_param_0];
	ld.param.u64 	%rd17, [gather_i64_f64_param_1];
	ld.param.u64 	%rd18, [gather_i64_f64_param_2];
	ld.param.u64 	%rd19, [gather_i64_f64_param_3];
	ld.param.u64 	%rd20, [gather_i64_f64_param_5];
	ld.param.u64 	%rd21, [gather_i64_f64_param_6];
	ld.param.u64 	%rd22, [gather_i64_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd38, %r15;
	setp.ge.u64 	%p1, %rd38, %rd16;
	@%p1 bra 	$L__BB16_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB16_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB16_4;

	rem.u64 	%rd39, %rd38, %rd22;
	bra.uni 	$L__BB16_5;

$L__BB16_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd38;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd39, %r11;

$L__BB16_5:
	shl.b64 	%rd24, %rd38, 3;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u64 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 9223372036854775807;
	add.s64 	%rd11, %rd5, %rd24;
	@%p3 bra 	$L__BB16_12;
	bra.uni 	$L__BB16_6;

$L__BB16_12:
	mov.u64 	%rd37, 0;
	st.global.u64 	[%rd11], %rd37;
	bra.uni 	$L__BB16_13;

$L__BB16_6:
	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB16_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 31

$L__BB16_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB16_10;

	div.u64 	%rd40, %rd38, %rd2;
	bra.uni 	$L__BB16_11;

$L__BB16_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd38;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd40, %r14;

$L__BB16_11:
	mul.lo.s64 	%rd31, %rd40, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd39;
	shl.b64 	%rd35, %rd34, 3;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.f64 	%fd1, [%rd36];
	st.global.f64 	[%rd11], %fd1;

$L__BB16_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd38, %r15;
	setp.lt.u64 	%p6, %rd38, %rd16;
	@%p6 bra 	$L__BB16_2;

$L__BB16_14:
	ret;

}
	// .globl	gather_i64_u8
.visible .entry gather_i64_u8(
	.param .u64 gather_i64_u8_param_0,
	.param .u64 gather_i64_u8_param_1,
	.param .u64 gather_i64_u8_param_2,
	.param .u64 gather_i64_u8_param_3,
	.param .u64 gather_i64_u8_param_4,
	.param .u64 gather_i64_u8_param_5,
	.param .u64 gather_i64_u8_param_6,
	.param .u64 gather_i64_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<39>;


	ld.param.u64 	%rd16, [gather_i64_u8_param_0];
	ld.param.u64 	%rd17, [gather_i64_u8_param_1];
	ld.param.u64 	%rd18, [gather_i64_u8_param_2];
	ld.param.u64 	%rd19, [gather_i64_u8_param_3];
	ld.param.u64 	%rd20, [gather_i64_u8_param_5];
	ld.param.u64 	%rd21, [gather_i64_u8_param_6];
	ld.param.u64 	%rd22, [gather_i64_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd36, %r15;
	setp.ge.u64 	%p1, %rd36, %rd16;
	@%p1 bra 	$L__BB17_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB17_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB17_4;

	rem.u64 	%rd37, %rd36, %rd22;
	bra.uni 	$L__BB17_5;

$L__BB17_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd36;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd37, %r11;

$L__BB17_5:
	shl.b64 	%rd24, %rd36, 3;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u64 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 9223372036854775807;
	add.s64 	%rd11, %rd5, %rd36;
	@%p3 bra 	$L__BB17_12;
	bra.uni 	$L__BB17_6;

$L__BB17_12:
	mov.u16 	%rs2, 0;
	st.global.u8 	[%rd11], %rs2;
	bra.uni 	$L__BB17_13;

$L__BB17_6:
	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB17_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 32

$L__BB17_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB17_10;

	div.u64 	%rd38, %rd36, %rd2;
	bra.uni 	$L__BB17_11;

$L__BB17_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd36;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd38, %r14;

$L__BB17_11:
	mul.lo.s64 	%rd31, %rd38, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd37;
	add.s64 	%rd35, %rd4, %rd34;
	ld.global.u8 	%rs1, [%rd35];
	st.global.u8 	[%rd11], %rs1;

$L__BB17_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd36, %r15;
	setp.lt.u64 	%p6, %rd36, %rd16;
	@%p6 bra 	$L__BB17_2;

$L__BB17_14:
	ret;

}
	// .globl	gather_i64_u32
.visible .entry gather_i64_u32(
	.param .u64 gather_i64_u32_param_0,
	.param .u64 gather_i64_u32_param_1,
	.param .u64 gather_i64_u32_param_2,
	.param .u64 gather_i64_u32_param_3,
	.param .u64 gather_i64_u32_param_4,
	.param .u64 gather_i64_u32_param_5,
	.param .u64 gather_i64_u32_param_6,
	.param .u64 gather_i64_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<41>;


	ld.param.u64 	%rd16, [gather_i64_u32_param_0];
	ld.param.u64 	%rd17, [gather_i64_u32_param_1];
	ld.param.u64 	%rd18, [gather_i64_u32_param_2];
	ld.param.u64 	%rd19, [gather_i64_u32_param_3];
	ld.param.u64 	%rd20, [gather_i64_u32_param_5];
	ld.param.u64 	%rd21, [gather_i64_u32_param_6];
	ld.param.u64 	%rd22, [gather_i64_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r17, %r6, %r1, %r7;
	cvt.u64.u32 	%rd38, %r17;
	setp.ge.u64 	%p1, %rd38, %rd16;
	@%p1 bra 	$L__BB18_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB18_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB18_4;

	rem.u64 	%rd39, %rd38, %rd22;
	bra.uni 	$L__BB18_5;

$L__BB18_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd38;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd39, %r11;

$L__BB18_5:
	shl.b64 	%rd24, %rd38, 3;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u64 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 9223372036854775807;
	shl.b64 	%rd26, %rd38, 2;
	add.s64 	%rd11, %rd5, %rd26;
	@%p3 bra 	$L__BB18_12;
	bra.uni 	$L__BB18_6;

$L__BB18_12:
	mov.u32 	%r16, 0;
	st.global.u32 	[%rd11], %r16;
	bra.uni 	$L__BB18_13;

$L__BB18_6:
	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB18_8;

	mov.u64 	%rd27, $str$2;
	cvta.global.u64 	%rd28, %rd27;
	mov.u64 	%rd29, $str$1;
	cvta.global.u64 	%rd30, %rd29;
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd28;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 33

$L__BB18_8:
	and.b64  	%rd31, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd31, 0;
	@%p5 bra 	$L__BB18_10;

	div.u64 	%rd40, %rd38, %rd2;
	bra.uni 	$L__BB18_11;

$L__BB18_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd38;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd40, %r14;

$L__BB18_11:
	mul.lo.s64 	%rd32, %rd40, %rd20;
	add.s64 	%rd33, %rd32, %rd10;
	mul.lo.s64 	%rd34, %rd33, %rd22;
	add.s64 	%rd35, %rd34, %rd39;
	shl.b64 	%rd36, %rd35, 2;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.u32 	%r15, [%rd37];
	st.global.u32 	[%rd11], %r15;

$L__BB18_13:
	add.s32 	%r17, %r17, %r3;
	cvt.u64.u32 	%rd38, %r17;
	setp.lt.u64 	%p6, %rd38, %rd16;
	@%p6 bra 	$L__BB18_2;

$L__BB18_14:
	ret;

}
	// .globl	gather_i64_i64
.visible .entry gather_i64_i64(
	.param .u64 gather_i64_i64_param_0,
	.param .u64 gather_i64_i64_param_1,
	.param .u64 gather_i64_i64_param_2,
	.param .u64 gather_i64_i64_param_3,
	.param .u64 gather_i64_i64_param_4,
	.param .u64 gather_i64_i64_param_5,
	.param .u64 gather_i64_i64_param_6,
	.param .u64 gather_i64_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<42>;


	ld.param.u64 	%rd16, [gather_i64_i64_param_0];
	ld.param.u64 	%rd17, [gather_i64_i64_param_1];
	ld.param.u64 	%rd18, [gather_i64_i64_param_2];
	ld.param.u64 	%rd19, [gather_i64_i64_param_3];
	ld.param.u64 	%rd20, [gather_i64_i64_param_5];
	ld.param.u64 	%rd21, [gather_i64_i64_param_6];
	ld.param.u64 	%rd22, [gather_i64_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd39, %r15;
	setp.ge.u64 	%p1, %rd39, %rd16;
	@%p1 bra 	$L__BB19_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB19_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB19_4;

	rem.u64 	%rd40, %rd39, %rd22;
	bra.uni 	$L__BB19_5;

$L__BB19_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd39;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd40, %r11;

$L__BB19_5:
	shl.b64 	%rd24, %rd39, 3;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u64 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 9223372036854775807;
	add.s64 	%rd11, %rd5, %rd24;
	@%p3 bra 	$L__BB19_12;
	bra.uni 	$L__BB19_6;

$L__BB19_12:
	mov.u64 	%rd38, 0;
	st.global.u64 	[%rd11], %rd38;
	bra.uni 	$L__BB19_13;

$L__BB19_6:
	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB19_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 34

$L__BB19_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB19_10;

	div.u64 	%rd41, %rd39, %rd2;
	bra.uni 	$L__BB19_11;

$L__BB19_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd39;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd41, %r14;

$L__BB19_11:
	mul.lo.s64 	%rd31, %rd41, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd40;
	shl.b64 	%rd35, %rd34, 3;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.u64 	%rd37, [%rd36];
	st.global.u64 	[%rd11], %rd37;

$L__BB19_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd39, %r15;
	setp.lt.u64 	%p6, %rd39, %rd16;
	@%p6 bra 	$L__BB19_2;

$L__BB19_14:
	ret;

}
	// .globl	gather_u32_f32
.visible .entry gather_u32_f32(
	.param .u64 gather_u32_f32_param_0,
	.param .u64 gather_u32_f32_param_1,
	.param .u64 gather_u32_f32_param_2,
	.param .u64 gather_u32_f32_param_3,
	.param .u64 gather_u32_f32_param_4,
	.param .u64 gather_u32_f32_param_5,
	.param .u64 gather_u32_f32_param_6,
	.param .u64 gather_u32_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd16, [gather_u32_f32_param_0];
	ld.param.u64 	%rd17, [gather_u32_f32_param_1];
	ld.param.u64 	%rd18, [gather_u32_f32_param_2];
	ld.param.u64 	%rd19, [gather_u32_f32_param_3];
	ld.param.u64 	%rd20, [gather_u32_f32_param_5];
	ld.param.u64 	%rd21, [gather_u32_f32_param_6];
	ld.param.u64 	%rd22, [gather_u32_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r16, %r6, %r1, %r7;
	cvt.u64.u32 	%rd37, %r16;
	setp.ge.u64 	%p1, %rd37, %rd16;
	@%p1 bra 	$L__BB20_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB20_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB20_4;

	rem.u64 	%rd38, %rd37, %rd22;
	bra.uni 	$L__BB20_5;

$L__BB20_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd37;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd38, %r11;

$L__BB20_5:
	shl.b64 	%rd24, %rd37, 2;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u32 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 4294967295;
	add.s64 	%rd11, %rd5, %rd24;
	@%p3 bra 	$L__BB20_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB20_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 35

$L__BB20_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB20_10;

	div.u64 	%rd39, %rd37, %rd2;
	bra.uni 	$L__BB20_11;

$L__BB20_12:
	mov.u32 	%r15, 0;
	st.global.u32 	[%rd11], %r15;
	bra.uni 	$L__BB20_13;

$L__BB20_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd37;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd39, %r14;

$L__BB20_11:
	mul.lo.s64 	%rd31, %rd39, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd38;
	shl.b64 	%rd35, %rd34, 2;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.f32 	%f1, [%rd36];
	st.global.f32 	[%rd11], %f1;

$L__BB20_13:
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd37, %r16;
	setp.lt.u64 	%p6, %rd37, %rd16;
	@%p6 bra 	$L__BB20_2;

$L__BB20_14:
	ret;

}
	// .globl	gather_u32_f64
.visible .entry gather_u32_f64(
	.param .u64 gather_u32_f64_param_0,
	.param .u64 gather_u32_f64_param_1,
	.param .u64 gather_u32_f64_param_2,
	.param .u64 gather_u32_f64_param_3,
	.param .u64 gather_u32_f64_param_4,
	.param .u64 gather_u32_f64_param_5,
	.param .u64 gather_u32_f64_param_6,
	.param .u64 gather_u32_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<42>;


	ld.param.u64 	%rd16, [gather_u32_f64_param_0];
	ld.param.u64 	%rd17, [gather_u32_f64_param_1];
	ld.param.u64 	%rd18, [gather_u32_f64_param_2];
	ld.param.u64 	%rd19, [gather_u32_f64_param_3];
	ld.param.u64 	%rd20, [gather_u32_f64_param_5];
	ld.param.u64 	%rd21, [gather_u32_f64_param_6];
	ld.param.u64 	%rd22, [gather_u32_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd39, %r15;
	setp.ge.u64 	%p1, %rd39, %rd16;
	@%p1 bra 	$L__BB21_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB21_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB21_4;

	rem.u64 	%rd40, %rd39, %rd22;
	bra.uni 	$L__BB21_5;

$L__BB21_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd39;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd40, %r11;

$L__BB21_5:
	shl.b64 	%rd24, %rd39, 2;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u32 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 4294967295;
	shl.b64 	%rd26, %rd39, 3;
	add.s64 	%rd11, %rd5, %rd26;
	@%p3 bra 	$L__BB21_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB21_8;

	mov.u64 	%rd27, $str$2;
	cvta.global.u64 	%rd28, %rd27;
	mov.u64 	%rd29, $str$1;
	cvta.global.u64 	%rd30, %rd29;
	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd28;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 36

$L__BB21_8:
	and.b64  	%rd31, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd31, 0;
	@%p5 bra 	$L__BB21_10;

	div.u64 	%rd41, %rd39, %rd2;
	bra.uni 	$L__BB21_11;

$L__BB21_12:
	mov.u64 	%rd38, 0;
	st.global.u64 	[%rd11], %rd38;
	bra.uni 	$L__BB21_13;

$L__BB21_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd39;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd41, %r14;

$L__BB21_11:
	mul.lo.s64 	%rd32, %rd41, %rd20;
	add.s64 	%rd33, %rd32, %rd10;
	mul.lo.s64 	%rd34, %rd33, %rd22;
	add.s64 	%rd35, %rd34, %rd40;
	shl.b64 	%rd36, %rd35, 3;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.f64 	%fd1, [%rd37];
	st.global.f64 	[%rd11], %fd1;

$L__BB21_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd39, %r15;
	setp.lt.u64 	%p6, %rd39, %rd16;
	@%p6 bra 	$L__BB21_2;

$L__BB21_14:
	ret;

}
	// .globl	gather_u32_u8
.visible .entry gather_u32_u8(
	.param .u64 gather_u32_u8_param_0,
	.param .u64 gather_u32_u8_param_1,
	.param .u64 gather_u32_u8_param_2,
	.param .u64 gather_u32_u8_param_3,
	.param .u64 gather_u32_u8_param_4,
	.param .u64 gather_u32_u8_param_5,
	.param .u64 gather_u32_u8_param_6,
	.param .u64 gather_u32_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<39>;


	ld.param.u64 	%rd16, [gather_u32_u8_param_0];
	ld.param.u64 	%rd17, [gather_u32_u8_param_1];
	ld.param.u64 	%rd18, [gather_u32_u8_param_2];
	ld.param.u64 	%rd19, [gather_u32_u8_param_3];
	ld.param.u64 	%rd20, [gather_u32_u8_param_5];
	ld.param.u64 	%rd21, [gather_u32_u8_param_6];
	ld.param.u64 	%rd22, [gather_u32_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd36, %r15;
	setp.ge.u64 	%p1, %rd36, %rd16;
	@%p1 bra 	$L__BB22_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB22_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB22_4;

	rem.u64 	%rd37, %rd36, %rd22;
	bra.uni 	$L__BB22_5;

$L__BB22_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd36;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd37, %r11;

$L__BB22_5:
	shl.b64 	%rd24, %rd36, 2;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u32 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 4294967295;
	add.s64 	%rd11, %rd5, %rd36;
	@%p3 bra 	$L__BB22_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB22_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 37

$L__BB22_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB22_10;

	div.u64 	%rd38, %rd36, %rd2;
	bra.uni 	$L__BB22_11;

$L__BB22_12:
	mov.u16 	%rs2, 0;
	st.global.u8 	[%rd11], %rs2;
	bra.uni 	$L__BB22_13;

$L__BB22_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd36;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd38, %r14;

$L__BB22_11:
	mul.lo.s64 	%rd31, %rd38, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd37;
	add.s64 	%rd35, %rd4, %rd34;
	ld.global.u8 	%rs1, [%rd35];
	st.global.u8 	[%rd11], %rs1;

$L__BB22_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd36, %r15;
	setp.lt.u64 	%p6, %rd36, %rd16;
	@%p6 bra 	$L__BB22_2;

$L__BB22_14:
	ret;

}
	// .globl	gather_u32_i64
.visible .entry gather_u32_i64(
	.param .u64 gather_u32_i64_param_0,
	.param .u64 gather_u32_i64_param_1,
	.param .u64 gather_u32_i64_param_2,
	.param .u64 gather_u32_i64_param_3,
	.param .u64 gather_u32_i64_param_4,
	.param .u64 gather_u32_i64_param_5,
	.param .u64 gather_u32_i64_param_6,
	.param .u64 gather_u32_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd16, [gather_u32_i64_param_0];
	ld.param.u64 	%rd17, [gather_u32_i64_param_1];
	ld.param.u64 	%rd18, [gather_u32_i64_param_2];
	ld.param.u64 	%rd19, [gather_u32_i64_param_3];
	ld.param.u64 	%rd20, [gather_u32_i64_param_5];
	ld.param.u64 	%rd21, [gather_u32_i64_param_6];
	ld.param.u64 	%rd22, [gather_u32_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd40, %r15;
	setp.ge.u64 	%p1, %rd40, %rd16;
	@%p1 bra 	$L__BB23_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB23_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB23_4;

	rem.u64 	%rd41, %rd40, %rd22;
	bra.uni 	$L__BB23_5;

$L__BB23_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd40;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd41, %r11;

$L__BB23_5:
	shl.b64 	%rd24, %rd40, 2;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u32 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 4294967295;
	shl.b64 	%rd26, %rd40, 3;
	add.s64 	%rd11, %rd5, %rd26;
	@%p3 bra 	$L__BB23_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB23_8;

	mov.u64 	%rd27, $str$2;
	cvta.global.u64 	%rd28, %rd27;
	mov.u64 	%rd29, $str$1;
	cvta.global.u64 	%rd30, %rd29;
	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd28;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd30;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 38

$L__BB23_8:
	and.b64  	%rd31, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd31, 0;
	@%p5 bra 	$L__BB23_10;

	div.u64 	%rd42, %rd40, %rd2;
	bra.uni 	$L__BB23_11;

$L__BB23_12:
	mov.u64 	%rd39, 0;
	st.global.u64 	[%rd11], %rd39;
	bra.uni 	$L__BB23_13;

$L__BB23_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd40;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd42, %r14;

$L__BB23_11:
	mul.lo.s64 	%rd32, %rd42, %rd20;
	add.s64 	%rd33, %rd32, %rd10;
	mul.lo.s64 	%rd34, %rd33, %rd22;
	add.s64 	%rd35, %rd34, %rd41;
	shl.b64 	%rd36, %rd35, 3;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.u64 	%rd38, [%rd37];
	st.global.u64 	[%rd11], %rd38;

$L__BB23_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd40, %r15;
	setp.lt.u64 	%p6, %rd40, %rd16;
	@%p6 bra 	$L__BB23_2;

$L__BB23_14:
	ret;

}
	// .globl	gather_u32_u32
.visible .entry gather_u32_u32(
	.param .u64 gather_u32_u32_param_0,
	.param .u64 gather_u32_u32_param_1,
	.param .u64 gather_u32_u32_param_2,
	.param .u64 gather_u32_u32_param_3,
	.param .u64 gather_u32_u32_param_4,
	.param .u64 gather_u32_u32_param_5,
	.param .u64 gather_u32_u32_param_6,
	.param .u64 gather_u32_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd16, [gather_u32_u32_param_0];
	ld.param.u64 	%rd17, [gather_u32_u32_param_1];
	ld.param.u64 	%rd18, [gather_u32_u32_param_2];
	ld.param.u64 	%rd19, [gather_u32_u32_param_3];
	ld.param.u64 	%rd20, [gather_u32_u32_param_5];
	ld.param.u64 	%rd21, [gather_u32_u32_param_6];
	ld.param.u64 	%rd22, [gather_u32_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r17, %r6, %r1, %r7;
	cvt.u64.u32 	%rd37, %r17;
	setp.ge.u64 	%p1, %rd37, %rd16;
	@%p1 bra 	$L__BB24_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB24_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB24_4;

	rem.u64 	%rd38, %rd37, %rd22;
	bra.uni 	$L__BB24_5;

$L__BB24_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd37;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd38, %r11;

$L__BB24_5:
	shl.b64 	%rd24, %rd37, 2;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.u32 	%rd10, [%rd25];
	setp.eq.s64 	%p3, %rd10, 4294967295;
	add.s64 	%rd11, %rd5, %rd24;
	@%p3 bra 	$L__BB24_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB24_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 39

$L__BB24_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB24_10;

	div.u64 	%rd39, %rd37, %rd2;
	bra.uni 	$L__BB24_11;

$L__BB24_12:
	mov.u32 	%r16, 0;
	st.global.u32 	[%rd11], %r16;
	bra.uni 	$L__BB24_13;

$L__BB24_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd37;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd39, %r14;

$L__BB24_11:
	mul.lo.s64 	%rd31, %rd39, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd38;
	shl.b64 	%rd35, %rd34, 2;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.u32 	%r15, [%rd36];
	st.global.u32 	[%rd11], %r15;

$L__BB24_13:
	add.s32 	%r17, %r17, %r3;
	cvt.u64.u32 	%rd37, %r17;
	setp.lt.u64 	%p6, %rd37, %rd16;
	@%p6 bra 	$L__BB24_2;

$L__BB24_14:
	ret;

}
	// .globl	gather_u8_f32
.visible .entry gather_u8_f32(
	.param .u64 gather_u8_f32_param_0,
	.param .u64 gather_u8_f32_param_1,
	.param .u64 gather_u8_f32_param_2,
	.param .u64 gather_u8_f32_param_3,
	.param .u64 gather_u8_f32_param_4,
	.param .u64 gather_u8_f32_param_5,
	.param .u64 gather_u8_f32_param_6,
	.param .u64 gather_u8_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd16, [gather_u8_f32_param_0];
	ld.param.u64 	%rd17, [gather_u8_f32_param_1];
	ld.param.u64 	%rd18, [gather_u8_f32_param_2];
	ld.param.u64 	%rd19, [gather_u8_f32_param_3];
	ld.param.u64 	%rd20, [gather_u8_f32_param_5];
	ld.param.u64 	%rd21, [gather_u8_f32_param_6];
	ld.param.u64 	%rd22, [gather_u8_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r16, %r6, %r1, %r7;
	cvt.u64.u32 	%rd37, %r16;
	setp.ge.u64 	%p1, %rd37, %rd16;
	@%p1 bra 	$L__BB25_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB25_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB25_4;

	rem.u64 	%rd38, %rd37, %rd22;
	bra.uni 	$L__BB25_5;

$L__BB25_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd37;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd38, %r11;

$L__BB25_5:
	add.s64 	%rd24, %rd3, %rd37;
	ld.global.u8 	%rd10, [%rd24];
	setp.eq.s64 	%p3, %rd10, 255;
	shl.b64 	%rd25, %rd37, 2;
	add.s64 	%rd11, %rd5, %rd25;
	@%p3 bra 	$L__BB25_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB25_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 40

$L__BB25_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB25_10;

	div.u64 	%rd39, %rd37, %rd2;
	bra.uni 	$L__BB25_11;

$L__BB25_12:
	mov.u32 	%r15, 0;
	st.global.u32 	[%rd11], %r15;
	bra.uni 	$L__BB25_13;

$L__BB25_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd37;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd39, %r14;

$L__BB25_11:
	mul.lo.s64 	%rd31, %rd39, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd38;
	shl.b64 	%rd35, %rd34, 2;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.f32 	%f1, [%rd36];
	st.global.f32 	[%rd11], %f1;

$L__BB25_13:
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd37, %r16;
	setp.lt.u64 	%p6, %rd37, %rd16;
	@%p6 bra 	$L__BB25_2;

$L__BB25_14:
	ret;

}
	// .globl	gather_u8_f64
.visible .entry gather_u8_f64(
	.param .u64 gather_u8_f64_param_0,
	.param .u64 gather_u8_f64_param_1,
	.param .u64 gather_u8_f64_param_2,
	.param .u64 gather_u8_f64_param_3,
	.param .u64 gather_u8_f64_param_4,
	.param .u64 gather_u8_f64_param_5,
	.param .u64 gather_u8_f64_param_6,
	.param .u64 gather_u8_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<41>;


	ld.param.u64 	%rd16, [gather_u8_f64_param_0];
	ld.param.u64 	%rd17, [gather_u8_f64_param_1];
	ld.param.u64 	%rd18, [gather_u8_f64_param_2];
	ld.param.u64 	%rd19, [gather_u8_f64_param_3];
	ld.param.u64 	%rd20, [gather_u8_f64_param_5];
	ld.param.u64 	%rd21, [gather_u8_f64_param_6];
	ld.param.u64 	%rd22, [gather_u8_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd38, %r15;
	setp.ge.u64 	%p1, %rd38, %rd16;
	@%p1 bra 	$L__BB26_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB26_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB26_4;

	rem.u64 	%rd39, %rd38, %rd22;
	bra.uni 	$L__BB26_5;

$L__BB26_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd38;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd39, %r11;

$L__BB26_5:
	add.s64 	%rd24, %rd3, %rd38;
	ld.global.u8 	%rd10, [%rd24];
	setp.eq.s64 	%p3, %rd10, 255;
	shl.b64 	%rd25, %rd38, 3;
	add.s64 	%rd11, %rd5, %rd25;
	@%p3 bra 	$L__BB26_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB26_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 41

$L__BB26_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB26_10;

	div.u64 	%rd40, %rd38, %rd2;
	bra.uni 	$L__BB26_11;

$L__BB26_12:
	mov.u64 	%rd37, 0;
	st.global.u64 	[%rd11], %rd37;
	bra.uni 	$L__BB26_13;

$L__BB26_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd38;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd40, %r14;

$L__BB26_11:
	mul.lo.s64 	%rd31, %rd40, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd39;
	shl.b64 	%rd35, %rd34, 3;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.f64 	%fd1, [%rd36];
	st.global.f64 	[%rd11], %fd1;

$L__BB26_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd38, %r15;
	setp.lt.u64 	%p6, %rd38, %rd16;
	@%p6 bra 	$L__BB26_2;

$L__BB26_14:
	ret;

}
	// .globl	gather_u8_u8
.visible .entry gather_u8_u8(
	.param .u64 gather_u8_u8_param_0,
	.param .u64 gather_u8_u8_param_1,
	.param .u64 gather_u8_u8_param_2,
	.param .u64 gather_u8_u8_param_3,
	.param .u64 gather_u8_u8_param_4,
	.param .u64 gather_u8_u8_param_5,
	.param .u64 gather_u8_u8_param_6,
	.param .u64 gather_u8_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd16, [gather_u8_u8_param_0];
	ld.param.u64 	%rd17, [gather_u8_u8_param_1];
	ld.param.u64 	%rd18, [gather_u8_u8_param_2];
	ld.param.u64 	%rd19, [gather_u8_u8_param_3];
	ld.param.u64 	%rd20, [gather_u8_u8_param_5];
	ld.param.u64 	%rd21, [gather_u8_u8_param_6];
	ld.param.u64 	%rd22, [gather_u8_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd35, %r15;
	setp.ge.u64 	%p1, %rd35, %rd16;
	@%p1 bra 	$L__BB27_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB27_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB27_4;

	rem.u64 	%rd36, %rd35, %rd22;
	bra.uni 	$L__BB27_5;

$L__BB27_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd35;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd36, %r11;

$L__BB27_5:
	add.s64 	%rd24, %rd3, %rd35;
	ld.global.u8 	%rd10, [%rd24];
	setp.eq.s64 	%p3, %rd10, 255;
	add.s64 	%rd11, %rd5, %rd35;
	@%p3 bra 	$L__BB27_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB27_8;

	mov.u64 	%rd25, $str$2;
	cvta.global.u64 	%rd26, %rd25;
	mov.u64 	%rd27, $str$1;
	cvta.global.u64 	%rd28, %rd27;
	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd28;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 42

$L__BB27_8:
	and.b64  	%rd29, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd29, 0;
	@%p5 bra 	$L__BB27_10;

	div.u64 	%rd37, %rd35, %rd2;
	bra.uni 	$L__BB27_11;

$L__BB27_12:
	mov.u16 	%rs2, 0;
	st.global.u8 	[%rd11], %rs2;
	bra.uni 	$L__BB27_13;

$L__BB27_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd35;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd37, %r14;

$L__BB27_11:
	mul.lo.s64 	%rd30, %rd37, %rd20;
	add.s64 	%rd31, %rd30, %rd10;
	mul.lo.s64 	%rd32, %rd31, %rd22;
	add.s64 	%rd33, %rd32, %rd36;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.u8 	%rs1, [%rd34];
	st.global.u8 	[%rd11], %rs1;

$L__BB27_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd35, %r15;
	setp.lt.u64 	%p6, %rd35, %rd16;
	@%p6 bra 	$L__BB27_2;

$L__BB27_14:
	ret;

}
	// .globl	gather_u8_u32
.visible .entry gather_u8_u32(
	.param .u64 gather_u8_u32_param_0,
	.param .u64 gather_u8_u32_param_1,
	.param .u64 gather_u8_u32_param_2,
	.param .u64 gather_u8_u32_param_3,
	.param .u64 gather_u8_u32_param_4,
	.param .u64 gather_u8_u32_param_5,
	.param .u64 gather_u8_u32_param_6,
	.param .u64 gather_u8_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd16, [gather_u8_u32_param_0];
	ld.param.u64 	%rd17, [gather_u8_u32_param_1];
	ld.param.u64 	%rd18, [gather_u8_u32_param_2];
	ld.param.u64 	%rd19, [gather_u8_u32_param_3];
	ld.param.u64 	%rd20, [gather_u8_u32_param_5];
	ld.param.u64 	%rd21, [gather_u8_u32_param_6];
	ld.param.u64 	%rd22, [gather_u8_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r17, %r6, %r1, %r7;
	cvt.u64.u32 	%rd37, %r17;
	setp.ge.u64 	%p1, %rd37, %rd16;
	@%p1 bra 	$L__BB28_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB28_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB28_4;

	rem.u64 	%rd38, %rd37, %rd22;
	bra.uni 	$L__BB28_5;

$L__BB28_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd37;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd38, %r11;

$L__BB28_5:
	add.s64 	%rd24, %rd3, %rd37;
	ld.global.u8 	%rd10, [%rd24];
	setp.eq.s64 	%p3, %rd10, 255;
	shl.b64 	%rd25, %rd37, 2;
	add.s64 	%rd11, %rd5, %rd25;
	@%p3 bra 	$L__BB28_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB28_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 43

$L__BB28_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB28_10;

	div.u64 	%rd39, %rd37, %rd2;
	bra.uni 	$L__BB28_11;

$L__BB28_12:
	mov.u32 	%r16, 0;
	st.global.u32 	[%rd11], %r16;
	bra.uni 	$L__BB28_13;

$L__BB28_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd37;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd39, %r14;

$L__BB28_11:
	mul.lo.s64 	%rd31, %rd39, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd38;
	shl.b64 	%rd35, %rd34, 2;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.u32 	%r15, [%rd36];
	st.global.u32 	[%rd11], %r15;

$L__BB28_13:
	add.s32 	%r17, %r17, %r3;
	cvt.u64.u32 	%rd37, %r17;
	setp.lt.u64 	%p6, %rd37, %rd16;
	@%p6 bra 	$L__BB28_2;

$L__BB28_14:
	ret;

}
	// .globl	gather_u8_i64
.visible .entry gather_u8_i64(
	.param .u64 gather_u8_i64_param_0,
	.param .u64 gather_u8_i64_param_1,
	.param .u64 gather_u8_i64_param_2,
	.param .u64 gather_u8_i64_param_3,
	.param .u64 gather_u8_i64_param_4,
	.param .u64 gather_u8_i64_param_5,
	.param .u64 gather_u8_i64_param_6,
	.param .u64 gather_u8_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<42>;


	ld.param.u64 	%rd16, [gather_u8_i64_param_0];
	ld.param.u64 	%rd17, [gather_u8_i64_param_1];
	ld.param.u64 	%rd18, [gather_u8_i64_param_2];
	ld.param.u64 	%rd19, [gather_u8_i64_param_3];
	ld.param.u64 	%rd20, [gather_u8_i64_param_5];
	ld.param.u64 	%rd21, [gather_u8_i64_param_6];
	ld.param.u64 	%rd22, [gather_u8_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd39, %r15;
	setp.ge.u64 	%p1, %rd39, %rd16;
	@%p1 bra 	$L__BB29_14;

	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	mul.lo.s64 	%rd2, %rd22, %rd21;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd18;
	cvta.to.global.u64 	%rd5, %rd19;

$L__BB29_2:
	and.b64  	%rd23, %rd22, -4294967296;
	setp.eq.s64 	%p2, %rd23, 0;
	@%p2 bra 	$L__BB29_4;

	rem.u64 	%rd40, %rd39, %rd22;
	bra.uni 	$L__BB29_5;

$L__BB29_4:
	cvt.u32.u64 	%r9, %rd22;
	cvt.u32.u64 	%r10, %rd39;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd40, %r11;

$L__BB29_5:
	add.s64 	%rd24, %rd3, %rd39;
	ld.global.u8 	%rd10, [%rd24];
	setp.eq.s64 	%p3, %rd10, 255;
	shl.b64 	%rd25, %rd39, 3;
	add.s64 	%rd11, %rd5, %rd25;
	@%p3 bra 	$L__BB29_12;

	setp.lt.u64 	%p4, %rd10, %rd20;
	@%p4 bra 	$L__BB29_8;

	mov.u64 	%rd26, $str$2;
	cvta.global.u64 	%rd27, %rd26;
	mov.u64 	%rd28, $str$1;
	cvta.global.u64 	%rd29, %rd28;
	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd29;
	.param .b32 param2;
	st.param.b32 	[param2+0], 108;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 44

$L__BB29_8:
	and.b64  	%rd30, %rd2, -4294967296;
	setp.eq.s64 	%p5, %rd30, 0;
	@%p5 bra 	$L__BB29_10;

	div.u64 	%rd41, %rd39, %rd2;
	bra.uni 	$L__BB29_11;

$L__BB29_12:
	mov.u64 	%rd38, 0;
	st.global.u64 	[%rd11], %rd38;
	bra.uni 	$L__BB29_13;

$L__BB29_10:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd39;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd41, %r14;

$L__BB29_11:
	mul.lo.s64 	%rd31, %rd41, %rd20;
	add.s64 	%rd32, %rd31, %rd10;
	mul.lo.s64 	%rd33, %rd32, %rd22;
	add.s64 	%rd34, %rd33, %rd40;
	shl.b64 	%rd35, %rd34, 3;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.u64 	%rd37, [%rd36];
	st.global.u64 	[%rd11], %rd37;

$L__BB29_13:
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd39, %r15;
	setp.lt.u64 	%p6, %rd39, %rd16;
	@%p6 bra 	$L__BB29_2;

$L__BB29_14:
	ret;

}
	// .globl	ia_i64_f32
.visible .entry ia_i64_f32(
	.param .u64 ia_i64_f32_param_0,
	.param .u64 ia_i64_f32_param_1,
	.param .u64 ia_i64_f32_param_2,
	.param .u64 ia_i64_f32_param_3,
	.param .u64 ia_i64_f32_param_4,
	.param .u64 ia_i64_f32_param_5,
	.param .u64 ia_i64_f32_param_6,
	.param .u64 ia_i64_f32_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd19, [ia_i64_f32_param_0];
	ld.param.u64 	%rd20, [ia_i64_f32_param_1];
	ld.param.u64 	%rd21, [ia_i64_f32_param_2];
	ld.param.u64 	%rd22, [ia_i64_f32_param_3];
	ld.param.u64 	%rd25, [ia_i64_f32_param_4];
	ld.param.u64 	%rd23, [ia_i64_f32_param_6];
	ld.param.u64 	%rd24, [ia_i64_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB30_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB30_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB30_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB30_5;

	div.u64 	%rd47, %rd46, %rd24;
	mul.lo.s64 	%rd27, %rd47, %rd24;
	sub.s64 	%rd48, %rd46, %rd27;
	bra.uni 	$L__BB30_6;

$L__BB30_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB30_6:
	mul.lo.s64 	%rd13, %rd47, %rd20;
	mul.lo.s64 	%rd14, %rd47, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB30_7:
	shl.b64 	%rd29, %rd49, 3;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u64 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 9223372036854775807;
	@%p4 bra 	$L__BB30_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB30_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 45

$L__BB30_10:
	add.s64 	%rd35, %rd16, %rd14;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd48;
	shl.b64 	%rd38, %rd37, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f32 	%f1, [%rd39];
	add.s64 	%rd40, %rd49, %rd13;
	mul.lo.s64 	%rd41, %rd40, %rd24;
	add.s64 	%rd42, %rd41, %rd48;
	shl.b64 	%rd43, %rd42, 2;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.f32 	%f2, [%rd44];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd39], %f3;

$L__BB30_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd20;
	@%p6 bra 	$L__BB30_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB30_3;
	bra.uni 	$L__BB30_14;

$L__BB30_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB30_13;

$L__BB30_14:
	ret;

}
	// .globl	ia_i64_f64
.visible .entry ia_i64_f64(
	.param .u64 ia_i64_f64_param_0,
	.param .u64 ia_i64_f64_param_1,
	.param .u64 ia_i64_f64_param_2,
	.param .u64 ia_i64_f64_param_3,
	.param .u64 ia_i64_f64_param_4,
	.param .u64 ia_i64_f64_param_5,
	.param .u64 ia_i64_f64_param_6,
	.param .u64 ia_i64_f64_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd19, [ia_i64_f64_param_0];
	ld.param.u64 	%rd20, [ia_i64_f64_param_1];
	ld.param.u64 	%rd21, [ia_i64_f64_param_2];
	ld.param.u64 	%rd22, [ia_i64_f64_param_3];
	ld.param.u64 	%rd25, [ia_i64_f64_param_4];
	ld.param.u64 	%rd23, [ia_i64_f64_param_6];
	ld.param.u64 	%rd24, [ia_i64_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB31_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB31_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB31_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB31_5;

	div.u64 	%rd47, %rd46, %rd24;
	mul.lo.s64 	%rd27, %rd47, %rd24;
	sub.s64 	%rd48, %rd46, %rd27;
	bra.uni 	$L__BB31_6;

$L__BB31_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB31_6:
	mul.lo.s64 	%rd13, %rd47, %rd20;
	mul.lo.s64 	%rd14, %rd47, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB31_7:
	shl.b64 	%rd29, %rd49, 3;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u64 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 9223372036854775807;
	@%p4 bra 	$L__BB31_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB31_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 46

$L__BB31_10:
	add.s64 	%rd35, %rd16, %rd14;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd48;
	shl.b64 	%rd38, %rd37, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f64 	%fd1, [%rd39];
	add.s64 	%rd40, %rd49, %rd13;
	mul.lo.s64 	%rd41, %rd40, %rd24;
	add.s64 	%rd42, %rd41, %rd48;
	shl.b64 	%rd43, %rd42, 3;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.f64 	%fd2, [%rd44];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd39], %fd3;

$L__BB31_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd20;
	@%p6 bra 	$L__BB31_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB31_3;
	bra.uni 	$L__BB31_14;

$L__BB31_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB31_13;

$L__BB31_14:
	ret;

}
	// .globl	ia_i64_u8
.visible .entry ia_i64_u8(
	.param .u64 ia_i64_u8_param_0,
	.param .u64 ia_i64_u8_param_1,
	.param .u64 ia_i64_u8_param_2,
	.param .u64 ia_i64_u8_param_3,
	.param .u64 ia_i64_u8_param_4,
	.param .u64 ia_i64_u8_param_5,
	.param .u64 ia_i64_u8_param_6,
	.param .u64 ia_i64_u8_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd19, [ia_i64_u8_param_0];
	ld.param.u64 	%rd20, [ia_i64_u8_param_1];
	ld.param.u64 	%rd21, [ia_i64_u8_param_2];
	ld.param.u64 	%rd22, [ia_i64_u8_param_3];
	ld.param.u64 	%rd25, [ia_i64_u8_param_4];
	ld.param.u64 	%rd23, [ia_i64_u8_param_6];
	ld.param.u64 	%rd24, [ia_i64_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB32_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB32_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB32_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB32_5;

	div.u64 	%rd45, %rd44, %rd24;
	mul.lo.s64 	%rd27, %rd45, %rd24;
	sub.s64 	%rd46, %rd44, %rd27;
	bra.uni 	$L__BB32_6;

$L__BB32_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB32_6:
	mul.lo.s64 	%rd13, %rd45, %rd20;
	mul.lo.s64 	%rd14, %rd45, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB32_7:
	shl.b64 	%rd29, %rd47, 3;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u64 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 9223372036854775807;
	@%p4 bra 	$L__BB32_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB32_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 47

$L__BB32_10:
	add.s64 	%rd35, %rd16, %rd14;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd46;
	add.s64 	%rd38, %rd3, %rd37;
	ld.global.u8 	%rs1, [%rd38];
	add.s64 	%rd39, %rd47, %rd13;
	mul.lo.s64 	%rd40, %rd39, %rd24;
	add.s64 	%rd41, %rd40, %rd46;
	add.s64 	%rd42, %rd4, %rd41;
	ld.global.u8 	%rs2, [%rd42];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;

$L__BB32_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p6, %rd47, %rd20;
	@%p6 bra 	$L__BB32_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p7, %rd2, %rd44;
	@%p7 bra 	$L__BB32_3;
	bra.uni 	$L__BB32_14;

$L__BB32_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p8, %rd2, %rd43;
	@%p8 bra 	$L__BB32_13;

$L__BB32_14:
	ret;

}
	// .globl	ia_i64_i64
.visible .entry ia_i64_i64(
	.param .u64 ia_i64_i64_param_0,
	.param .u64 ia_i64_i64_param_1,
	.param .u64 ia_i64_i64_param_2,
	.param .u64 ia_i64_i64_param_3,
	.param .u64 ia_i64_i64_param_4,
	.param .u64 ia_i64_i64_param_5,
	.param .u64 ia_i64_i64_param_6,
	.param .u64 ia_i64_i64_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<53>;


	ld.param.u64 	%rd19, [ia_i64_i64_param_0];
	ld.param.u64 	%rd20, [ia_i64_i64_param_1];
	ld.param.u64 	%rd21, [ia_i64_i64_param_2];
	ld.param.u64 	%rd22, [ia_i64_i64_param_3];
	ld.param.u64 	%rd25, [ia_i64_i64_param_4];
	ld.param.u64 	%rd23, [ia_i64_i64_param_6];
	ld.param.u64 	%rd24, [ia_i64_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd49, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd49;
	@%p1 bra 	$L__BB33_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB33_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB33_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB33_5;

	div.u64 	%rd50, %rd49, %rd24;
	mul.lo.s64 	%rd27, %rd50, %rd24;
	sub.s64 	%rd51, %rd49, %rd27;
	bra.uni 	$L__BB33_6;

$L__BB33_5:
	cvt.u32.u64 	%r14, %rd49;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd50, %r15;
	cvt.u64.u32 	%rd51, %r17;

$L__BB33_6:
	mul.lo.s64 	%rd13, %rd50, %rd20;
	mul.lo.s64 	%rd14, %rd50, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd52, 0;

$L__BB33_7:
	shl.b64 	%rd29, %rd52, 3;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u64 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 9223372036854775807;
	@%p4 bra 	$L__BB33_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB33_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 48

$L__BB33_10:
	add.s64 	%rd35, %rd16, %rd14;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd51;
	shl.b64 	%rd38, %rd37, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u64 	%rd40, [%rd39];
	add.s64 	%rd41, %rd52, %rd13;
	mul.lo.s64 	%rd42, %rd41, %rd24;
	add.s64 	%rd43, %rd42, %rd51;
	shl.b64 	%rd44, %rd43, 3;
	add.s64 	%rd45, %rd4, %rd44;
	ld.global.u64 	%rd46, [%rd45];
	add.s64 	%rd47, %rd40, %rd46;
	st.global.u64 	[%rd39], %rd47;

$L__BB33_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd52, %r20;
	setp.lt.u64 	%p6, %rd52, %rd20;
	@%p6 bra 	$L__BB33_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd49, %r19;
	setp.gt.u64 	%p7, %rd2, %rd49;
	@%p7 bra 	$L__BB33_3;
	bra.uni 	$L__BB33_14;

$L__BB33_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd48, %r19;
	setp.gt.u64 	%p8, %rd2, %rd48;
	@%p8 bra 	$L__BB33_13;

$L__BB33_14:
	ret;

}
	// .globl	ia_i64_u32
.visible .entry ia_i64_u32(
	.param .u64 ia_i64_u32_param_0,
	.param .u64 ia_i64_u32_param_1,
	.param .u64 ia_i64_u32_param_2,
	.param .u64 ia_i64_u32_param_3,
	.param .u64 ia_i64_u32_param_4,
	.param .u64 ia_i64_u32_param_5,
	.param .u64 ia_i64_u32_param_6,
	.param .u64 ia_i64_u32_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd19, [ia_i64_u32_param_0];
	ld.param.u64 	%rd20, [ia_i64_u32_param_1];
	ld.param.u64 	%rd21, [ia_i64_u32_param_2];
	ld.param.u64 	%rd22, [ia_i64_u32_param_3];
	ld.param.u64 	%rd25, [ia_i64_u32_param_4];
	ld.param.u64 	%rd23, [ia_i64_u32_param_6];
	ld.param.u64 	%rd24, [ia_i64_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r22;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB34_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB34_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB34_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB34_5;

	div.u64 	%rd47, %rd46, %rd24;
	mul.lo.s64 	%rd27, %rd47, %rd24;
	sub.s64 	%rd48, %rd46, %rd27;
	bra.uni 	$L__BB34_6;

$L__BB34_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB34_6:
	mul.lo.s64 	%rd13, %rd47, %rd20;
	mul.lo.s64 	%rd14, %rd47, %rd23;
	mov.u32 	%r23, 0;
	mov.u64 	%rd49, 0;

$L__BB34_7:
	shl.b64 	%rd29, %rd49, 3;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u64 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 9223372036854775807;
	@%p4 bra 	$L__BB34_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB34_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 49

$L__BB34_10:
	add.s64 	%rd35, %rd16, %rd14;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd48;
	shl.b64 	%rd38, %rd37, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r19, [%rd39];
	add.s64 	%rd40, %rd49, %rd13;
	mul.lo.s64 	%rd41, %rd40, %rd24;
	add.s64 	%rd42, %rd41, %rd48;
	shl.b64 	%rd43, %rd42, 2;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.u32 	%r20, [%rd44];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd39], %r21;

$L__BB34_11:
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd49, %r23;
	setp.lt.u64 	%p6, %rd49, %rd20;
	@%p6 bra 	$L__BB34_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd46, %r22;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB34_3;
	bra.uni 	$L__BB34_14;

$L__BB34_13:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd45, %r22;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB34_13;

$L__BB34_14:
	ret;

}
	// .globl	ia_u32_f32
.visible .entry ia_u32_f32(
	.param .u64 ia_u32_f32_param_0,
	.param .u64 ia_u32_f32_param_1,
	.param .u64 ia_u32_f32_param_2,
	.param .u64 ia_u32_f32_param_3,
	.param .u64 ia_u32_f32_param_4,
	.param .u64 ia_u32_f32_param_5,
	.param .u64 ia_u32_f32_param_6,
	.param .u64 ia_u32_f32_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd19, [ia_u32_f32_param_0];
	ld.param.u64 	%rd20, [ia_u32_f32_param_1];
	ld.param.u64 	%rd21, [ia_u32_f32_param_2];
	ld.param.u64 	%rd22, [ia_u32_f32_param_3];
	ld.param.u64 	%rd25, [ia_u32_f32_param_4];
	ld.param.u64 	%rd23, [ia_u32_f32_param_6];
	ld.param.u64 	%rd24, [ia_u32_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB35_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB35_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB35_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB35_5;

	div.u64 	%rd47, %rd46, %rd24;
	mul.lo.s64 	%rd27, %rd47, %rd24;
	sub.s64 	%rd48, %rd46, %rd27;
	bra.uni 	$L__BB35_6;

$L__BB35_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB35_6:
	mul.lo.s64 	%rd13, %rd47, %rd20;
	mul.lo.s64 	%rd14, %rd47, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB35_7:
	shl.b64 	%rd29, %rd49, 2;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u32 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 4294967295;
	@%p4 bra 	$L__BB35_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB35_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 50

$L__BB35_10:
	add.s64 	%rd35, %rd14, %rd16;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd48;
	shl.b64 	%rd38, %rd37, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f32 	%f1, [%rd39];
	add.s64 	%rd40, %rd49, %rd13;
	mul.lo.s64 	%rd41, %rd40, %rd24;
	add.s64 	%rd42, %rd41, %rd48;
	shl.b64 	%rd43, %rd42, 2;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.f32 	%f2, [%rd44];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd39], %f3;

$L__BB35_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd20;
	@%p6 bra 	$L__BB35_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB35_3;
	bra.uni 	$L__BB35_14;

$L__BB35_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB35_13;

$L__BB35_14:
	ret;

}
	// .globl	ia_u32_f64
.visible .entry ia_u32_f64(
	.param .u64 ia_u32_f64_param_0,
	.param .u64 ia_u32_f64_param_1,
	.param .u64 ia_u32_f64_param_2,
	.param .u64 ia_u32_f64_param_3,
	.param .u64 ia_u32_f64_param_4,
	.param .u64 ia_u32_f64_param_5,
	.param .u64 ia_u32_f64_param_6,
	.param .u64 ia_u32_f64_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd19, [ia_u32_f64_param_0];
	ld.param.u64 	%rd20, [ia_u32_f64_param_1];
	ld.param.u64 	%rd21, [ia_u32_f64_param_2];
	ld.param.u64 	%rd22, [ia_u32_f64_param_3];
	ld.param.u64 	%rd25, [ia_u32_f64_param_4];
	ld.param.u64 	%rd23, [ia_u32_f64_param_6];
	ld.param.u64 	%rd24, [ia_u32_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB36_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB36_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB36_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB36_5;

	div.u64 	%rd47, %rd46, %rd24;
	mul.lo.s64 	%rd27, %rd47, %rd24;
	sub.s64 	%rd48, %rd46, %rd27;
	bra.uni 	$L__BB36_6;

$L__BB36_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB36_6:
	mul.lo.s64 	%rd13, %rd47, %rd20;
	mul.lo.s64 	%rd14, %rd47, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB36_7:
	shl.b64 	%rd29, %rd49, 2;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u32 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 4294967295;
	@%p4 bra 	$L__BB36_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB36_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 51

$L__BB36_10:
	add.s64 	%rd35, %rd14, %rd16;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd48;
	shl.b64 	%rd38, %rd37, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f64 	%fd1, [%rd39];
	add.s64 	%rd40, %rd49, %rd13;
	mul.lo.s64 	%rd41, %rd40, %rd24;
	add.s64 	%rd42, %rd41, %rd48;
	shl.b64 	%rd43, %rd42, 3;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.f64 	%fd2, [%rd44];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd39], %fd3;

$L__BB36_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd20;
	@%p6 bra 	$L__BB36_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB36_3;
	bra.uni 	$L__BB36_14;

$L__BB36_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB36_13;

$L__BB36_14:
	ret;

}
	// .globl	ia_u32_u8
.visible .entry ia_u32_u8(
	.param .u64 ia_u32_u8_param_0,
	.param .u64 ia_u32_u8_param_1,
	.param .u64 ia_u32_u8_param_2,
	.param .u64 ia_u32_u8_param_3,
	.param .u64 ia_u32_u8_param_4,
	.param .u64 ia_u32_u8_param_5,
	.param .u64 ia_u32_u8_param_6,
	.param .u64 ia_u32_u8_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd19, [ia_u32_u8_param_0];
	ld.param.u64 	%rd20, [ia_u32_u8_param_1];
	ld.param.u64 	%rd21, [ia_u32_u8_param_2];
	ld.param.u64 	%rd22, [ia_u32_u8_param_3];
	ld.param.u64 	%rd25, [ia_u32_u8_param_4];
	ld.param.u64 	%rd23, [ia_u32_u8_param_6];
	ld.param.u64 	%rd24, [ia_u32_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB37_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB37_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB37_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB37_5;

	div.u64 	%rd45, %rd44, %rd24;
	mul.lo.s64 	%rd27, %rd45, %rd24;
	sub.s64 	%rd46, %rd44, %rd27;
	bra.uni 	$L__BB37_6;

$L__BB37_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB37_6:
	mul.lo.s64 	%rd13, %rd45, %rd20;
	mul.lo.s64 	%rd14, %rd45, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB37_7:
	shl.b64 	%rd29, %rd47, 2;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u32 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 4294967295;
	@%p4 bra 	$L__BB37_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB37_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 52

$L__BB37_10:
	add.s64 	%rd35, %rd14, %rd16;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd46;
	add.s64 	%rd38, %rd3, %rd37;
	ld.global.u8 	%rs1, [%rd38];
	add.s64 	%rd39, %rd47, %rd13;
	mul.lo.s64 	%rd40, %rd39, %rd24;
	add.s64 	%rd41, %rd40, %rd46;
	add.s64 	%rd42, %rd4, %rd41;
	ld.global.u8 	%rs2, [%rd42];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;

$L__BB37_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p6, %rd47, %rd20;
	@%p6 bra 	$L__BB37_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p7, %rd2, %rd44;
	@%p7 bra 	$L__BB37_3;
	bra.uni 	$L__BB37_14;

$L__BB37_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p8, %rd2, %rd43;
	@%p8 bra 	$L__BB37_13;

$L__BB37_14:
	ret;

}
	// .globl	ia_u32_i64
.visible .entry ia_u32_i64(
	.param .u64 ia_u32_i64_param_0,
	.param .u64 ia_u32_i64_param_1,
	.param .u64 ia_u32_i64_param_2,
	.param .u64 ia_u32_i64_param_3,
	.param .u64 ia_u32_i64_param_4,
	.param .u64 ia_u32_i64_param_5,
	.param .u64 ia_u32_i64_param_6,
	.param .u64 ia_u32_i64_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<53>;


	ld.param.u64 	%rd19, [ia_u32_i64_param_0];
	ld.param.u64 	%rd20, [ia_u32_i64_param_1];
	ld.param.u64 	%rd21, [ia_u32_i64_param_2];
	ld.param.u64 	%rd22, [ia_u32_i64_param_3];
	ld.param.u64 	%rd25, [ia_u32_i64_param_4];
	ld.param.u64 	%rd23, [ia_u32_i64_param_6];
	ld.param.u64 	%rd24, [ia_u32_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd49, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd49;
	@%p1 bra 	$L__BB38_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB38_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB38_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB38_5;

	div.u64 	%rd50, %rd49, %rd24;
	mul.lo.s64 	%rd27, %rd50, %rd24;
	sub.s64 	%rd51, %rd49, %rd27;
	bra.uni 	$L__BB38_6;

$L__BB38_5:
	cvt.u32.u64 	%r14, %rd49;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd50, %r15;
	cvt.u64.u32 	%rd51, %r17;

$L__BB38_6:
	mul.lo.s64 	%rd13, %rd50, %rd20;
	mul.lo.s64 	%rd14, %rd50, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd52, 0;

$L__BB38_7:
	shl.b64 	%rd29, %rd52, 2;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u32 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 4294967295;
	@%p4 bra 	$L__BB38_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB38_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 53, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 53

$L__BB38_10:
	add.s64 	%rd35, %rd14, %rd16;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd51;
	shl.b64 	%rd38, %rd37, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u64 	%rd40, [%rd39];
	add.s64 	%rd41, %rd52, %rd13;
	mul.lo.s64 	%rd42, %rd41, %rd24;
	add.s64 	%rd43, %rd42, %rd51;
	shl.b64 	%rd44, %rd43, 3;
	add.s64 	%rd45, %rd4, %rd44;
	ld.global.u64 	%rd46, [%rd45];
	add.s64 	%rd47, %rd40, %rd46;
	st.global.u64 	[%rd39], %rd47;

$L__BB38_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd52, %r20;
	setp.lt.u64 	%p6, %rd52, %rd20;
	@%p6 bra 	$L__BB38_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd49, %r19;
	setp.gt.u64 	%p7, %rd2, %rd49;
	@%p7 bra 	$L__BB38_3;
	bra.uni 	$L__BB38_14;

$L__BB38_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd48, %r19;
	setp.gt.u64 	%p8, %rd2, %rd48;
	@%p8 bra 	$L__BB38_13;

$L__BB38_14:
	ret;

}
	// .globl	ia_u32_u32
.visible .entry ia_u32_u32(
	.param .u64 ia_u32_u32_param_0,
	.param .u64 ia_u32_u32_param_1,
	.param .u64 ia_u32_u32_param_2,
	.param .u64 ia_u32_u32_param_3,
	.param .u64 ia_u32_u32_param_4,
	.param .u64 ia_u32_u32_param_5,
	.param .u64 ia_u32_u32_param_6,
	.param .u64 ia_u32_u32_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd19, [ia_u32_u32_param_0];
	ld.param.u64 	%rd20, [ia_u32_u32_param_1];
	ld.param.u64 	%rd21, [ia_u32_u32_param_2];
	ld.param.u64 	%rd22, [ia_u32_u32_param_3];
	ld.param.u64 	%rd25, [ia_u32_u32_param_4];
	ld.param.u64 	%rd23, [ia_u32_u32_param_6];
	ld.param.u64 	%rd24, [ia_u32_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r22;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB39_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB39_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB39_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB39_5;

	div.u64 	%rd47, %rd46, %rd24;
	mul.lo.s64 	%rd27, %rd47, %rd24;
	sub.s64 	%rd48, %rd46, %rd27;
	bra.uni 	$L__BB39_6;

$L__BB39_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB39_6:
	mul.lo.s64 	%rd13, %rd47, %rd20;
	mul.lo.s64 	%rd14, %rd47, %rd23;
	mov.u32 	%r23, 0;
	mov.u64 	%rd49, 0;

$L__BB39_7:
	shl.b64 	%rd29, %rd49, 2;
	add.s64 	%rd30, %rd5, %rd29;
	ld.global.u32 	%rd16, [%rd30];
	setp.eq.s64 	%p4, %rd16, 4294967295;
	@%p4 bra 	$L__BB39_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB39_10;

	mov.u64 	%rd31, $str$3;
	cvta.global.u64 	%rd32, %rd31;
	mov.u64 	%rd33, $str$1;
	cvta.global.u64 	%rd34, %rd33;
	{ // callseq 54, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 54

$L__BB39_10:
	add.s64 	%rd35, %rd14, %rd16;
	mul.lo.s64 	%rd36, %rd35, %rd24;
	add.s64 	%rd37, %rd36, %rd48;
	shl.b64 	%rd38, %rd37, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r19, [%rd39];
	add.s64 	%rd40, %rd49, %rd13;
	mul.lo.s64 	%rd41, %rd40, %rd24;
	add.s64 	%rd42, %rd41, %rd48;
	shl.b64 	%rd43, %rd42, 2;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.u32 	%r20, [%rd44];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd39], %r21;

$L__BB39_11:
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd49, %r23;
	setp.lt.u64 	%p6, %rd49, %rd20;
	@%p6 bra 	$L__BB39_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd46, %r22;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB39_3;
	bra.uni 	$L__BB39_14;

$L__BB39_13:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd45, %r22;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB39_13;

$L__BB39_14:
	ret;

}
	// .globl	ia_u8_f32
.visible .entry ia_u8_f32(
	.param .u64 ia_u8_f32_param_0,
	.param .u64 ia_u8_f32_param_1,
	.param .u64 ia_u8_f32_param_2,
	.param .u64 ia_u8_f32_param_3,
	.param .u64 ia_u8_f32_param_4,
	.param .u64 ia_u8_f32_param_5,
	.param .u64 ia_u8_f32_param_6,
	.param .u64 ia_u8_f32_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd19, [ia_u8_f32_param_0];
	ld.param.u64 	%rd20, [ia_u8_f32_param_1];
	ld.param.u64 	%rd21, [ia_u8_f32_param_2];
	ld.param.u64 	%rd22, [ia_u8_f32_param_3];
	ld.param.u64 	%rd25, [ia_u8_f32_param_4];
	ld.param.u64 	%rd23, [ia_u8_f32_param_6];
	ld.param.u64 	%rd24, [ia_u8_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB40_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB40_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB40_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB40_5;

	div.u64 	%rd46, %rd45, %rd24;
	mul.lo.s64 	%rd27, %rd46, %rd24;
	sub.s64 	%rd47, %rd45, %rd27;
	bra.uni 	$L__BB40_6;

$L__BB40_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB40_6:
	mul.lo.s64 	%rd13, %rd46, %rd20;
	mul.lo.s64 	%rd14, %rd46, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB40_7:
	add.s64 	%rd29, %rd5, %rd48;
	ld.global.u8 	%rd16, [%rd29];
	setp.eq.s64 	%p4, %rd16, 255;
	@%p4 bra 	$L__BB40_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB40_10;

	mov.u64 	%rd30, $str$3;
	cvta.global.u64 	%rd31, %rd30;
	mov.u64 	%rd32, $str$1;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 55, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd31;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 55

$L__BB40_10:
	add.s64 	%rd34, %rd14, %rd16;
	mul.lo.s64 	%rd35, %rd34, %rd24;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd36, 2;
	add.s64 	%rd38, %rd3, %rd37;
	ld.global.f32 	%f1, [%rd38];
	add.s64 	%rd39, %rd48, %rd13;
	mul.lo.s64 	%rd40, %rd39, %rd24;
	add.s64 	%rd41, %rd40, %rd47;
	shl.b64 	%rd42, %rd41, 2;
	add.s64 	%rd43, %rd4, %rd42;
	ld.global.f32 	%f2, [%rd43];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd38], %f3;

$L__BB40_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p6, %rd48, %rd20;
	@%p6 bra 	$L__BB40_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB40_3;
	bra.uni 	$L__BB40_14;

$L__BB40_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB40_13;

$L__BB40_14:
	ret;

}
	// .globl	ia_u8_f64
.visible .entry ia_u8_f64(
	.param .u64 ia_u8_f64_param_0,
	.param .u64 ia_u8_f64_param_1,
	.param .u64 ia_u8_f64_param_2,
	.param .u64 ia_u8_f64_param_3,
	.param .u64 ia_u8_f64_param_4,
	.param .u64 ia_u8_f64_param_5,
	.param .u64 ia_u8_f64_param_6,
	.param .u64 ia_u8_f64_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd19, [ia_u8_f64_param_0];
	ld.param.u64 	%rd20, [ia_u8_f64_param_1];
	ld.param.u64 	%rd21, [ia_u8_f64_param_2];
	ld.param.u64 	%rd22, [ia_u8_f64_param_3];
	ld.param.u64 	%rd25, [ia_u8_f64_param_4];
	ld.param.u64 	%rd23, [ia_u8_f64_param_6];
	ld.param.u64 	%rd24, [ia_u8_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB41_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB41_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB41_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB41_5;

	div.u64 	%rd46, %rd45, %rd24;
	mul.lo.s64 	%rd27, %rd46, %rd24;
	sub.s64 	%rd47, %rd45, %rd27;
	bra.uni 	$L__BB41_6;

$L__BB41_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB41_6:
	mul.lo.s64 	%rd13, %rd46, %rd20;
	mul.lo.s64 	%rd14, %rd46, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB41_7:
	add.s64 	%rd29, %rd5, %rd48;
	ld.global.u8 	%rd16, [%rd29];
	setp.eq.s64 	%p4, %rd16, 255;
	@%p4 bra 	$L__BB41_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB41_10;

	mov.u64 	%rd30, $str$3;
	cvta.global.u64 	%rd31, %rd30;
	mov.u64 	%rd32, $str$1;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 56, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd31;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 56

$L__BB41_10:
	add.s64 	%rd34, %rd14, %rd16;
	mul.lo.s64 	%rd35, %rd34, %rd24;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd36, 3;
	add.s64 	%rd38, %rd3, %rd37;
	ld.global.f64 	%fd1, [%rd38];
	add.s64 	%rd39, %rd48, %rd13;
	mul.lo.s64 	%rd40, %rd39, %rd24;
	add.s64 	%rd41, %rd40, %rd47;
	shl.b64 	%rd42, %rd41, 3;
	add.s64 	%rd43, %rd4, %rd42;
	ld.global.f64 	%fd2, [%rd43];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd38], %fd3;

$L__BB41_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p6, %rd48, %rd20;
	@%p6 bra 	$L__BB41_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB41_3;
	bra.uni 	$L__BB41_14;

$L__BB41_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB41_13;

$L__BB41_14:
	ret;

}
	// .globl	ia_u8_u8
.visible .entry ia_u8_u8(
	.param .u64 ia_u8_u8_param_0,
	.param .u64 ia_u8_u8_param_1,
	.param .u64 ia_u8_u8_param_2,
	.param .u64 ia_u8_u8_param_3,
	.param .u64 ia_u8_u8_param_4,
	.param .u64 ia_u8_u8_param_5,
	.param .u64 ia_u8_u8_param_6,
	.param .u64 ia_u8_u8_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<47>;


	ld.param.u64 	%rd19, [ia_u8_u8_param_0];
	ld.param.u64 	%rd20, [ia_u8_u8_param_1];
	ld.param.u64 	%rd21, [ia_u8_u8_param_2];
	ld.param.u64 	%rd22, [ia_u8_u8_param_3];
	ld.param.u64 	%rd25, [ia_u8_u8_param_4];
	ld.param.u64 	%rd23, [ia_u8_u8_param_6];
	ld.param.u64 	%rd24, [ia_u8_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd43, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd43;
	@%p1 bra 	$L__BB42_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB42_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB42_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB42_5;

	div.u64 	%rd44, %rd43, %rd24;
	mul.lo.s64 	%rd27, %rd44, %rd24;
	sub.s64 	%rd45, %rd43, %rd27;
	bra.uni 	$L__BB42_6;

$L__BB42_5:
	cvt.u32.u64 	%r14, %rd43;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd44, %r15;
	cvt.u64.u32 	%rd45, %r17;

$L__BB42_6:
	mul.lo.s64 	%rd13, %rd44, %rd20;
	mul.lo.s64 	%rd14, %rd44, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd46, 0;

$L__BB42_7:
	add.s64 	%rd29, %rd5, %rd46;
	ld.global.u8 	%rd16, [%rd29];
	setp.eq.s64 	%p4, %rd16, 255;
	@%p4 bra 	$L__BB42_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB42_10;

	mov.u64 	%rd30, $str$3;
	cvta.global.u64 	%rd31, %rd30;
	mov.u64 	%rd32, $str$1;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 57, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd31;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 57

$L__BB42_10:
	add.s64 	%rd34, %rd14, %rd16;
	mul.lo.s64 	%rd35, %rd34, %rd24;
	add.s64 	%rd36, %rd35, %rd45;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd37];
	add.s64 	%rd38, %rd46, %rd13;
	mul.lo.s64 	%rd39, %rd38, %rd24;
	add.s64 	%rd40, %rd39, %rd45;
	add.s64 	%rd41, %rd4, %rd40;
	ld.global.u8 	%rs2, [%rd41];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd37], %rs3;

$L__BB42_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd46, %r20;
	setp.lt.u64 	%p6, %rd46, %rd20;
	@%p6 bra 	$L__BB42_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p7, %rd2, %rd43;
	@%p7 bra 	$L__BB42_3;
	bra.uni 	$L__BB42_14;

$L__BB42_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p8, %rd2, %rd42;
	@%p8 bra 	$L__BB42_13;

$L__BB42_14:
	ret;

}
	// .globl	ia_u8_u32
.visible .entry ia_u8_u32(
	.param .u64 ia_u8_u32_param_0,
	.param .u64 ia_u8_u32_param_1,
	.param .u64 ia_u8_u32_param_2,
	.param .u64 ia_u8_u32_param_3,
	.param .u64 ia_u8_u32_param_4,
	.param .u64 ia_u8_u32_param_5,
	.param .u64 ia_u8_u32_param_6,
	.param .u64 ia_u8_u32_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd19, [ia_u8_u32_param_0];
	ld.param.u64 	%rd20, [ia_u8_u32_param_1];
	ld.param.u64 	%rd21, [ia_u8_u32_param_2];
	ld.param.u64 	%rd22, [ia_u8_u32_param_3];
	ld.param.u64 	%rd25, [ia_u8_u32_param_4];
	ld.param.u64 	%rd23, [ia_u8_u32_param_6];
	ld.param.u64 	%rd24, [ia_u8_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r22;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB43_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB43_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB43_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB43_5;

	div.u64 	%rd46, %rd45, %rd24;
	mul.lo.s64 	%rd27, %rd46, %rd24;
	sub.s64 	%rd47, %rd45, %rd27;
	bra.uni 	$L__BB43_6;

$L__BB43_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB43_6:
	mul.lo.s64 	%rd13, %rd46, %rd20;
	mul.lo.s64 	%rd14, %rd46, %rd23;
	mov.u32 	%r23, 0;
	mov.u64 	%rd48, 0;

$L__BB43_7:
	add.s64 	%rd29, %rd5, %rd48;
	ld.global.u8 	%rd16, [%rd29];
	setp.eq.s64 	%p4, %rd16, 255;
	@%p4 bra 	$L__BB43_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB43_10;

	mov.u64 	%rd30, $str$3;
	cvta.global.u64 	%rd31, %rd30;
	mov.u64 	%rd32, $str$1;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 58, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd31;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 58

$L__BB43_10:
	add.s64 	%rd34, %rd14, %rd16;
	mul.lo.s64 	%rd35, %rd34, %rd24;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd36, 2;
	add.s64 	%rd38, %rd3, %rd37;
	ld.global.u32 	%r19, [%rd38];
	add.s64 	%rd39, %rd48, %rd13;
	mul.lo.s64 	%rd40, %rd39, %rd24;
	add.s64 	%rd41, %rd40, %rd47;
	shl.b64 	%rd42, %rd41, 2;
	add.s64 	%rd43, %rd4, %rd42;
	ld.global.u32 	%r20, [%rd43];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd38], %r21;

$L__BB43_11:
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd48, %r23;
	setp.lt.u64 	%p6, %rd48, %rd20;
	@%p6 bra 	$L__BB43_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd45, %r22;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB43_3;
	bra.uni 	$L__BB43_14;

$L__BB43_13:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd44, %r22;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB43_13;

$L__BB43_14:
	ret;

}
	// .globl	ia_u8_i64
.visible .entry ia_u8_i64(
	.param .u64 ia_u8_i64_param_0,
	.param .u64 ia_u8_i64_param_1,
	.param .u64 ia_u8_i64_param_2,
	.param .u64 ia_u8_i64_param_3,
	.param .u64 ia_u8_i64_param_4,
	.param .u64 ia_u8_i64_param_5,
	.param .u64 ia_u8_i64_param_6,
	.param .u64 ia_u8_i64_param_7
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<52>;


	ld.param.u64 	%rd19, [ia_u8_i64_param_0];
	ld.param.u64 	%rd20, [ia_u8_i64_param_1];
	ld.param.u64 	%rd21, [ia_u8_i64_param_2];
	ld.param.u64 	%rd22, [ia_u8_i64_param_3];
	ld.param.u64 	%rd25, [ia_u8_i64_param_4];
	ld.param.u64 	%rd23, [ia_u8_i64_param_6];
	ld.param.u64 	%rd24, [ia_u8_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd48, %r19;
	mul.lo.s64 	%rd2, %rd24, %rd25;
	setp.le.u64 	%p1, %rd2, %rd48;
	@%p1 bra 	$L__BB44_14;

	setp.eq.s64 	%p2, %rd20, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB44_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd19;
	cvt.u32.u64 	%r13, %rd24;

$L__BB44_3:
	and.b64  	%rd26, %rd24, -4294967296;
	setp.eq.s64 	%p3, %rd26, 0;
	@%p3 bra 	$L__BB44_5;

	div.u64 	%rd49, %rd48, %rd24;
	mul.lo.s64 	%rd27, %rd49, %rd24;
	sub.s64 	%rd50, %rd48, %rd27;
	bra.uni 	$L__BB44_6;

$L__BB44_5:
	cvt.u32.u64 	%r14, %rd48;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd49, %r15;
	cvt.u64.u32 	%rd50, %r17;

$L__BB44_6:
	mul.lo.s64 	%rd13, %rd49, %rd20;
	mul.lo.s64 	%rd14, %rd49, %rd23;
	mov.u32 	%r20, 0;
	mov.u64 	%rd51, 0;

$L__BB44_7:
	add.s64 	%rd29, %rd5, %rd51;
	ld.global.u8 	%rd16, [%rd29];
	setp.eq.s64 	%p4, %rd16, 255;
	@%p4 bra 	$L__BB44_11;

	setp.lt.u64 	%p5, %rd16, %rd23;
	@%p5 bra 	$L__BB44_10;

	mov.u64 	%rd30, $str$3;
	cvta.global.u64 	%rd31, %rd30;
	mov.u64 	%rd32, $str$1;
	cvta.global.u64 	%rd33, %rd32;
	{ // callseq 59, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd31;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b32 param2;
	st.param.b32 	[param2+0], 149;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 59

$L__BB44_10:
	add.s64 	%rd34, %rd14, %rd16;
	mul.lo.s64 	%rd35, %rd34, %rd24;
	add.s64 	%rd36, %rd35, %rd50;
	shl.b64 	%rd37, %rd36, 3;
	add.s64 	%rd38, %rd3, %rd37;
	ld.global.u64 	%rd39, [%rd38];
	add.s64 	%rd40, %rd51, %rd13;
	mul.lo.s64 	%rd41, %rd40, %rd24;
	add.s64 	%rd42, %rd41, %rd50;
	shl.b64 	%rd43, %rd42, 3;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.u64 	%rd45, [%rd44];
	add.s64 	%rd46, %rd39, %rd45;
	st.global.u64 	[%rd38], %rd46;

$L__BB44_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd51, %r20;
	setp.lt.u64 	%p6, %rd51, %rd20;
	@%p6 bra 	$L__BB44_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd48, %r19;
	setp.gt.u64 	%p7, %rd2, %rd48;
	@%p7 bra 	$L__BB44_3;
	bra.uni 	$L__BB44_14;

$L__BB44_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd47, %r19;
	setp.gt.u64 	%p8, %rd2, %rd47;
	@%p8 bra 	$L__BB44_13;

$L__BB44_14:
	ret;

}
	// .globl	sa_i64_f32
.visible .entry sa_i64_f32(
	.param .u64 sa_i64_f32_param_0,
	.param .u64 sa_i64_f32_param_1,
	.param .u64 sa_i64_f32_param_2,
	.param .u64 sa_i64_f32_param_3,
	.param .u64 sa_i64_f32_param_4,
	.param .u64 sa_i64_f32_param_5,
	.param .u64 sa_i64_f32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [sa_i64_f32_param_0];
	ld.param.u64 	%rd21, [sa_i64_f32_param_1];
	ld.param.u64 	%rd22, [sa_i64_f32_param_2];
	ld.param.u64 	%rd26, [sa_i64_f32_param_3];
	ld.param.u64 	%rd23, [sa_i64_f32_param_4];
	ld.param.u64 	%rd24, [sa_i64_f32_param_5];
	ld.param.u64 	%rd25, [sa_i64_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB45_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB45_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB45_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB45_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB45_6;

$L__BB45_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB45_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB45_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB45_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB45_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 60, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 60

$L__BB45_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd40, 2;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.f32 	%f1, [%rd42];
	shl.b64 	%rd43, %rd16, 2;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.f32 	%f2, [%rd44];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd42], %f3;

$L__BB45_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB45_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB45_3;
	bra.uni 	$L__BB45_14;

$L__BB45_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB45_13;

$L__BB45_14:
	ret;

}
	// .globl	sa_i64_f64
.visible .entry sa_i64_f64(
	.param .u64 sa_i64_f64_param_0,
	.param .u64 sa_i64_f64_param_1,
	.param .u64 sa_i64_f64_param_2,
	.param .u64 sa_i64_f64_param_3,
	.param .u64 sa_i64_f64_param_4,
	.param .u64 sa_i64_f64_param_5,
	.param .u64 sa_i64_f64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [sa_i64_f64_param_0];
	ld.param.u64 	%rd21, [sa_i64_f64_param_1];
	ld.param.u64 	%rd22, [sa_i64_f64_param_2];
	ld.param.u64 	%rd26, [sa_i64_f64_param_3];
	ld.param.u64 	%rd23, [sa_i64_f64_param_4];
	ld.param.u64 	%rd24, [sa_i64_f64_param_5];
	ld.param.u64 	%rd25, [sa_i64_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB46_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB46_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB46_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB46_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB46_6;

$L__BB46_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB46_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB46_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB46_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB46_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 61, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 61

$L__BB46_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd40, 3;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.f64 	%fd1, [%rd42];
	add.s64 	%rd44, %rd4, %rd32;
	ld.global.f64 	%fd2, [%rd44];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd42], %fd3;

$L__BB46_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB46_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB46_3;
	bra.uni 	$L__BB46_14;

$L__BB46_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB46_13;

$L__BB46_14:
	ret;

}
	// .globl	sa_i64_u8
.visible .entry sa_i64_u8(
	.param .u64 sa_i64_u8_param_0,
	.param .u64 sa_i64_u8_param_1,
	.param .u64 sa_i64_u8_param_2,
	.param .u64 sa_i64_u8_param_3,
	.param .u64 sa_i64_u8_param_4,
	.param .u64 sa_i64_u8_param_5,
	.param .u64 sa_i64_u8_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd20, [sa_i64_u8_param_0];
	ld.param.u64 	%rd21, [sa_i64_u8_param_1];
	ld.param.u64 	%rd22, [sa_i64_u8_param_2];
	ld.param.u64 	%rd26, [sa_i64_u8_param_3];
	ld.param.u64 	%rd23, [sa_i64_u8_param_4];
	ld.param.u64 	%rd24, [sa_i64_u8_param_5];
	ld.param.u64 	%rd25, [sa_i64_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB47_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB47_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB47_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB47_5;

	div.u64 	%rd45, %rd44, %rd25;
	mul.lo.s64 	%rd28, %rd45, %rd25;
	sub.s64 	%rd46, %rd44, %rd28;
	bra.uni 	$L__BB47_6;

$L__BB47_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB47_6:
	mul.lo.s64 	%rd13, %rd45, %rd23;
	mul.lo.s64 	%rd14, %rd45, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB47_7:
	add.s64 	%rd30, %rd47, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd46;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB47_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB47_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 62, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 62

$L__BB47_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd46;
	add.s64 	%rd41, %rd3, %rd40;
	ld.global.u8 	%rs1, [%rd41];
	add.s64 	%rd42, %rd4, %rd16;
	ld.global.u8 	%rs2, [%rd42];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd41], %rs3;

$L__BB47_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p6, %rd47, %rd23;
	@%p6 bra 	$L__BB47_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p7, %rd2, %rd44;
	@%p7 bra 	$L__BB47_3;
	bra.uni 	$L__BB47_14;

$L__BB47_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p8, %rd2, %rd43;
	@%p8 bra 	$L__BB47_13;

$L__BB47_14:
	ret;

}
	// .globl	sa_i64_i64
.visible .entry sa_i64_i64(
	.param .u64 sa_i64_i64_param_0,
	.param .u64 sa_i64_i64_param_1,
	.param .u64 sa_i64_i64_param_2,
	.param .u64 sa_i64_i64_param_3,
	.param .u64 sa_i64_i64_param_4,
	.param .u64 sa_i64_i64_param_5,
	.param .u64 sa_i64_i64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<53>;


	ld.param.u64 	%rd20, [sa_i64_i64_param_0];
	ld.param.u64 	%rd21, [sa_i64_i64_param_1];
	ld.param.u64 	%rd22, [sa_i64_i64_param_2];
	ld.param.u64 	%rd26, [sa_i64_i64_param_3];
	ld.param.u64 	%rd23, [sa_i64_i64_param_4];
	ld.param.u64 	%rd24, [sa_i64_i64_param_5];
	ld.param.u64 	%rd25, [sa_i64_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd49, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd49;
	@%p1 bra 	$L__BB48_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB48_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB48_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB48_5;

	div.u64 	%rd50, %rd49, %rd25;
	mul.lo.s64 	%rd28, %rd50, %rd25;
	sub.s64 	%rd51, %rd49, %rd28;
	bra.uni 	$L__BB48_6;

$L__BB48_5:
	cvt.u32.u64 	%r14, %rd49;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd50, %r15;
	cvt.u64.u32 	%rd51, %r17;

$L__BB48_6:
	mul.lo.s64 	%rd13, %rd50, %rd23;
	mul.lo.s64 	%rd14, %rd50, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd52, 0;

$L__BB48_7:
	add.s64 	%rd30, %rd52, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd51;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB48_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB48_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 63, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 63

$L__BB48_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd51;
	shl.b64 	%rd41, %rd40, 3;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.u64 	%rd43, [%rd42];
	add.s64 	%rd45, %rd4, %rd32;
	ld.global.u64 	%rd46, [%rd45];
	add.s64 	%rd47, %rd43, %rd46;
	st.global.u64 	[%rd42], %rd47;

$L__BB48_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd52, %r20;
	setp.lt.u64 	%p6, %rd52, %rd23;
	@%p6 bra 	$L__BB48_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd49, %r19;
	setp.gt.u64 	%p7, %rd2, %rd49;
	@%p7 bra 	$L__BB48_3;
	bra.uni 	$L__BB48_14;

$L__BB48_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd48, %r19;
	setp.gt.u64 	%p8, %rd2, %rd48;
	@%p8 bra 	$L__BB48_13;

$L__BB48_14:
	ret;

}
	// .globl	sa_i64_u32
.visible .entry sa_i64_u32(
	.param .u64 sa_i64_u32_param_0,
	.param .u64 sa_i64_u32_param_1,
	.param .u64 sa_i64_u32_param_2,
	.param .u64 sa_i64_u32_param_3,
	.param .u64 sa_i64_u32_param_4,
	.param .u64 sa_i64_u32_param_5,
	.param .u64 sa_i64_u32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [sa_i64_u32_param_0];
	ld.param.u64 	%rd21, [sa_i64_u32_param_1];
	ld.param.u64 	%rd22, [sa_i64_u32_param_2];
	ld.param.u64 	%rd26, [sa_i64_u32_param_3];
	ld.param.u64 	%rd23, [sa_i64_u32_param_4];
	ld.param.u64 	%rd24, [sa_i64_u32_param_5];
	ld.param.u64 	%rd25, [sa_i64_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r22;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB49_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB49_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB49_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB49_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB49_6;

$L__BB49_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB49_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r23, 0;
	mov.u64 	%rd49, 0;

$L__BB49_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB49_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB49_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 64, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 64

$L__BB49_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd40, 2;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.u32 	%r19, [%rd42];
	shl.b64 	%rd43, %rd16, 2;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.u32 	%r20, [%rd44];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd42], %r21;

$L__BB49_11:
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd49, %r23;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB49_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd46, %r22;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB49_3;
	bra.uni 	$L__BB49_14;

$L__BB49_13:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd45, %r22;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB49_13;

$L__BB49_14:
	ret;

}
	// .globl	sa_u32_f32
.visible .entry sa_u32_f32(
	.param .u64 sa_u32_f32_param_0,
	.param .u64 sa_u32_f32_param_1,
	.param .u64 sa_u32_f32_param_2,
	.param .u64 sa_u32_f32_param_3,
	.param .u64 sa_u32_f32_param_4,
	.param .u64 sa_u32_f32_param_5,
	.param .u64 sa_u32_f32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [sa_u32_f32_param_0];
	ld.param.u64 	%rd21, [sa_u32_f32_param_1];
	ld.param.u64 	%rd22, [sa_u32_f32_param_2];
	ld.param.u64 	%rd26, [sa_u32_f32_param_3];
	ld.param.u64 	%rd23, [sa_u32_f32_param_4];
	ld.param.u64 	%rd24, [sa_u32_f32_param_5];
	ld.param.u64 	%rd25, [sa_u32_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB50_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB50_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB50_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB50_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB50_6;

$L__BB50_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB50_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB50_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB50_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB50_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 65, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 65

$L__BB50_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd40, 2;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.f32 	%f1, [%rd42];
	add.s64 	%rd44, %rd4, %rd32;
	ld.global.f32 	%f2, [%rd44];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd42], %f3;

$L__BB50_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB50_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB50_3;
	bra.uni 	$L__BB50_14;

$L__BB50_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB50_13;

$L__BB50_14:
	ret;

}
	// .globl	sa_u32_f64
.visible .entry sa_u32_f64(
	.param .u64 sa_u32_f64_param_0,
	.param .u64 sa_u32_f64_param_1,
	.param .u64 sa_u32_f64_param_2,
	.param .u64 sa_u32_f64_param_3,
	.param .u64 sa_u32_f64_param_4,
	.param .u64 sa_u32_f64_param_5,
	.param .u64 sa_u32_f64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [sa_u32_f64_param_0];
	ld.param.u64 	%rd21, [sa_u32_f64_param_1];
	ld.param.u64 	%rd22, [sa_u32_f64_param_2];
	ld.param.u64 	%rd26, [sa_u32_f64_param_3];
	ld.param.u64 	%rd23, [sa_u32_f64_param_4];
	ld.param.u64 	%rd24, [sa_u32_f64_param_5];
	ld.param.u64 	%rd25, [sa_u32_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB51_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB51_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB51_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB51_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB51_6;

$L__BB51_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB51_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB51_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB51_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB51_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 66, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 66

$L__BB51_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd40, 3;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.f64 	%fd1, [%rd42];
	shl.b64 	%rd43, %rd16, 3;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.f64 	%fd2, [%rd44];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd42], %fd3;

$L__BB51_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB51_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB51_3;
	bra.uni 	$L__BB51_14;

$L__BB51_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB51_13;

$L__BB51_14:
	ret;

}
	// .globl	sa_u32_u8
.visible .entry sa_u32_u8(
	.param .u64 sa_u32_u8_param_0,
	.param .u64 sa_u32_u8_param_1,
	.param .u64 sa_u32_u8_param_2,
	.param .u64 sa_u32_u8_param_3,
	.param .u64 sa_u32_u8_param_4,
	.param .u64 sa_u32_u8_param_5,
	.param .u64 sa_u32_u8_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd20, [sa_u32_u8_param_0];
	ld.param.u64 	%rd21, [sa_u32_u8_param_1];
	ld.param.u64 	%rd22, [sa_u32_u8_param_2];
	ld.param.u64 	%rd26, [sa_u32_u8_param_3];
	ld.param.u64 	%rd23, [sa_u32_u8_param_4];
	ld.param.u64 	%rd24, [sa_u32_u8_param_5];
	ld.param.u64 	%rd25, [sa_u32_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB52_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB52_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB52_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB52_5;

	div.u64 	%rd45, %rd44, %rd25;
	mul.lo.s64 	%rd28, %rd45, %rd25;
	sub.s64 	%rd46, %rd44, %rd28;
	bra.uni 	$L__BB52_6;

$L__BB52_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB52_6:
	mul.lo.s64 	%rd13, %rd45, %rd23;
	mul.lo.s64 	%rd14, %rd45, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB52_7:
	add.s64 	%rd30, %rd47, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd46;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB52_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB52_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 67, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 67

$L__BB52_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd46;
	add.s64 	%rd41, %rd3, %rd40;
	ld.global.u8 	%rs1, [%rd41];
	add.s64 	%rd42, %rd4, %rd16;
	ld.global.u8 	%rs2, [%rd42];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd41], %rs3;

$L__BB52_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p6, %rd47, %rd23;
	@%p6 bra 	$L__BB52_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p7, %rd2, %rd44;
	@%p7 bra 	$L__BB52_3;
	bra.uni 	$L__BB52_14;

$L__BB52_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p8, %rd2, %rd43;
	@%p8 bra 	$L__BB52_13;

$L__BB52_14:
	ret;

}
	// .globl	sa_u32_i64
.visible .entry sa_u32_i64(
	.param .u64 sa_u32_i64_param_0,
	.param .u64 sa_u32_i64_param_1,
	.param .u64 sa_u32_i64_param_2,
	.param .u64 sa_u32_i64_param_3,
	.param .u64 sa_u32_i64_param_4,
	.param .u64 sa_u32_i64_param_5,
	.param .u64 sa_u32_i64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<53>;


	ld.param.u64 	%rd20, [sa_u32_i64_param_0];
	ld.param.u64 	%rd21, [sa_u32_i64_param_1];
	ld.param.u64 	%rd22, [sa_u32_i64_param_2];
	ld.param.u64 	%rd26, [sa_u32_i64_param_3];
	ld.param.u64 	%rd23, [sa_u32_i64_param_4];
	ld.param.u64 	%rd24, [sa_u32_i64_param_5];
	ld.param.u64 	%rd25, [sa_u32_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd49, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd49;
	@%p1 bra 	$L__BB53_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB53_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB53_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB53_5;

	div.u64 	%rd50, %rd49, %rd25;
	mul.lo.s64 	%rd28, %rd50, %rd25;
	sub.s64 	%rd51, %rd49, %rd28;
	bra.uni 	$L__BB53_6;

$L__BB53_5:
	cvt.u32.u64 	%r14, %rd49;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd50, %r15;
	cvt.u64.u32 	%rd51, %r17;

$L__BB53_6:
	mul.lo.s64 	%rd13, %rd50, %rd23;
	mul.lo.s64 	%rd14, %rd50, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd52, 0;

$L__BB53_7:
	add.s64 	%rd30, %rd52, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd51;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB53_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB53_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 68, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 68

$L__BB53_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd51;
	shl.b64 	%rd41, %rd40, 3;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.u64 	%rd43, [%rd42];
	shl.b64 	%rd44, %rd16, 3;
	add.s64 	%rd45, %rd4, %rd44;
	ld.global.u64 	%rd46, [%rd45];
	add.s64 	%rd47, %rd43, %rd46;
	st.global.u64 	[%rd42], %rd47;

$L__BB53_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd52, %r20;
	setp.lt.u64 	%p6, %rd52, %rd23;
	@%p6 bra 	$L__BB53_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd49, %r19;
	setp.gt.u64 	%p7, %rd2, %rd49;
	@%p7 bra 	$L__BB53_3;
	bra.uni 	$L__BB53_14;

$L__BB53_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd48, %r19;
	setp.gt.u64 	%p8, %rd2, %rd48;
	@%p8 bra 	$L__BB53_13;

$L__BB53_14:
	ret;

}
	// .globl	sa_u32_u32
.visible .entry sa_u32_u32(
	.param .u64 sa_u32_u32_param_0,
	.param .u64 sa_u32_u32_param_1,
	.param .u64 sa_u32_u32_param_2,
	.param .u64 sa_u32_u32_param_3,
	.param .u64 sa_u32_u32_param_4,
	.param .u64 sa_u32_u32_param_5,
	.param .u64 sa_u32_u32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [sa_u32_u32_param_0];
	ld.param.u64 	%rd21, [sa_u32_u32_param_1];
	ld.param.u64 	%rd22, [sa_u32_u32_param_2];
	ld.param.u64 	%rd26, [sa_u32_u32_param_3];
	ld.param.u64 	%rd23, [sa_u32_u32_param_4];
	ld.param.u64 	%rd24, [sa_u32_u32_param_5];
	ld.param.u64 	%rd25, [sa_u32_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r22;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB54_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB54_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB54_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB54_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB54_6;

$L__BB54_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB54_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r23, 0;
	mov.u64 	%rd49, 0;

$L__BB54_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB54_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB54_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 69, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 69

$L__BB54_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd40, 2;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.u32 	%r19, [%rd42];
	add.s64 	%rd44, %rd4, %rd32;
	ld.global.u32 	%r20, [%rd44];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd42], %r21;

$L__BB54_11:
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd49, %r23;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB54_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd46, %r22;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB54_3;
	bra.uni 	$L__BB54_14;

$L__BB54_13:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd45, %r22;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB54_13;

$L__BB54_14:
	ret;

}
	// .globl	sa_u8_f32
.visible .entry sa_u8_f32(
	.param .u64 sa_u8_f32_param_0,
	.param .u64 sa_u8_f32_param_1,
	.param .u64 sa_u8_f32_param_2,
	.param .u64 sa_u8_f32_param_3,
	.param .u64 sa_u8_f32_param_4,
	.param .u64 sa_u8_f32_param_5,
	.param .u64 sa_u8_f32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd20, [sa_u8_f32_param_0];
	ld.param.u64 	%rd21, [sa_u8_f32_param_1];
	ld.param.u64 	%rd22, [sa_u8_f32_param_2];
	ld.param.u64 	%rd26, [sa_u8_f32_param_3];
	ld.param.u64 	%rd23, [sa_u8_f32_param_4];
	ld.param.u64 	%rd24, [sa_u8_f32_param_5];
	ld.param.u64 	%rd25, [sa_u8_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB55_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB55_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB55_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB55_5;

	div.u64 	%rd46, %rd45, %rd25;
	mul.lo.s64 	%rd28, %rd46, %rd25;
	sub.s64 	%rd47, %rd45, %rd28;
	bra.uni 	$L__BB55_6;

$L__BB55_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB55_6:
	mul.lo.s64 	%rd13, %rd46, %rd23;
	mul.lo.s64 	%rd14, %rd46, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB55_7:
	add.s64 	%rd30, %rd48, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd47;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB55_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB55_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 70, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 70

$L__BB55_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd47;
	shl.b64 	%rd40, %rd39, 2;
	add.s64 	%rd41, %rd3, %rd40;
	ld.global.f32 	%f1, [%rd41];
	shl.b64 	%rd42, %rd16, 2;
	add.s64 	%rd43, %rd4, %rd42;
	ld.global.f32 	%f2, [%rd43];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd41], %f3;

$L__BB55_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p6, %rd48, %rd23;
	@%p6 bra 	$L__BB55_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB55_3;
	bra.uni 	$L__BB55_14;

$L__BB55_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB55_13;

$L__BB55_14:
	ret;

}
	// .globl	sa_u8_f64
.visible .entry sa_u8_f64(
	.param .u64 sa_u8_f64_param_0,
	.param .u64 sa_u8_f64_param_1,
	.param .u64 sa_u8_f64_param_2,
	.param .u64 sa_u8_f64_param_3,
	.param .u64 sa_u8_f64_param_4,
	.param .u64 sa_u8_f64_param_5,
	.param .u64 sa_u8_f64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd20, [sa_u8_f64_param_0];
	ld.param.u64 	%rd21, [sa_u8_f64_param_1];
	ld.param.u64 	%rd22, [sa_u8_f64_param_2];
	ld.param.u64 	%rd26, [sa_u8_f64_param_3];
	ld.param.u64 	%rd23, [sa_u8_f64_param_4];
	ld.param.u64 	%rd24, [sa_u8_f64_param_5];
	ld.param.u64 	%rd25, [sa_u8_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB56_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB56_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB56_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB56_5;

	div.u64 	%rd46, %rd45, %rd25;
	mul.lo.s64 	%rd28, %rd46, %rd25;
	sub.s64 	%rd47, %rd45, %rd28;
	bra.uni 	$L__BB56_6;

$L__BB56_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB56_6:
	mul.lo.s64 	%rd13, %rd46, %rd23;
	mul.lo.s64 	%rd14, %rd46, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB56_7:
	add.s64 	%rd30, %rd48, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd47;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB56_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB56_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 71, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 71

$L__BB56_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd47;
	shl.b64 	%rd40, %rd39, 3;
	add.s64 	%rd41, %rd3, %rd40;
	ld.global.f64 	%fd1, [%rd41];
	shl.b64 	%rd42, %rd16, 3;
	add.s64 	%rd43, %rd4, %rd42;
	ld.global.f64 	%fd2, [%rd43];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd41], %fd3;

$L__BB56_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p6, %rd48, %rd23;
	@%p6 bra 	$L__BB56_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB56_3;
	bra.uni 	$L__BB56_14;

$L__BB56_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB56_13;

$L__BB56_14:
	ret;

}
	// .globl	sa_u8_u8
.visible .entry sa_u8_u8(
	.param .u64 sa_u8_u8_param_0,
	.param .u64 sa_u8_u8_param_1,
	.param .u64 sa_u8_u8_param_2,
	.param .u64 sa_u8_u8_param_3,
	.param .u64 sa_u8_u8_param_4,
	.param .u64 sa_u8_u8_param_5,
	.param .u64 sa_u8_u8_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<47>;


	ld.param.u64 	%rd20, [sa_u8_u8_param_0];
	ld.param.u64 	%rd21, [sa_u8_u8_param_1];
	ld.param.u64 	%rd22, [sa_u8_u8_param_2];
	ld.param.u64 	%rd26, [sa_u8_u8_param_3];
	ld.param.u64 	%rd23, [sa_u8_u8_param_4];
	ld.param.u64 	%rd24, [sa_u8_u8_param_5];
	ld.param.u64 	%rd25, [sa_u8_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd43, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd43;
	@%p1 bra 	$L__BB57_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB57_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB57_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB57_5;

	div.u64 	%rd44, %rd43, %rd25;
	mul.lo.s64 	%rd28, %rd44, %rd25;
	sub.s64 	%rd45, %rd43, %rd28;
	bra.uni 	$L__BB57_6;

$L__BB57_5:
	cvt.u32.u64 	%r14, %rd43;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd44, %r15;
	cvt.u64.u32 	%rd45, %r17;

$L__BB57_6:
	mul.lo.s64 	%rd13, %rd44, %rd23;
	mul.lo.s64 	%rd14, %rd44, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd46, 0;

$L__BB57_7:
	add.s64 	%rd30, %rd46, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd45;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB57_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB57_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 72, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 72

$L__BB57_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd45;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u8 	%rs1, [%rd40];
	add.s64 	%rd41, %rd4, %rd16;
	ld.global.u8 	%rs2, [%rd41];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd40], %rs3;

$L__BB57_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd46, %r20;
	setp.lt.u64 	%p6, %rd46, %rd23;
	@%p6 bra 	$L__BB57_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p7, %rd2, %rd43;
	@%p7 bra 	$L__BB57_3;
	bra.uni 	$L__BB57_14;

$L__BB57_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p8, %rd2, %rd42;
	@%p8 bra 	$L__BB57_13;

$L__BB57_14:
	ret;

}
	// .globl	sa_u8_u32
.visible .entry sa_u8_u32(
	.param .u64 sa_u8_u32_param_0,
	.param .u64 sa_u8_u32_param_1,
	.param .u64 sa_u8_u32_param_2,
	.param .u64 sa_u8_u32_param_3,
	.param .u64 sa_u8_u32_param_4,
	.param .u64 sa_u8_u32_param_5,
	.param .u64 sa_u8_u32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd20, [sa_u8_u32_param_0];
	ld.param.u64 	%rd21, [sa_u8_u32_param_1];
	ld.param.u64 	%rd22, [sa_u8_u32_param_2];
	ld.param.u64 	%rd26, [sa_u8_u32_param_3];
	ld.param.u64 	%rd23, [sa_u8_u32_param_4];
	ld.param.u64 	%rd24, [sa_u8_u32_param_5];
	ld.param.u64 	%rd25, [sa_u8_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r22;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB58_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB58_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB58_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB58_5;

	div.u64 	%rd46, %rd45, %rd25;
	mul.lo.s64 	%rd28, %rd46, %rd25;
	sub.s64 	%rd47, %rd45, %rd28;
	bra.uni 	$L__BB58_6;

$L__BB58_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB58_6:
	mul.lo.s64 	%rd13, %rd46, %rd23;
	mul.lo.s64 	%rd14, %rd46, %rd24;
	mov.u32 	%r23, 0;
	mov.u64 	%rd48, 0;

$L__BB58_7:
	add.s64 	%rd30, %rd48, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd47;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB58_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB58_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 73, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 73

$L__BB58_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd47;
	shl.b64 	%rd40, %rd39, 2;
	add.s64 	%rd41, %rd3, %rd40;
	ld.global.u32 	%r19, [%rd41];
	shl.b64 	%rd42, %rd16, 2;
	add.s64 	%rd43, %rd4, %rd42;
	ld.global.u32 	%r20, [%rd43];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd41], %r21;

$L__BB58_11:
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd48, %r23;
	setp.lt.u64 	%p6, %rd48, %rd23;
	@%p6 bra 	$L__BB58_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd45, %r22;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB58_3;
	bra.uni 	$L__BB58_14;

$L__BB58_13:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd44, %r22;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB58_13;

$L__BB58_14:
	ret;

}
	// .globl	sa_u8_i64
.visible .entry sa_u8_i64(
	.param .u64 sa_u8_i64_param_0,
	.param .u64 sa_u8_i64_param_1,
	.param .u64 sa_u8_i64_param_2,
	.param .u64 sa_u8_i64_param_3,
	.param .u64 sa_u8_i64_param_4,
	.param .u64 sa_u8_i64_param_5,
	.param .u64 sa_u8_i64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<52>;


	ld.param.u64 	%rd20, [sa_u8_i64_param_0];
	ld.param.u64 	%rd21, [sa_u8_i64_param_1];
	ld.param.u64 	%rd22, [sa_u8_i64_param_2];
	ld.param.u64 	%rd26, [sa_u8_i64_param_3];
	ld.param.u64 	%rd23, [sa_u8_i64_param_4];
	ld.param.u64 	%rd24, [sa_u8_i64_param_5];
	ld.param.u64 	%rd25, [sa_u8_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd48, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd48;
	@%p1 bra 	$L__BB59_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB59_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB59_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB59_5;

	div.u64 	%rd49, %rd48, %rd25;
	mul.lo.s64 	%rd28, %rd49, %rd25;
	sub.s64 	%rd50, %rd48, %rd28;
	bra.uni 	$L__BB59_6;

$L__BB59_5:
	cvt.u32.u64 	%r14, %rd48;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd49, %r15;
	cvt.u64.u32 	%rd50, %r17;

$L__BB59_6:
	mul.lo.s64 	%rd13, %rd49, %rd23;
	mul.lo.s64 	%rd14, %rd49, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd51, 0;

$L__BB59_7:
	add.s64 	%rd30, %rd51, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd50;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB59_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB59_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 74, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 284;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 74

$L__BB59_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd50;
	shl.b64 	%rd40, %rd39, 3;
	add.s64 	%rd41, %rd3, %rd40;
	ld.global.u64 	%rd42, [%rd41];
	shl.b64 	%rd43, %rd16, 3;
	add.s64 	%rd44, %rd4, %rd43;
	ld.global.u64 	%rd45, [%rd44];
	add.s64 	%rd46, %rd42, %rd45;
	st.global.u64 	[%rd41], %rd46;

$L__BB59_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd51, %r20;
	setp.lt.u64 	%p6, %rd51, %rd23;
	@%p6 bra 	$L__BB59_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd48, %r19;
	setp.gt.u64 	%p7, %rd2, %rd48;
	@%p7 bra 	$L__BB59_3;
	bra.uni 	$L__BB59_14;

$L__BB59_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd47, %r19;
	setp.gt.u64 	%p8, %rd2, %rd47;
	@%p8 bra 	$L__BB59_13;

$L__BB59_14:
	ret;

}
	// .globl	s_i64_f32
.visible .entry s_i64_f32(
	.param .u64 s_i64_f32_param_0,
	.param .u64 s_i64_f32_param_1,
	.param .u64 s_i64_f32_param_2,
	.param .u64 s_i64_f32_param_3,
	.param .u64 s_i64_f32_param_4,
	.param .u64 s_i64_f32_param_5,
	.param .u64 s_i64_f32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [s_i64_f32_param_0];
	ld.param.u64 	%rd21, [s_i64_f32_param_1];
	ld.param.u64 	%rd22, [s_i64_f32_param_2];
	ld.param.u64 	%rd26, [s_i64_f32_param_3];
	ld.param.u64 	%rd23, [s_i64_f32_param_4];
	ld.param.u64 	%rd24, [s_i64_f32_param_5];
	ld.param.u64 	%rd25, [s_i64_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB60_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB60_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB60_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB60_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB60_6;

$L__BB60_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB60_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB60_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB60_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB60_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 75, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 75

$L__BB60_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd16, 2;
	add.s64 	%rd42, %rd4, %rd41;
	ld.global.f32 	%f1, [%rd42];
	shl.b64 	%rd43, %rd40, 2;
	add.s64 	%rd44, %rd3, %rd43;
	st.global.f32 	[%rd44], %f1;

$L__BB60_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB60_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB60_3;
	bra.uni 	$L__BB60_14;

$L__BB60_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB60_13;

$L__BB60_14:
	ret;

}
	// .globl	s_i64_f64
.visible .entry s_i64_f64(
	.param .u64 s_i64_f64_param_0,
	.param .u64 s_i64_f64_param_1,
	.param .u64 s_i64_f64_param_2,
	.param .u64 s_i64_f64_param_3,
	.param .u64 s_i64_f64_param_4,
	.param .u64 s_i64_f64_param_5,
	.param .u64 s_i64_f64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [s_i64_f64_param_0];
	ld.param.u64 	%rd21, [s_i64_f64_param_1];
	ld.param.u64 	%rd22, [s_i64_f64_param_2];
	ld.param.u64 	%rd26, [s_i64_f64_param_3];
	ld.param.u64 	%rd23, [s_i64_f64_param_4];
	ld.param.u64 	%rd24, [s_i64_f64_param_5];
	ld.param.u64 	%rd25, [s_i64_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB61_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB61_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB61_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB61_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB61_6;

$L__BB61_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB61_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB61_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB61_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB61_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 76, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 76

$L__BB61_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	add.s64 	%rd42, %rd4, %rd32;
	ld.global.f64 	%fd1, [%rd42];
	shl.b64 	%rd43, %rd40, 3;
	add.s64 	%rd44, %rd3, %rd43;
	st.global.f64 	[%rd44], %fd1;

$L__BB61_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB61_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB61_3;
	bra.uni 	$L__BB61_14;

$L__BB61_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB61_13;

$L__BB61_14:
	ret;

}
	// .globl	s_i64_u8
.visible .entry s_i64_u8(
	.param .u64 s_i64_u8_param_0,
	.param .u64 s_i64_u8_param_1,
	.param .u64 s_i64_u8_param_2,
	.param .u64 s_i64_u8_param_3,
	.param .u64 s_i64_u8_param_4,
	.param .u64 s_i64_u8_param_5,
	.param .u64 s_i64_u8_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd20, [s_i64_u8_param_0];
	ld.param.u64 	%rd21, [s_i64_u8_param_1];
	ld.param.u64 	%rd22, [s_i64_u8_param_2];
	ld.param.u64 	%rd26, [s_i64_u8_param_3];
	ld.param.u64 	%rd23, [s_i64_u8_param_4];
	ld.param.u64 	%rd24, [s_i64_u8_param_5];
	ld.param.u64 	%rd25, [s_i64_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB62_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB62_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB62_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB62_5;

	div.u64 	%rd45, %rd44, %rd25;
	mul.lo.s64 	%rd28, %rd45, %rd25;
	sub.s64 	%rd46, %rd44, %rd28;
	bra.uni 	$L__BB62_6;

$L__BB62_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB62_6:
	mul.lo.s64 	%rd13, %rd45, %rd23;
	mul.lo.s64 	%rd14, %rd45, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB62_7:
	add.s64 	%rd30, %rd47, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd46;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB62_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB62_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 77, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 77

$L__BB62_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd46;
	add.s64 	%rd41, %rd4, %rd16;
	ld.global.u8 	%rs1, [%rd41];
	add.s64 	%rd42, %rd3, %rd40;
	st.global.u8 	[%rd42], %rs1;

$L__BB62_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p6, %rd47, %rd23;
	@%p6 bra 	$L__BB62_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p7, %rd2, %rd44;
	@%p7 bra 	$L__BB62_3;
	bra.uni 	$L__BB62_14;

$L__BB62_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p8, %rd2, %rd43;
	@%p8 bra 	$L__BB62_13;

$L__BB62_14:
	ret;

}
	// .globl	s_i64_i64
.visible .entry s_i64_i64(
	.param .u64 s_i64_i64_param_0,
	.param .u64 s_i64_i64_param_1,
	.param .u64 s_i64_i64_param_2,
	.param .u64 s_i64_i64_param_3,
	.param .u64 s_i64_i64_param_4,
	.param .u64 s_i64_i64_param_5,
	.param .u64 s_i64_i64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<51>;


	ld.param.u64 	%rd20, [s_i64_i64_param_0];
	ld.param.u64 	%rd21, [s_i64_i64_param_1];
	ld.param.u64 	%rd22, [s_i64_i64_param_2];
	ld.param.u64 	%rd26, [s_i64_i64_param_3];
	ld.param.u64 	%rd23, [s_i64_i64_param_4];
	ld.param.u64 	%rd24, [s_i64_i64_param_5];
	ld.param.u64 	%rd25, [s_i64_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd47, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd47;
	@%p1 bra 	$L__BB63_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB63_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB63_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB63_5;

	div.u64 	%rd48, %rd47, %rd25;
	mul.lo.s64 	%rd28, %rd48, %rd25;
	sub.s64 	%rd49, %rd47, %rd28;
	bra.uni 	$L__BB63_6;

$L__BB63_5:
	cvt.u32.u64 	%r14, %rd47;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd48, %r15;
	cvt.u64.u32 	%rd49, %r17;

$L__BB63_6:
	mul.lo.s64 	%rd13, %rd48, %rd23;
	mul.lo.s64 	%rd14, %rd48, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd50, 0;

$L__BB63_7:
	add.s64 	%rd30, %rd50, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd49;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB63_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB63_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 78, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 78

$L__BB63_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd49;
	add.s64 	%rd42, %rd4, %rd32;
	ld.global.u64 	%rd43, [%rd42];
	shl.b64 	%rd44, %rd40, 3;
	add.s64 	%rd45, %rd3, %rd44;
	st.global.u64 	[%rd45], %rd43;

$L__BB63_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd50, %r20;
	setp.lt.u64 	%p6, %rd50, %rd23;
	@%p6 bra 	$L__BB63_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd47, %r19;
	setp.gt.u64 	%p7, %rd2, %rd47;
	@%p7 bra 	$L__BB63_3;
	bra.uni 	$L__BB63_14;

$L__BB63_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p8, %rd2, %rd46;
	@%p8 bra 	$L__BB63_13;

$L__BB63_14:
	ret;

}
	// .globl	s_i64_u32
.visible .entry s_i64_u32(
	.param .u64 s_i64_u32_param_0,
	.param .u64 s_i64_u32_param_1,
	.param .u64 s_i64_u32_param_2,
	.param .u64 s_i64_u32_param_3,
	.param .u64 s_i64_u32_param_4,
	.param .u64 s_i64_u32_param_5,
	.param .u64 s_i64_u32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [s_i64_u32_param_0];
	ld.param.u64 	%rd21, [s_i64_u32_param_1];
	ld.param.u64 	%rd22, [s_i64_u32_param_2];
	ld.param.u64 	%rd26, [s_i64_u32_param_3];
	ld.param.u64 	%rd23, [s_i64_u32_param_4];
	ld.param.u64 	%rd24, [s_i64_u32_param_5];
	ld.param.u64 	%rd25, [s_i64_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r20, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r20;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB64_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB64_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB64_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB64_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB64_6;

$L__BB64_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB64_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r21, 0;
	mov.u64 	%rd49, 0;

$L__BB64_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 3;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u64 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 9223372036854775807;
	@%p4 bra 	$L__BB64_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB64_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 79, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 79

$L__BB64_10:
	add.s64 	%rd38, %rd17, %rd14;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd16, 2;
	add.s64 	%rd42, %rd4, %rd41;
	ld.global.u32 	%r19, [%rd42];
	shl.b64 	%rd43, %rd40, 2;
	add.s64 	%rd44, %rd3, %rd43;
	st.global.u32 	[%rd44], %r19;

$L__BB64_11:
	add.s32 	%r21, %r21, 1;
	cvt.u64.u32 	%rd49, %r21;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB64_7;

	add.s32 	%r20, %r20, %r3;
	cvt.u64.u32 	%rd46, %r20;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB64_3;
	bra.uni 	$L__BB64_14;

$L__BB64_13:
	add.s32 	%r20, %r20, %r3;
	cvt.u64.u32 	%rd45, %r20;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB64_13;

$L__BB64_14:
	ret;

}
	// .globl	s_u32_f32
.visible .entry s_u32_f32(
	.param .u64 s_u32_f32_param_0,
	.param .u64 s_u32_f32_param_1,
	.param .u64 s_u32_f32_param_2,
	.param .u64 s_u32_f32_param_3,
	.param .u64 s_u32_f32_param_4,
	.param .u64 s_u32_f32_param_5,
	.param .u64 s_u32_f32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [s_u32_f32_param_0];
	ld.param.u64 	%rd21, [s_u32_f32_param_1];
	ld.param.u64 	%rd22, [s_u32_f32_param_2];
	ld.param.u64 	%rd26, [s_u32_f32_param_3];
	ld.param.u64 	%rd23, [s_u32_f32_param_4];
	ld.param.u64 	%rd24, [s_u32_f32_param_5];
	ld.param.u64 	%rd25, [s_u32_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB65_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB65_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB65_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB65_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB65_6;

$L__BB65_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB65_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB65_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB65_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB65_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 80, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 80

$L__BB65_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	add.s64 	%rd42, %rd4, %rd32;
	ld.global.f32 	%f1, [%rd42];
	shl.b64 	%rd43, %rd40, 2;
	add.s64 	%rd44, %rd3, %rd43;
	st.global.f32 	[%rd44], %f1;

$L__BB65_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB65_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB65_3;
	bra.uni 	$L__BB65_14;

$L__BB65_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB65_13;

$L__BB65_14:
	ret;

}
	// .globl	s_u32_f64
.visible .entry s_u32_f64(
	.param .u64 s_u32_f64_param_0,
	.param .u64 s_u32_f64_param_1,
	.param .u64 s_u32_f64_param_2,
	.param .u64 s_u32_f64_param_3,
	.param .u64 s_u32_f64_param_4,
	.param .u64 s_u32_f64_param_5,
	.param .u64 s_u32_f64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [s_u32_f64_param_0];
	ld.param.u64 	%rd21, [s_u32_f64_param_1];
	ld.param.u64 	%rd22, [s_u32_f64_param_2];
	ld.param.u64 	%rd26, [s_u32_f64_param_3];
	ld.param.u64 	%rd23, [s_u32_f64_param_4];
	ld.param.u64 	%rd24, [s_u32_f64_param_5];
	ld.param.u64 	%rd25, [s_u32_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB66_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB66_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB66_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB66_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB66_6;

$L__BB66_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB66_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB66_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB66_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB66_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 81, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 81

$L__BB66_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	shl.b64 	%rd41, %rd16, 3;
	add.s64 	%rd42, %rd4, %rd41;
	ld.global.f64 	%fd1, [%rd42];
	shl.b64 	%rd43, %rd40, 3;
	add.s64 	%rd44, %rd3, %rd43;
	st.global.f64 	[%rd44], %fd1;

$L__BB66_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB66_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB66_3;
	bra.uni 	$L__BB66_14;

$L__BB66_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB66_13;

$L__BB66_14:
	ret;

}
	// .globl	s_u32_u8
.visible .entry s_u32_u8(
	.param .u64 s_u32_u8_param_0,
	.param .u64 s_u32_u8_param_1,
	.param .u64 s_u32_u8_param_2,
	.param .u64 s_u32_u8_param_3,
	.param .u64 s_u32_u8_param_4,
	.param .u64 s_u32_u8_param_5,
	.param .u64 s_u32_u8_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd20, [s_u32_u8_param_0];
	ld.param.u64 	%rd21, [s_u32_u8_param_1];
	ld.param.u64 	%rd22, [s_u32_u8_param_2];
	ld.param.u64 	%rd26, [s_u32_u8_param_3];
	ld.param.u64 	%rd23, [s_u32_u8_param_4];
	ld.param.u64 	%rd24, [s_u32_u8_param_5];
	ld.param.u64 	%rd25, [s_u32_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB67_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB67_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB67_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB67_5;

	div.u64 	%rd45, %rd44, %rd25;
	mul.lo.s64 	%rd28, %rd45, %rd25;
	sub.s64 	%rd46, %rd44, %rd28;
	bra.uni 	$L__BB67_6;

$L__BB67_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB67_6:
	mul.lo.s64 	%rd13, %rd45, %rd23;
	mul.lo.s64 	%rd14, %rd45, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB67_7:
	add.s64 	%rd30, %rd47, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd46;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB67_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB67_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 82, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 82

$L__BB67_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd46;
	add.s64 	%rd41, %rd4, %rd16;
	ld.global.u8 	%rs1, [%rd41];
	add.s64 	%rd42, %rd3, %rd40;
	st.global.u8 	[%rd42], %rs1;

$L__BB67_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p6, %rd47, %rd23;
	@%p6 bra 	$L__BB67_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p7, %rd2, %rd44;
	@%p7 bra 	$L__BB67_3;
	bra.uni 	$L__BB67_14;

$L__BB67_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p8, %rd2, %rd43;
	@%p8 bra 	$L__BB67_13;

$L__BB67_14:
	ret;

}
	// .globl	s_u32_i64
.visible .entry s_u32_i64(
	.param .u64 s_u32_i64_param_0,
	.param .u64 s_u32_i64_param_1,
	.param .u64 s_u32_i64_param_2,
	.param .u64 s_u32_i64_param_3,
	.param .u64 s_u32_i64_param_4,
	.param .u64 s_u32_i64_param_5,
	.param .u64 s_u32_i64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<51>;


	ld.param.u64 	%rd20, [s_u32_i64_param_0];
	ld.param.u64 	%rd21, [s_u32_i64_param_1];
	ld.param.u64 	%rd22, [s_u32_i64_param_2];
	ld.param.u64 	%rd26, [s_u32_i64_param_3];
	ld.param.u64 	%rd23, [s_u32_i64_param_4];
	ld.param.u64 	%rd24, [s_u32_i64_param_5];
	ld.param.u64 	%rd25, [s_u32_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd47, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd47;
	@%p1 bra 	$L__BB68_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB68_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB68_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB68_5;

	div.u64 	%rd48, %rd47, %rd25;
	mul.lo.s64 	%rd28, %rd48, %rd25;
	sub.s64 	%rd49, %rd47, %rd28;
	bra.uni 	$L__BB68_6;

$L__BB68_5:
	cvt.u32.u64 	%r14, %rd47;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd48, %r15;
	cvt.u64.u32 	%rd49, %r17;

$L__BB68_6:
	mul.lo.s64 	%rd13, %rd48, %rd23;
	mul.lo.s64 	%rd14, %rd48, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd50, 0;

$L__BB68_7:
	add.s64 	%rd30, %rd50, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd49;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB68_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB68_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 83, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 83

$L__BB68_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd49;
	shl.b64 	%rd41, %rd16, 3;
	add.s64 	%rd42, %rd4, %rd41;
	ld.global.u64 	%rd43, [%rd42];
	shl.b64 	%rd44, %rd40, 3;
	add.s64 	%rd45, %rd3, %rd44;
	st.global.u64 	[%rd45], %rd43;

$L__BB68_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd50, %r20;
	setp.lt.u64 	%p6, %rd50, %rd23;
	@%p6 bra 	$L__BB68_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd47, %r19;
	setp.gt.u64 	%p7, %rd2, %rd47;
	@%p7 bra 	$L__BB68_3;
	bra.uni 	$L__BB68_14;

$L__BB68_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p8, %rd2, %rd46;
	@%p8 bra 	$L__BB68_13;

$L__BB68_14:
	ret;

}
	// .globl	s_u32_u32
.visible .entry s_u32_u32(
	.param .u64 s_u32_u32_param_0,
	.param .u64 s_u32_u32_param_1,
	.param .u64 s_u32_u32_param_2,
	.param .u64 s_u32_u32_param_3,
	.param .u64 s_u32_u32_param_4,
	.param .u64 s_u32_u32_param_5,
	.param .u64 s_u32_u32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [s_u32_u32_param_0];
	ld.param.u64 	%rd21, [s_u32_u32_param_1];
	ld.param.u64 	%rd22, [s_u32_u32_param_2];
	ld.param.u64 	%rd26, [s_u32_u32_param_3];
	ld.param.u64 	%rd23, [s_u32_u32_param_4];
	ld.param.u64 	%rd24, [s_u32_u32_param_5];
	ld.param.u64 	%rd25, [s_u32_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r20, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r20;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB69_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB69_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB69_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB69_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB69_6;

$L__BB69_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB69_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r21, 0;
	mov.u64 	%rd49, 0;

$L__BB69_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	shl.b64 	%rd32, %rd16, 2;
	add.s64 	%rd33, %rd5, %rd32;
	ld.global.u32 	%rd17, [%rd33];
	setp.eq.s64 	%p4, %rd17, 4294967295;
	@%p4 bra 	$L__BB69_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB69_10;

	mov.u64 	%rd34, $str$3;
	cvta.global.u64 	%rd35, %rd34;
	mov.u64 	%rd36, $str$1;
	cvta.global.u64 	%rd37, %rd36;
	{ // callseq 84, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd35;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 84

$L__BB69_10:
	add.s64 	%rd38, %rd14, %rd17;
	mul.lo.s64 	%rd39, %rd38, %rd25;
	add.s64 	%rd40, %rd39, %rd48;
	add.s64 	%rd42, %rd4, %rd32;
	ld.global.u32 	%r19, [%rd42];
	shl.b64 	%rd43, %rd40, 2;
	add.s64 	%rd44, %rd3, %rd43;
	st.global.u32 	[%rd44], %r19;

$L__BB69_11:
	add.s32 	%r21, %r21, 1;
	cvt.u64.u32 	%rd49, %r21;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB69_7;

	add.s32 	%r20, %r20, %r3;
	cvt.u64.u32 	%rd46, %r20;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB69_3;
	bra.uni 	$L__BB69_14;

$L__BB69_13:
	add.s32 	%r20, %r20, %r3;
	cvt.u64.u32 	%rd45, %r20;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB69_13;

$L__BB69_14:
	ret;

}
	// .globl	s_u8_f32
.visible .entry s_u8_f32(
	.param .u64 s_u8_f32_param_0,
	.param .u64 s_u8_f32_param_1,
	.param .u64 s_u8_f32_param_2,
	.param .u64 s_u8_f32_param_3,
	.param .u64 s_u8_f32_param_4,
	.param .u64 s_u8_f32_param_5,
	.param .u64 s_u8_f32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd20, [s_u8_f32_param_0];
	ld.param.u64 	%rd21, [s_u8_f32_param_1];
	ld.param.u64 	%rd22, [s_u8_f32_param_2];
	ld.param.u64 	%rd26, [s_u8_f32_param_3];
	ld.param.u64 	%rd23, [s_u8_f32_param_4];
	ld.param.u64 	%rd24, [s_u8_f32_param_5];
	ld.param.u64 	%rd25, [s_u8_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB70_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB70_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB70_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB70_5;

	div.u64 	%rd46, %rd45, %rd25;
	mul.lo.s64 	%rd28, %rd46, %rd25;
	sub.s64 	%rd47, %rd45, %rd28;
	bra.uni 	$L__BB70_6;

$L__BB70_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB70_6:
	mul.lo.s64 	%rd13, %rd46, %rd23;
	mul.lo.s64 	%rd14, %rd46, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB70_7:
	add.s64 	%rd30, %rd48, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd47;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB70_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB70_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 85, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 85

$L__BB70_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd47;
	shl.b64 	%rd40, %rd16, 2;
	add.s64 	%rd41, %rd4, %rd40;
	ld.global.f32 	%f1, [%rd41];
	shl.b64 	%rd42, %rd39, 2;
	add.s64 	%rd43, %rd3, %rd42;
	st.global.f32 	[%rd43], %f1;

$L__BB70_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p6, %rd48, %rd23;
	@%p6 bra 	$L__BB70_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB70_3;
	bra.uni 	$L__BB70_14;

$L__BB70_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB70_13;

$L__BB70_14:
	ret;

}
	// .globl	s_u8_f64
.visible .entry s_u8_f64(
	.param .u64 s_u8_f64_param_0,
	.param .u64 s_u8_f64_param_1,
	.param .u64 s_u8_f64_param_2,
	.param .u64 s_u8_f64_param_3,
	.param .u64 s_u8_f64_param_4,
	.param .u64 s_u8_f64_param_5,
	.param .u64 s_u8_f64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd20, [s_u8_f64_param_0];
	ld.param.u64 	%rd21, [s_u8_f64_param_1];
	ld.param.u64 	%rd22, [s_u8_f64_param_2];
	ld.param.u64 	%rd26, [s_u8_f64_param_3];
	ld.param.u64 	%rd23, [s_u8_f64_param_4];
	ld.param.u64 	%rd24, [s_u8_f64_param_5];
	ld.param.u64 	%rd25, [s_u8_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB71_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB71_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB71_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB71_5;

	div.u64 	%rd46, %rd45, %rd25;
	mul.lo.s64 	%rd28, %rd46, %rd25;
	sub.s64 	%rd47, %rd45, %rd28;
	bra.uni 	$L__BB71_6;

$L__BB71_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB71_6:
	mul.lo.s64 	%rd13, %rd46, %rd23;
	mul.lo.s64 	%rd14, %rd46, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB71_7:
	add.s64 	%rd30, %rd48, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd47;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB71_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB71_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 86, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 86

$L__BB71_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd47;
	shl.b64 	%rd40, %rd16, 3;
	add.s64 	%rd41, %rd4, %rd40;
	ld.global.f64 	%fd1, [%rd41];
	shl.b64 	%rd42, %rd39, 3;
	add.s64 	%rd43, %rd3, %rd42;
	st.global.f64 	[%rd43], %fd1;

$L__BB71_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p6, %rd48, %rd23;
	@%p6 bra 	$L__BB71_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB71_3;
	bra.uni 	$L__BB71_14;

$L__BB71_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB71_13;

$L__BB71_14:
	ret;

}
	// .globl	s_u8_u8
.visible .entry s_u8_u8(
	.param .u64 s_u8_u8_param_0,
	.param .u64 s_u8_u8_param_1,
	.param .u64 s_u8_u8_param_2,
	.param .u64 s_u8_u8_param_3,
	.param .u64 s_u8_u8_param_4,
	.param .u64 s_u8_u8_param_5,
	.param .u64 s_u8_u8_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<47>;


	ld.param.u64 	%rd20, [s_u8_u8_param_0];
	ld.param.u64 	%rd21, [s_u8_u8_param_1];
	ld.param.u64 	%rd22, [s_u8_u8_param_2];
	ld.param.u64 	%rd26, [s_u8_u8_param_3];
	ld.param.u64 	%rd23, [s_u8_u8_param_4];
	ld.param.u64 	%rd24, [s_u8_u8_param_5];
	ld.param.u64 	%rd25, [s_u8_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd43, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd43;
	@%p1 bra 	$L__BB72_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB72_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB72_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB72_5;

	div.u64 	%rd44, %rd43, %rd25;
	mul.lo.s64 	%rd28, %rd44, %rd25;
	sub.s64 	%rd45, %rd43, %rd28;
	bra.uni 	$L__BB72_6;

$L__BB72_5:
	cvt.u32.u64 	%r14, %rd43;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd44, %r15;
	cvt.u64.u32 	%rd45, %r17;

$L__BB72_6:
	mul.lo.s64 	%rd13, %rd44, %rd23;
	mul.lo.s64 	%rd14, %rd44, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd46, 0;

$L__BB72_7:
	add.s64 	%rd30, %rd46, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd45;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB72_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB72_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 87, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 87

$L__BB72_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd45;
	add.s64 	%rd40, %rd4, %rd16;
	ld.global.u8 	%rs1, [%rd40];
	add.s64 	%rd41, %rd3, %rd39;
	st.global.u8 	[%rd41], %rs1;

$L__BB72_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd46, %r20;
	setp.lt.u64 	%p6, %rd46, %rd23;
	@%p6 bra 	$L__BB72_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p7, %rd2, %rd43;
	@%p7 bra 	$L__BB72_3;
	bra.uni 	$L__BB72_14;

$L__BB72_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p8, %rd2, %rd42;
	@%p8 bra 	$L__BB72_13;

$L__BB72_14:
	ret;

}
	// .globl	s_u8_u32
.visible .entry s_u8_u32(
	.param .u64 s_u8_u32_param_0,
	.param .u64 s_u8_u32_param_1,
	.param .u64 s_u8_u32_param_2,
	.param .u64 s_u8_u32_param_3,
	.param .u64 s_u8_u32_param_4,
	.param .u64 s_u8_u32_param_5,
	.param .u64 s_u8_u32_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd20, [s_u8_u32_param_0];
	ld.param.u64 	%rd21, [s_u8_u32_param_1];
	ld.param.u64 	%rd22, [s_u8_u32_param_2];
	ld.param.u64 	%rd26, [s_u8_u32_param_3];
	ld.param.u64 	%rd23, [s_u8_u32_param_4];
	ld.param.u64 	%rd24, [s_u8_u32_param_5];
	ld.param.u64 	%rd25, [s_u8_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r20, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r20;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB73_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB73_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB73_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB73_5;

	div.u64 	%rd46, %rd45, %rd25;
	mul.lo.s64 	%rd28, %rd46, %rd25;
	sub.s64 	%rd47, %rd45, %rd28;
	bra.uni 	$L__BB73_6;

$L__BB73_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB73_6:
	mul.lo.s64 	%rd13, %rd46, %rd23;
	mul.lo.s64 	%rd14, %rd46, %rd24;
	mov.u32 	%r21, 0;
	mov.u64 	%rd48, 0;

$L__BB73_7:
	add.s64 	%rd30, %rd48, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd47;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB73_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB73_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 88, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 88

$L__BB73_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd47;
	shl.b64 	%rd40, %rd16, 2;
	add.s64 	%rd41, %rd4, %rd40;
	ld.global.u32 	%r19, [%rd41];
	shl.b64 	%rd42, %rd39, 2;
	add.s64 	%rd43, %rd3, %rd42;
	st.global.u32 	[%rd43], %r19;

$L__BB73_11:
	add.s32 	%r21, %r21, 1;
	cvt.u64.u32 	%rd48, %r21;
	setp.lt.u64 	%p6, %rd48, %rd23;
	@%p6 bra 	$L__BB73_7;

	add.s32 	%r20, %r20, %r3;
	cvt.u64.u32 	%rd45, %r20;
	setp.gt.u64 	%p7, %rd2, %rd45;
	@%p7 bra 	$L__BB73_3;
	bra.uni 	$L__BB73_14;

$L__BB73_13:
	add.s32 	%r20, %r20, %r3;
	cvt.u64.u32 	%rd44, %r20;
	setp.gt.u64 	%p8, %rd2, %rd44;
	@%p8 bra 	$L__BB73_13;

$L__BB73_14:
	ret;

}
	// .globl	s_u8_i64
.visible .entry s_u8_i64(
	.param .u64 s_u8_i64_param_0,
	.param .u64 s_u8_i64_param_1,
	.param .u64 s_u8_i64_param_2,
	.param .u64 s_u8_i64_param_3,
	.param .u64 s_u8_i64_param_4,
	.param .u64 s_u8_i64_param_5,
	.param .u64 s_u8_i64_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<50>;


	ld.param.u64 	%rd20, [s_u8_i64_param_0];
	ld.param.u64 	%rd21, [s_u8_i64_param_1];
	ld.param.u64 	%rd22, [s_u8_i64_param_2];
	ld.param.u64 	%rd26, [s_u8_i64_param_3];
	ld.param.u64 	%rd23, [s_u8_i64_param_4];
	ld.param.u64 	%rd24, [s_u8_i64_param_5];
	ld.param.u64 	%rd25, [s_u8_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd46, %r19;
	mul.lo.s64 	%rd2, %rd25, %rd26;
	setp.le.u64 	%p1, %rd2, %rd46;
	@%p1 bra 	$L__BB74_14;

	setp.eq.s64 	%p2, %rd23, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB74_13;

	cvta.to.global.u64 	%rd3, %rd22;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd20;
	cvt.u32.u64 	%r13, %rd25;

$L__BB74_3:
	and.b64  	%rd27, %rd25, -4294967296;
	setp.eq.s64 	%p3, %rd27, 0;
	@%p3 bra 	$L__BB74_5;

	div.u64 	%rd47, %rd46, %rd25;
	mul.lo.s64 	%rd28, %rd47, %rd25;
	sub.s64 	%rd48, %rd46, %rd28;
	bra.uni 	$L__BB74_6;

$L__BB74_5:
	cvt.u32.u64 	%r14, %rd46;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd47, %r15;
	cvt.u64.u32 	%rd48, %r17;

$L__BB74_6:
	mul.lo.s64 	%rd13, %rd47, %rd23;
	mul.lo.s64 	%rd14, %rd47, %rd24;
	mov.u32 	%r20, 0;
	mov.u64 	%rd49, 0;

$L__BB74_7:
	add.s64 	%rd30, %rd49, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd25;
	add.s64 	%rd16, %rd31, %rd48;
	add.s64 	%rd32, %rd5, %rd16;
	ld.global.u8 	%rd17, [%rd32];
	setp.eq.s64 	%p4, %rd17, 255;
	@%p4 bra 	$L__BB74_11;

	setp.lt.u64 	%p5, %rd17, %rd24;
	@%p5 bra 	$L__BB74_10;

	mov.u64 	%rd33, $str$3;
	cvta.global.u64 	%rd34, %rd33;
	mov.u64 	%rd35, $str$1;
	cvta.global.u64 	%rd36, %rd35;
	{ // callseq 89, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd36;
	.param .b32 param2;
	st.param.b32 	[param2+0], 255;
	.param .b64 param3;
	st.param.b64 	[param3+0], 0;
	.param .b64 param4;
	st.param.b64 	[param4+0], 2;
	call.uni 
	__assertfail, 
	(
	param0, 
	param1, 
	param2, 
	param3, 
	param4
	);
	} // callseq 89

$L__BB74_10:
	add.s64 	%rd37, %rd14, %rd17;
	mul.lo.s64 	%rd38, %rd37, %rd25;
	add.s64 	%rd39, %rd38, %rd48;
	shl.b64 	%rd40, %rd16, 3;
	add.s64 	%rd41, %rd4, %rd40;
	ld.global.u64 	%rd42, [%rd41];
	shl.b64 	%rd43, %rd39, 3;
	add.s64 	%rd44, %rd3, %rd43;
	st.global.u64 	[%rd44], %rd42;

$L__BB74_11:
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd49, %r20;
	setp.lt.u64 	%p6, %rd49, %rd23;
	@%p6 bra 	$L__BB74_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd46, %r19;
	setp.gt.u64 	%p7, %rd2, %rd46;
	@%p7 bra 	$L__BB74_3;
	bra.uni 	$L__BB74_14;

$L__BB74_13:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p8, %rd2, %rd45;
	@%p8 bra 	$L__BB74_13;

$L__BB74_14:
	ret;

}

